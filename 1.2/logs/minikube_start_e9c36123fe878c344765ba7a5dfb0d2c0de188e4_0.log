Log file created at: 2022/09/20 05:14:04
Running on machine: DESKTOP-9D9FOPT
Binary: Built with gc go1.18.3 for windows/amd64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0920 05:14:04.650602    7432 out.go:296] Setting OutFile to fd 1420 ...
I0920 05:14:04.651602    7432 out.go:343] TERM=,COLORTERM=, which probably does not support color
I0920 05:14:04.651602    7432 out.go:309] Setting ErrFile to fd 92...
I0920 05:14:04.651602    7432 out.go:343] TERM=,COLORTERM=, which probably does not support color
I0920 05:14:04.662601    7432 out.go:303] Setting JSON to false
I0920 05:14:04.668602    7432 start.go:115] hostinfo: {"hostname":"DESKTOP-9D9FOPT","uptime":6271,"bootTime":1663662573,"procs":304,"os":"windows","platform":"Microsoft Windows 10 Home","platformFamily":"Standalone Workstation","platformVersion":"10.0.19044 Build 19044","kernelVersion":"10.0.19044 Build 19044","kernelArch":"x86_64","virtualizationSystem":"","virtualizationRole":"","hostId":"1b124a21-ded5-4c8f-8353-aebb67e61cfb"}
W0920 05:14:04.668602    7432 start.go:123] gopshost.Virtualization returned error: not implemented yet
I0920 05:14:04.672601    7432 out.go:177] * minikube v1.26.1 on Microsoft Windows 10 Home 10.0.19044 Build 19044
I0920 05:14:04.673602    7432 notify.go:193] Checking for updates...
I0920 05:14:04.674603    7432 driver.go:365] Setting default libvirt URI to qemu:///system
I0920 05:14:04.849251    7432 docker.go:137] docker version: linux-20.10.16
I0920 05:14:04.860196    7432 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0920 05:14:05.239257    7432 info.go:265] docker info: {ID:L7ZV:4RQ3:VGXF:PEOU:J5XA:5F73:RDPM:ANUF:ZH5V:B6LC:XKSZ:SFZC Containers:0 ContainersRunning:0 ContainersPaused:0 ContainersStopped:0 Images:6 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:true KernelMemoryTCP:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:51 OomKillDisable:true NGoroutines:52 SystemTime:2022-09-20 10:14:04.9721032 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:5 KernelVersion:5.10.102.1-microsoft-standard-WSL2 OperatingSystem:Docker Desktop OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:12 MemTotal:13233201152 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http.docker.internal:3128 HTTPSProxy:http.docker.internal:3128 NoProxy:hubproxy.docker.internal Name:docker-desktop Labels:[] ExperimentalBuild:false ServerVersion:20.10.16 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:212e8b6fa2f44b9c21b2798135fc6fb7c53efc16 Expected:212e8b6fa2f44b9c21b2798135fc6fb7c53efc16} RuncCommit:{ID:v1.1.1-0-g52de29d Expected:v1.1.1-0-g52de29d} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=default] ProductLicense: Warnings:[WARNING: No blkio throttle.read_bps_device support WARNING: No blkio throttle.write_bps_device support WARNING: No blkio throttle.read_iops_device support WARNING: No blkio throttle.write_iops_device support] ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:C:\Program Files\Docker\cli-plugins\docker-buildx.exe SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.8.2] map[Name:compose Path:C:\Program Files\Docker\cli-plugins\docker-compose.exe SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.6.0] map[Name:sbom Path:C:\Program Files\Docker\cli-plugins\docker-sbom.exe SchemaVersion:0.1.0 ShortDescription:View the packaged-based Software Bill Of Materials (SBOM) for an image URL:https://github.com/docker/sbom-cli-plugin Vendor:Anchore Inc. Version:0.6.0] map[Name:scan Path:C:\Program Files\Docker\cli-plugins\docker-scan.exe SchemaVersion:0.1.0 ShortDescription:Docker Scan Vendor:Docker Inc. Version:v0.17.0]] Warnings:<nil>}}
I0920 05:14:05.245578    7432 out.go:177] * Using the docker driver based on user configuration
I0920 05:14:05.246662    7432 start.go:284] selected driver: docker
I0920 05:14:05.246662    7432 start.go:808] validating driver "docker" against <nil>
I0920 05:14:05.246662    7432 start.go:819] status for docker: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I0920 05:14:05.267424    7432 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0920 05:14:05.609700    7432 info.go:265] docker info: {ID:L7ZV:4RQ3:VGXF:PEOU:J5XA:5F73:RDPM:ANUF:ZH5V:B6LC:XKSZ:SFZC Containers:0 ContainersRunning:0 ContainersPaused:0 ContainersStopped:0 Images:6 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:true KernelMemoryTCP:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:51 OomKillDisable:true NGoroutines:52 SystemTime:2022-09-20 10:14:05.3796486 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:5 KernelVersion:5.10.102.1-microsoft-standard-WSL2 OperatingSystem:Docker Desktop OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:12 MemTotal:13233201152 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http.docker.internal:3128 HTTPSProxy:http.docker.internal:3128 NoProxy:hubproxy.docker.internal Name:docker-desktop Labels:[] ExperimentalBuild:false ServerVersion:20.10.16 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:212e8b6fa2f44b9c21b2798135fc6fb7c53efc16 Expected:212e8b6fa2f44b9c21b2798135fc6fb7c53efc16} RuncCommit:{ID:v1.1.1-0-g52de29d Expected:v1.1.1-0-g52de29d} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=default] ProductLicense: Warnings:[WARNING: No blkio throttle.read_bps_device support WARNING: No blkio throttle.write_bps_device support WARNING: No blkio throttle.read_iops_device support WARNING: No blkio throttle.write_iops_device support] ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:C:\Program Files\Docker\cli-plugins\docker-buildx.exe SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.8.2] map[Name:compose Path:C:\Program Files\Docker\cli-plugins\docker-compose.exe SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.6.0] map[Name:sbom Path:C:\Program Files\Docker\cli-plugins\docker-sbom.exe SchemaVersion:0.1.0 ShortDescription:View the packaged-based Software Bill Of Materials (SBOM) for an image URL:https://github.com/docker/sbom-cli-plugin Vendor:Anchore Inc. Version:0.6.0] map[Name:scan Path:C:\Program Files\Docker\cli-plugins\docker-scan.exe SchemaVersion:0.1.0 ShortDescription:Docker Scan Vendor:Docker Inc. Version:v0.17.0]] Warnings:<nil>}}
I0920 05:14:05.609700    7432 start_flags.go:296] no existing cluster config was found, will generate one from the flags 
I0920 05:14:05.652817    7432 start_flags.go:377] Using suggested 2200MB memory alloc based on sys=16190MB, container=12620MB
I0920 05:14:05.653337    7432 start_flags.go:835] Wait components to verify : map[apiserver:true system_pods:true]
I0920 05:14:05.655986    7432 out.go:177] * Using Docker Desktop driver with root privileges
I0920 05:14:05.657587    7432 cni.go:95] Creating CNI manager for ""
I0920 05:14:05.657587    7432 cni.go:156] 0 nodes found, recommending kindnet
I0920 05:14:05.657587    7432 start_flags.go:305] Found "CNI" CNI - setting NetworkPlugin=cni
I0920 05:14:05.657587    7432 start_flags.go:310] config:
{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 Memory:2200 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.24.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[] Addons:map[] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:true ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:C:\Users\Esteban:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath:}
I0920 05:14:05.660297    7432 out.go:177] * Starting control plane node minikube in cluster minikube
I0920 05:14:05.661377    7432 cache.go:120] Beginning downloading kic base image for docker with docker
I0920 05:14:05.663494    7432 out.go:177] * Pulling base image ...
I0920 05:14:05.665574    7432 preload.go:132] Checking if preload exists for k8s version v1.24.3 and runtime docker
I0920 05:14:05.665574    7432 image.go:75] Checking for gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 in local docker daemon
I0920 05:14:05.665574    7432 preload.go:148] Found local preload: C:\Users\Esteban\.minikube\cache\preloaded-tarball\preloaded-images-k8s-v18-v1.24.3-docker-overlay2-amd64.tar.lz4
I0920 05:14:05.665574    7432 cache.go:57] Caching tarball of preloaded images
I0920 05:14:05.665574    7432 preload.go:174] Found C:\Users\Esteban\.minikube\cache\preloaded-tarball\preloaded-images-k8s-v18-v1.24.3-docker-overlay2-amd64.tar.lz4 in cache, skipping download
I0920 05:14:05.666079    7432 cache.go:60] Finished verifying existence of preloaded tar for  v1.24.3 on docker
I0920 05:14:05.666144    7432 profile.go:148] Saving config to C:\Users\Esteban\.minikube\profiles\minikube\config.json ...
I0920 05:14:05.666144    7432 lock.go:35] WriteFile acquiring C:\Users\Esteban\.minikube\profiles\minikube\config.json: {Name:mk2a00695caa01573162753941d974857a7beb3e Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0920 05:14:05.829414    7432 image.go:79] Found gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 in local docker daemon, skipping pull
I0920 05:14:05.829414    7432 cache.go:142] gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 exists in daemon, skipping load
I0920 05:14:05.829414    7432 cache.go:208] Successfully downloaded all kic artifacts
I0920 05:14:05.829414    7432 start.go:371] acquiring machines lock for minikube: {Name:mkb1a3f9dd56644c74d06159971e44ffb1f7dc12 Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I0920 05:14:05.829414    7432 start.go:375] acquired machines lock for "minikube" in 0s
I0920 05:14:05.829414    7432 start.go:92] Provisioning new machine with config: &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 Memory:2200 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.24.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP: Port:8443 KubernetesVersion:v1.24.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:true ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:C:\Users\Esteban:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath:} &{Name: IP: Port:8443 KubernetesVersion:v1.24.3 ContainerRuntime:docker ControlPlane:true Worker:true}
I0920 05:14:05.829414    7432 start.go:132] createHost starting for "" (driver="docker")
I0920 05:14:05.832709    7432 out.go:204] * Creating docker container (CPUs=2, Memory=2200MB) ...
I0920 05:14:05.832724    7432 start.go:166] libmachine.API.Create for "minikube" (driver="docker")
I0920 05:14:05.832724    7432 client.go:168] LocalClient.Create starting
I0920 05:14:05.833228    7432 main.go:134] libmachine: Reading certificate data from C:\Users\Esteban\.minikube\certs\ca.pem
I0920 05:14:05.833244    7432 main.go:134] libmachine: Decoding PEM data...
I0920 05:14:05.833244    7432 main.go:134] libmachine: Parsing certificate...
I0920 05:14:05.833244    7432 main.go:134] libmachine: Reading certificate data from C:\Users\Esteban\.minikube\certs\cert.pem
I0920 05:14:05.833244    7432 main.go:134] libmachine: Decoding PEM data...
I0920 05:14:05.833244    7432 main.go:134] libmachine: Parsing certificate...
I0920 05:14:05.844806    7432 cli_runner.go:164] Run: docker network inspect minikube --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}"
W0920 05:14:05.983129    7432 cli_runner.go:211] docker network inspect minikube --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}" returned with exit code 1
I0920 05:14:05.993965    7432 network_create.go:272] running [docker network inspect minikube] to gather additional debugging logs...
I0920 05:14:05.993965    7432 cli_runner.go:164] Run: docker network inspect minikube
W0920 05:14:06.135888    7432 cli_runner.go:211] docker network inspect minikube returned with exit code 1
I0920 05:14:06.135888    7432 network_create.go:275] error running [docker network inspect minikube]: docker network inspect minikube: exit status 1
stdout:
[]

stderr:
Error: No such network: minikube
I0920 05:14:06.135888    7432 network_create.go:277] output of [docker network inspect minikube]: -- stdout --
[]

-- /stdout --
** stderr ** 
Error: No such network: minikube

** /stderr **
I0920 05:14:06.146577    7432 cli_runner.go:164] Run: docker network inspect bridge --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}"
I0920 05:14:06.399436    7432 network.go:288] reserving subnet 192.168.49.0 for 1m0s: &{mu:{state:0 sema:0} read:{v:{m:map[] amended:true}} dirty:map[192.168.49.0:0xc000598440] misses:0}
I0920 05:14:06.399436    7432 network.go:235] using free private subnet 192.168.49.0/24: &{IP:192.168.49.0 Netmask:255.255.255.0 Prefix:24 CIDR:192.168.49.0/24 Gateway:192.168.49.1 ClientMin:192.168.49.2 ClientMax:192.168.49.254 Broadcast:192.168.49.255 Interface:{IfaceName: IfaceIPv4: IfaceMTU:0 IfaceMAC:}}
I0920 05:14:06.399436    7432 network_create.go:115] attempt to create docker network minikube 192.168.49.0/24 with gateway 192.168.49.1 and MTU of 1500 ...
I0920 05:14:06.410105    7432 cli_runner.go:164] Run: docker network create --driver=bridge --subnet=192.168.49.0/24 --gateway=192.168.49.1 -o --ip-masq -o --icc -o com.docker.network.driver.mtu=1500 --label=created_by.minikube.sigs.k8s.io=true --label=name.minikube.sigs.k8s.io=minikube minikube
I0920 05:14:06.599202    7432 network_create.go:99] docker network minikube 192.168.49.0/24 created
I0920 05:14:06.599202    7432 kic.go:106] calculated static IP "192.168.49.2" for the "minikube" container
I0920 05:14:06.620107    7432 cli_runner.go:164] Run: docker ps -a --format {{.Names}}
I0920 05:14:06.780802    7432 cli_runner.go:164] Run: docker volume create minikube --label name.minikube.sigs.k8s.io=minikube --label created_by.minikube.sigs.k8s.io=true
I0920 05:14:06.923617    7432 oci.go:103] Successfully created a docker volume minikube
I0920 05:14:06.933742    7432 cli_runner.go:164] Run: docker run --rm --name minikube-preload-sidecar --label created_by.minikube.sigs.k8s.io=true --label name.minikube.sigs.k8s.io=minikube --entrypoint /usr/bin/test -v minikube:/var gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 -d /var/lib
I0920 05:14:08.063490    7432 cli_runner.go:217] Completed: docker run --rm --name minikube-preload-sidecar --label created_by.minikube.sigs.k8s.io=true --label name.minikube.sigs.k8s.io=minikube --entrypoint /usr/bin/test -v minikube:/var gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 -d /var/lib: (1.1297479s)
I0920 05:14:08.063490    7432 oci.go:107] Successfully prepared a docker volume minikube
I0920 05:14:08.063490    7432 preload.go:132] Checking if preload exists for k8s version v1.24.3 and runtime docker
I0920 05:14:08.063490    7432 kic.go:179] Starting extracting preloaded images to volume ...
I0920 05:14:08.074121    7432 cli_runner.go:164] Run: docker run --rm --entrypoint /usr/bin/tar -v C:\Users\Esteban\.minikube\cache\preloaded-tarball\preloaded-images-k8s-v18-v1.24.3-docker-overlay2-amd64.tar.lz4:/preloaded.tar:ro -v minikube:/extractDir gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 -I lz4 -xf /preloaded.tar -C /extractDir
I0920 05:14:35.082923    7432 cli_runner.go:217] Completed: docker run --rm --entrypoint /usr/bin/tar -v C:\Users\Esteban\.minikube\cache\preloaded-tarball\preloaded-images-k8s-v18-v1.24.3-docker-overlay2-amd64.tar.lz4:/preloaded.tar:ro -v minikube:/extractDir gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 -I lz4 -xf /preloaded.tar -C /extractDir: (27.0088021s)
I0920 05:14:35.082923    7432 kic.go:188] duration metric: took 27.019433 seconds to extract preloaded images to volume
I0920 05:14:35.093564    7432 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0920 05:14:35.532774    7432 info.go:265] docker info: {ID:L7ZV:4RQ3:VGXF:PEOU:J5XA:5F73:RDPM:ANUF:ZH5V:B6LC:XKSZ:SFZC Containers:0 ContainersRunning:0 ContainersPaused:0 ContainersStopped:0 Images:6 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:true KernelMemoryTCP:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:50 OomKillDisable:true NGoroutines:52 SystemTime:2022-09-20 10:14:35.3004356 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:5 KernelVersion:5.10.102.1-microsoft-standard-WSL2 OperatingSystem:Docker Desktop OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:12 MemTotal:13233201152 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http.docker.internal:3128 HTTPSProxy:http.docker.internal:3128 NoProxy:hubproxy.docker.internal Name:docker-desktop Labels:[] ExperimentalBuild:false ServerVersion:20.10.16 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:212e8b6fa2f44b9c21b2798135fc6fb7c53efc16 Expected:212e8b6fa2f44b9c21b2798135fc6fb7c53efc16} RuncCommit:{ID:v1.1.1-0-g52de29d Expected:v1.1.1-0-g52de29d} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=default] ProductLicense: Warnings:[WARNING: No blkio throttle.read_bps_device support WARNING: No blkio throttle.write_bps_device support WARNING: No blkio throttle.read_iops_device support WARNING: No blkio throttle.write_iops_device support] ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:C:\Program Files\Docker\cli-plugins\docker-buildx.exe SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.8.2] map[Name:compose Path:C:\Program Files\Docker\cli-plugins\docker-compose.exe SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.6.0] map[Name:sbom Path:C:\Program Files\Docker\cli-plugins\docker-sbom.exe SchemaVersion:0.1.0 ShortDescription:View the packaged-based Software Bill Of Materials (SBOM) for an image URL:https://github.com/docker/sbom-cli-plugin Vendor:Anchore Inc. Version:0.6.0] map[Name:scan Path:C:\Program Files\Docker\cli-plugins\docker-scan.exe SchemaVersion:0.1.0 ShortDescription:Docker Scan Vendor:Docker Inc. Version:v0.17.0]] Warnings:<nil>}}
I0920 05:14:35.543413    7432 cli_runner.go:164] Run: docker info --format "'{{json .SecurityOptions}}'"
I0920 05:14:35.912301    7432 cli_runner.go:164] Run: docker run -d -t --privileged --security-opt seccomp=unconfined --tmpfs /tmp --tmpfs /run -v /lib/modules:/lib/modules:ro --hostname minikube --name minikube --label created_by.minikube.sigs.k8s.io=true --label name.minikube.sigs.k8s.io=minikube --label role.minikube.sigs.k8s.io= --label mode.minikube.sigs.k8s.io=minikube --network minikube --ip 192.168.49.2 --volume minikube:/var --security-opt apparmor=unconfined --memory=2200mb --memory-swap=2200mb --cpus=2 -e container=docker --expose 8443 --publish=127.0.0.1::8443 --publish=127.0.0.1::22 --publish=127.0.0.1::2376 --publish=127.0.0.1::5000 --publish=127.0.0.1::32443 gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8
I0920 05:14:36.805114    7432 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Running}}
I0920 05:14:36.992386    7432 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0920 05:14:37.174712    7432 cli_runner.go:164] Run: docker exec minikube stat /var/lib/dpkg/alternatives/iptables
I0920 05:14:37.457602    7432 oci.go:144] the created container "minikube" has a running status.
I0920 05:14:37.457602    7432 kic.go:210] Creating ssh key for kic: C:\Users\Esteban\.minikube\machines\minikube\id_rsa...
I0920 05:14:37.535307    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\machines\minikube\id_rsa.pub -> /home/docker/.ssh/authorized_keys
I0920 05:14:37.539306    7432 kic_runner.go:191] docker (temp): C:\Users\Esteban\.minikube\machines\minikube\id_rsa.pub --> /home/docker/.ssh/authorized_keys (381 bytes)
I0920 05:14:37.782120    7432 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0920 05:14:37.969983    7432 kic_runner.go:93] Run: chown docker:docker /home/docker/.ssh/authorized_keys
I0920 05:14:37.969983    7432 kic_runner.go:114] Args: [docker exec --privileged minikube chown docker:docker /home/docker/.ssh/authorized_keys]
I0920 05:14:38.224255    7432 kic.go:250] ensuring only current user has permissions to key file located at : C:\Users\Esteban\.minikube\machines\minikube\id_rsa...
I0920 05:14:38.587481    7432 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0920 05:14:38.749709    7432 machine.go:88] provisioning docker machine ...
I0920 05:14:38.749709    7432 ubuntu.go:169] provisioning hostname "minikube"
I0920 05:14:38.761401    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0920 05:14:38.925162    7432 main.go:134] libmachine: Using SSH client type: native
I0920 05:14:38.925682    7432 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x8d3da0] 0x8d6c00 <nil>  [] 0s} 127.0.0.1 55721 <nil> <nil>}
I0920 05:14:38.925682    7432 main.go:134] libmachine: About to run SSH command:
sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
I0920 05:14:39.007832    7432 main.go:134] libmachine: SSH cmd err, output: <nil>: minikube

I0920 05:14:39.018970    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0920 05:14:39.169086    7432 main.go:134] libmachine: Using SSH client type: native
I0920 05:14:39.169086    7432 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x8d3da0] 0x8d6c00 <nil>  [] 0s} 127.0.0.1 55721 <nil> <nil>}
I0920 05:14:39.169086    7432 main.go:134] libmachine: About to run SSH command:

		if ! grep -xq '.*\sminikube' /etc/hosts; then
			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 minikube/g' /etc/hosts;
			else 
				echo '127.0.1.1 minikube' | sudo tee -a /etc/hosts; 
			fi
		fi
I0920 05:14:39.298556    7432 main.go:134] libmachine: SSH cmd err, output: <nil>: 
I0920 05:14:39.298577    7432 ubuntu.go:175] set auth options {CertDir:C:\Users\Esteban\.minikube CaCertPath:C:\Users\Esteban\.minikube\certs\ca.pem CaPrivateKeyPath:C:\Users\Esteban\.minikube\certs\ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:C:\Users\Esteban\.minikube\machines\server.pem ServerKeyPath:C:\Users\Esteban\.minikube\machines\server-key.pem ClientKeyPath:C:\Users\Esteban\.minikube\certs\key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:C:\Users\Esteban\.minikube\certs\cert.pem ServerCertSANs:[] StorePath:C:\Users\Esteban\.minikube}
I0920 05:14:39.298577    7432 ubuntu.go:177] setting up certificates
I0920 05:14:39.298577    7432 provision.go:83] configureAuth start
I0920 05:14:39.308582    7432 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0920 05:14:39.457116    7432 provision.go:138] copyHostCerts
I0920 05:14:39.457116    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\certs\ca.pem -> C:\Users\Esteban\.minikube/ca.pem
I0920 05:14:39.457116    7432 exec_runner.go:144] found C:\Users\Esteban\.minikube/ca.pem, removing ...
I0920 05:14:39.457116    7432 exec_runner.go:207] rm: C:\Users\Esteban\.minikube\ca.pem
I0920 05:14:39.457116    7432 exec_runner.go:151] cp: C:\Users\Esteban\.minikube\certs\ca.pem --> C:\Users\Esteban\.minikube/ca.pem (1082 bytes)
I0920 05:14:39.458833    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\certs\cert.pem -> C:\Users\Esteban\.minikube/cert.pem
I0920 05:14:39.458833    7432 exec_runner.go:144] found C:\Users\Esteban\.minikube/cert.pem, removing ...
I0920 05:14:39.458833    7432 exec_runner.go:207] rm: C:\Users\Esteban\.minikube\cert.pem
I0920 05:14:39.458833    7432 exec_runner.go:151] cp: C:\Users\Esteban\.minikube\certs\cert.pem --> C:\Users\Esteban\.minikube/cert.pem (1123 bytes)
I0920 05:14:39.459381    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\certs\key.pem -> C:\Users\Esteban\.minikube/key.pem
I0920 05:14:39.459381    7432 exec_runner.go:144] found C:\Users\Esteban\.minikube/key.pem, removing ...
I0920 05:14:39.459381    7432 exec_runner.go:207] rm: C:\Users\Esteban\.minikube\key.pem
I0920 05:14:39.459381    7432 exec_runner.go:151] cp: C:\Users\Esteban\.minikube\certs\key.pem --> C:\Users\Esteban\.minikube/key.pem (1679 bytes)
I0920 05:14:39.459902    7432 provision.go:112] generating server cert: C:\Users\Esteban\.minikube\machines\server.pem ca-key=C:\Users\Esteban\.minikube\certs\ca.pem private-key=C:\Users\Esteban\.minikube\certs\ca-key.pem org=Esteban.minikube san=[192.168.49.2 127.0.0.1 localhost 127.0.0.1 minikube minikube]
I0920 05:14:39.562842    7432 provision.go:172] copyRemoteCerts
I0920 05:14:39.568842    7432 ssh_runner.go:195] Run: sudo mkdir -p /etc/docker /etc/docker /etc/docker
I0920 05:14:39.578841    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0920 05:14:39.721599    7432 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:55721 SSHKeyPath:C:\Users\Esteban\.minikube\machines\minikube\id_rsa Username:docker}
I0920 05:14:39.822808    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\machines\server-key.pem -> /etc/docker/server-key.pem
I0920 05:14:39.822808    7432 ssh_runner.go:362] scp C:\Users\Esteban\.minikube\machines\server-key.pem --> /etc/docker/server-key.pem (1675 bytes)
I0920 05:14:39.841537    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\certs\ca.pem -> /etc/docker/ca.pem
I0920 05:14:39.842070    7432 ssh_runner.go:362] scp C:\Users\Esteban\.minikube\certs\ca.pem --> /etc/docker/ca.pem (1082 bytes)
I0920 05:14:39.862312    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\machines\server.pem -> /etc/docker/server.pem
I0920 05:14:39.862312    7432 ssh_runner.go:362] scp C:\Users\Esteban\.minikube\machines\server.pem --> /etc/docker/server.pem (1204 bytes)
I0920 05:14:39.884269    7432 provision.go:86] duration metric: configureAuth took 585.692ms
I0920 05:14:39.884269    7432 ubuntu.go:193] setting minikube options for container-runtime
I0920 05:14:39.884798    7432 config.go:180] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.24.3
I0920 05:14:39.896885    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0920 05:14:40.051368    7432 main.go:134] libmachine: Using SSH client type: native
I0920 05:14:40.051927    7432 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x8d3da0] 0x8d6c00 <nil>  [] 0s} 127.0.0.1 55721 <nil> <nil>}
I0920 05:14:40.051927    7432 main.go:134] libmachine: About to run SSH command:
df --output=fstype / | tail -n 1
I0920 05:14:40.169078    7432 main.go:134] libmachine: SSH cmd err, output: <nil>: overlay

I0920 05:14:40.169078    7432 ubuntu.go:71] root file system type: overlay
I0920 05:14:40.169078    7432 provision.go:309] Updating docker unit: /lib/systemd/system/docker.service ...
I0920 05:14:40.181248    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0920 05:14:40.332369    7432 main.go:134] libmachine: Using SSH client type: native
I0920 05:14:40.332954    7432 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x8d3da0] 0x8d6c00 <nil>  [] 0s} 127.0.0.1 55721 <nil> <nil>}
I0920 05:14:40.332954    7432 main.go:134] libmachine: About to run SSH command:
sudo mkdir -p /lib/systemd/system && printf %s "[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP \$MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target
" | sudo tee /lib/systemd/system/docker.service.new
I0920 05:14:40.468007    7432 main.go:134] libmachine: SSH cmd err, output: <nil>: [Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP $MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target

I0920 05:14:40.480001    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0920 05:14:40.639752    7432 main.go:134] libmachine: Using SSH client type: native
I0920 05:14:40.640272    7432 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x8d3da0] 0x8d6c00 <nil>  [] 0s} 127.0.0.1 55721 <nil> <nil>}
I0920 05:14:40.640272    7432 main.go:134] libmachine: About to run SSH command:
sudo diff -u /lib/systemd/system/docker.service /lib/systemd/system/docker.service.new || { sudo mv /lib/systemd/system/docker.service.new /lib/systemd/system/docker.service; sudo systemctl -f daemon-reload && sudo systemctl -f enable docker && sudo systemctl -f restart docker; }
I0920 05:14:41.384417    7432 main.go:134] libmachine: SSH cmd err, output: <nil>: --- /lib/systemd/system/docker.service	2022-06-06 23:01:03.000000000 +0000
+++ /lib/systemd/system/docker.service.new	2022-09-20 10:14:40.462362000 +0000
@@ -1,30 +1,32 @@
 [Unit]
 Description=Docker Application Container Engine
 Documentation=https://docs.docker.com
-After=network-online.target docker.socket firewalld.service containerd.service
+BindsTo=containerd.service
+After=network-online.target firewalld.service containerd.service
 Wants=network-online.target
-Requires=docker.socket containerd.service
+Requires=docker.socket
+StartLimitBurst=3
+StartLimitIntervalSec=60
 
 [Service]
 Type=notify
-# the default is not to use systemd for cgroups because the delegate issues still
-# exists and systemd currently does not support the cgroup feature set required
-# for containers run by docker
-ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock
-ExecReload=/bin/kill -s HUP $MAINPID
-TimeoutSec=0
-RestartSec=2
-Restart=always
-
-# Note that StartLimit* options were moved from "Service" to "Unit" in systemd 229.
-# Both the old, and new location are accepted by systemd 229 and up, so using the old location
-# to make them work for either version of systemd.
-StartLimitBurst=3
+Restart=on-failure
 
-# Note that StartLimitInterval was renamed to StartLimitIntervalSec in systemd 230.
-# Both the old, and new name are accepted by systemd 230 and up, so using the old name to make
-# this option work for either version of systemd.
-StartLimitInterval=60s
+
+
+# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
+# The base configuration already specifies an 'ExecStart=...' command. The first directive
+# here is to clear out that command inherited from the base configuration. Without this,
+# the command from the base configuration and the command specified here are treated as
+# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
+# will catch this invalid input and refuse to start the service with an error like:
+#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.
+
+# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
+# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
+ExecStart=
+ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
+ExecReload=/bin/kill -s HUP $MAINPID
 
 # Having non-zero Limit*s causes performance problems due to accounting overhead
 # in the kernel. We recommend using cgroups to do container-local accounting.
@@ -32,16 +34,16 @@
 LimitNPROC=infinity
 LimitCORE=infinity
 
-# Comment TasksMax if your systemd version does not support it.
-# Only systemd 226 and above support this option.
+# Uncomment TasksMax if your systemd version supports it.
+# Only systemd 226 and above support this version.
 TasksMax=infinity
+TimeoutStartSec=0
 
 # set delegate yes so that systemd does not reset the cgroups of docker containers
 Delegate=yes
 
 # kill only the docker process, not all processes in the cgroup
 KillMode=process
-OOMScoreAdjust=-500
 
 [Install]
 WantedBy=multi-user.target
Synchronizing state of docker.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable docker

I0920 05:14:41.384417    7432 machine.go:91] provisioned docker machine in 2.6347085s
I0920 05:14:41.384417    7432 client.go:171] LocalClient.Create took 35.5516933s
I0920 05:14:41.384925    7432 start.go:174] duration metric: libmachine.API.Create for "minikube" took 35.5522008s
I0920 05:14:41.384925    7432 start.go:307] post-start starting for "minikube" (driver="docker")
I0920 05:14:41.384925    7432 start.go:335] creating required directories: [/etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs]
I0920 05:14:41.391844    7432 ssh_runner.go:195] Run: sudo mkdir -p /etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs
I0920 05:14:41.402354    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0920 05:14:41.549415    7432 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:55721 SSHKeyPath:C:\Users\Esteban\.minikube\machines\minikube\id_rsa Username:docker}
I0920 05:14:41.612140    7432 ssh_runner.go:195] Run: cat /etc/os-release
I0920 05:14:41.617530    7432 command_runner.go:130] > NAME="Ubuntu"
I0920 05:14:41.617530    7432 command_runner.go:130] > VERSION="20.04.4 LTS (Focal Fossa)"
I0920 05:14:41.617530    7432 command_runner.go:130] > ID=ubuntu
I0920 05:14:41.617530    7432 command_runner.go:130] > ID_LIKE=debian
I0920 05:14:41.617530    7432 command_runner.go:130] > PRETTY_NAME="Ubuntu 20.04.4 LTS"
I0920 05:14:41.617530    7432 command_runner.go:130] > VERSION_ID="20.04"
I0920 05:14:41.617530    7432 command_runner.go:130] > HOME_URL="https://www.ubuntu.com/"
I0920 05:14:41.617530    7432 command_runner.go:130] > SUPPORT_URL="https://help.ubuntu.com/"
I0920 05:14:41.617530    7432 command_runner.go:130] > BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
I0920 05:14:41.617530    7432 command_runner.go:130] > PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
I0920 05:14:41.617530    7432 command_runner.go:130] > VERSION_CODENAME=focal
I0920 05:14:41.617530    7432 command_runner.go:130] > UBUNTU_CODENAME=focal
I0920 05:14:41.617530    7432 main.go:134] libmachine: Couldn't set key PRIVACY_POLICY_URL, no corresponding struct field found
I0920 05:14:41.617530    7432 main.go:134] libmachine: Couldn't set key VERSION_CODENAME, no corresponding struct field found
I0920 05:14:41.617530    7432 main.go:134] libmachine: Couldn't set key UBUNTU_CODENAME, no corresponding struct field found
I0920 05:14:41.617530    7432 info.go:137] Remote host: Ubuntu 20.04.4 LTS
I0920 05:14:41.617530    7432 filesync.go:126] Scanning C:\Users\Esteban\.minikube\addons for local assets ...
I0920 05:14:41.617530    7432 filesync.go:126] Scanning C:\Users\Esteban\.minikube\files for local assets ...
I0920 05:14:41.617530    7432 start.go:310] post-start completed in 232.6047ms
I0920 05:14:41.630305    7432 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0920 05:14:41.781027    7432 profile.go:148] Saving config to C:\Users\Esteban\.minikube\profiles\minikube\config.json ...
I0920 05:14:41.801336    7432 ssh_runner.go:195] Run: sh -c "df -h /var | awk 'NR==2{print $5}'"
I0920 05:14:41.811363    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0920 05:14:41.951821    7432 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:55721 SSHKeyPath:C:\Users\Esteban\.minikube\machines\minikube\id_rsa Username:docker}
I0920 05:14:42.038523    7432 command_runner.go:130] > 2%
I0920 05:14:42.057031    7432 ssh_runner.go:195] Run: sh -c "df -BG /var | awk 'NR==2{print $4}'"
I0920 05:14:42.061722    7432 command_runner.go:130] > 234G
I0920 05:14:42.062248    7432 start.go:135] duration metric: createHost completed in 36.2328337s
I0920 05:14:42.062248    7432 start.go:82] releasing machines lock for "minikube", held for 36.2328337s
I0920 05:14:42.072755    7432 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0920 05:14:42.215924    7432 ssh_runner.go:195] Run: curl -sS -m 2 https://k8s.gcr.io/
I0920 05:14:42.227093    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0920 05:14:42.230927    7432 ssh_runner.go:195] Run: systemctl --version
I0920 05:14:42.241494    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0920 05:14:42.385026    7432 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:55721 SSHKeyPath:C:\Users\Esteban\.minikube\machines\minikube\id_rsa Username:docker}
I0920 05:14:42.399802    7432 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:55721 SSHKeyPath:C:\Users\Esteban\.minikube\machines\minikube\id_rsa Username:docker}
I0920 05:14:43.378044    7432 command_runner.go:130] > <HTML><HEAD><meta http-equiv="content-type" content="text/html;charset=utf-8">
I0920 05:14:43.378044    7432 command_runner.go:130] > <TITLE>302 Moved</TITLE></HEAD><BODY>
I0920 05:14:43.378044    7432 command_runner.go:130] > <H1>302 Moved</H1>
I0920 05:14:43.378044    7432 command_runner.go:130] > The document has moved
I0920 05:14:43.378044    7432 command_runner.go:130] > <A HREF="https://cloud.google.com/container-registry/">here</A>.
I0920 05:14:43.378044    7432 command_runner.go:130] > </BODY></HTML>
I0920 05:14:43.379668    7432 command_runner.go:130] > systemd 245 (245.4-4ubuntu3.17)
I0920 05:14:43.379668    7432 command_runner.go:130] > +PAM +AUDIT +SELINUX +IMA +APPARMOR +SMACK +SYSVINIT +UTMP +LIBCRYPTSETUP +GCRYPT +GNUTLS +ACL +XZ +LZ4 +SECCOMP +BLKID +ELFUTILS +KMOD +IDN2 -IDN +PCRE2 default-hierarchy=hybrid
I0920 05:14:43.379668    7432 ssh_runner.go:235] Completed: systemctl --version: (1.1487406s)
I0920 05:14:43.379668    7432 ssh_runner.go:235] Completed: curl -sS -m 2 https://k8s.gcr.io/: (1.1637444s)
I0920 05:14:43.387226    7432 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/cri-docker.service.d
I0920 05:14:43.398542    7432 ssh_runner.go:362] scp memory --> /etc/systemd/system/cri-docker.service.d/10-cni.conf (234 bytes)
I0920 05:14:43.423425    7432 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0920 05:14:43.529112    7432 ssh_runner.go:195] Run: sudo systemctl restart cri-docker
I0920 05:14:43.611110    7432 ssh_runner.go:195] Run: sudo systemctl cat docker.service
I0920 05:14:43.622831    7432 command_runner.go:130] > # /lib/systemd/system/docker.service
I0920 05:14:43.622831    7432 command_runner.go:130] > [Unit]
I0920 05:14:43.622831    7432 command_runner.go:130] > Description=Docker Application Container Engine
I0920 05:14:43.622831    7432 command_runner.go:130] > Documentation=https://docs.docker.com
I0920 05:14:43.622831    7432 command_runner.go:130] > BindsTo=containerd.service
I0920 05:14:43.622831    7432 command_runner.go:130] > After=network-online.target firewalld.service containerd.service
I0920 05:14:43.622831    7432 command_runner.go:130] > Wants=network-online.target
I0920 05:14:43.622831    7432 command_runner.go:130] > Requires=docker.socket
I0920 05:14:43.622831    7432 command_runner.go:130] > StartLimitBurst=3
I0920 05:14:43.622831    7432 command_runner.go:130] > StartLimitIntervalSec=60
I0920 05:14:43.622831    7432 command_runner.go:130] > [Service]
I0920 05:14:43.622831    7432 command_runner.go:130] > Type=notify
I0920 05:14:43.622831    7432 command_runner.go:130] > Restart=on-failure
I0920 05:14:43.622831    7432 command_runner.go:130] > # This file is a systemd drop-in unit that inherits from the base dockerd configuration.
I0920 05:14:43.622831    7432 command_runner.go:130] > # The base configuration already specifies an 'ExecStart=...' command. The first directive
I0920 05:14:43.622831    7432 command_runner.go:130] > # here is to clear out that command inherited from the base configuration. Without this,
I0920 05:14:43.622831    7432 command_runner.go:130] > # the command from the base configuration and the command specified here are treated as
I0920 05:14:43.622831    7432 command_runner.go:130] > # a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
I0920 05:14:43.622831    7432 command_runner.go:130] > # will catch this invalid input and refuse to start the service with an error like:
I0920 05:14:43.622831    7432 command_runner.go:130] > #  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.
I0920 05:14:43.622831    7432 command_runner.go:130] > # NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
I0920 05:14:43.622831    7432 command_runner.go:130] > # container runtimes. If left unlimited, it may result in OOM issues with MySQL.
I0920 05:14:43.622831    7432 command_runner.go:130] > ExecStart=
I0920 05:14:43.622831    7432 command_runner.go:130] > ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
I0920 05:14:43.622831    7432 command_runner.go:130] > ExecReload=/bin/kill -s HUP $MAINPID
I0920 05:14:43.622831    7432 command_runner.go:130] > # Having non-zero Limit*s causes performance problems due to accounting overhead
I0920 05:14:43.622831    7432 command_runner.go:130] > # in the kernel. We recommend using cgroups to do container-local accounting.
I0920 05:14:43.622831    7432 command_runner.go:130] > LimitNOFILE=infinity
I0920 05:14:43.622831    7432 command_runner.go:130] > LimitNPROC=infinity
I0920 05:14:43.622831    7432 command_runner.go:130] > LimitCORE=infinity
I0920 05:14:43.622831    7432 command_runner.go:130] > # Uncomment TasksMax if your systemd version supports it.
I0920 05:14:43.622831    7432 command_runner.go:130] > # Only systemd 226 and above support this version.
I0920 05:14:43.622831    7432 command_runner.go:130] > TasksMax=infinity
I0920 05:14:43.622831    7432 command_runner.go:130] > TimeoutStartSec=0
I0920 05:14:43.622831    7432 command_runner.go:130] > # set delegate yes so that systemd does not reset the cgroups of docker containers
I0920 05:14:43.622831    7432 command_runner.go:130] > Delegate=yes
I0920 05:14:43.622831    7432 command_runner.go:130] > # kill only the docker process, not all processes in the cgroup
I0920 05:14:43.622831    7432 command_runner.go:130] > KillMode=process
I0920 05:14:43.622831    7432 command_runner.go:130] > [Install]
I0920 05:14:43.622831    7432 command_runner.go:130] > WantedBy=multi-user.target
I0920 05:14:43.623337    7432 cruntime.go:273] skipping containerd shutdown because we are bound to it
I0920 05:14:43.630232    7432 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service crio
I0920 05:14:43.641493    7432 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %s "runtime-endpoint: unix:///var/run/cri-dockerd.sock
image-endpoint: unix:///var/run/cri-dockerd.sock
" | sudo tee /etc/crictl.yaml"
I0920 05:14:43.655817    7432 command_runner.go:130] > runtime-endpoint: unix:///var/run/cri-dockerd.sock
I0920 05:14:43.655817    7432 command_runner.go:130] > image-endpoint: unix:///var/run/cri-dockerd.sock
I0920 05:14:43.662650    7432 ssh_runner.go:195] Run: sudo systemctl unmask docker.service
I0920 05:14:43.760630    7432 ssh_runner.go:195] Run: sudo systemctl enable docker.socket
I0920 05:14:43.849347    7432 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0920 05:14:43.950450    7432 ssh_runner.go:195] Run: sudo systemctl restart docker
I0920 05:14:44.187372    7432 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I0920 05:14:44.197390    7432 command_runner.go:130] ! Created symlink /etc/systemd/system/sockets.target.wants/cri-docker.socket → /lib/systemd/system/cri-docker.socket.
I0920 05:14:44.279459    7432 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0920 05:14:44.379401    7432 ssh_runner.go:195] Run: sudo systemctl start cri-docker.socket
I0920 05:14:44.389400    7432 start.go:450] Will wait 60s for socket path /var/run/cri-dockerd.sock
I0920 05:14:44.407399    7432 ssh_runner.go:195] Run: stat /var/run/cri-dockerd.sock
I0920 05:14:44.411399    7432 command_runner.go:130] >   File: /var/run/cri-dockerd.sock
I0920 05:14:44.411399    7432 command_runner.go:130] >   Size: 0         	Blocks: 0          IO Block: 4096   socket
I0920 05:14:44.411399    7432 command_runner.go:130] > Device: 10001ah/1048602d	Inode: 136         Links: 1
I0920 05:14:44.411399    7432 command_runner.go:130] > Access: (0660/srw-rw----)  Uid: (    0/    root)   Gid: (  999/  docker)
I0920 05:14:44.411399    7432 command_runner.go:130] > Access: 2022-09-20 10:14:43.532362000 +0000
I0920 05:14:44.411399    7432 command_runner.go:130] > Modify: 2022-09-20 10:14:43.532362000 +0000
I0920 05:14:44.411399    7432 command_runner.go:130] > Change: 2022-09-20 10:14:43.532362000 +0000
I0920 05:14:44.411399    7432 command_runner.go:130] >  Birth: -
I0920 05:14:44.411399    7432 start.go:471] Will wait 60s for crictl version
I0920 05:14:44.418400    7432 ssh_runner.go:195] Run: sudo crictl version
I0920 05:14:44.445506    7432 command_runner.go:130] > Version:  0.1.0
I0920 05:14:44.445506    7432 command_runner.go:130] > RuntimeName:  docker
I0920 05:14:44.445506    7432 command_runner.go:130] > RuntimeVersion:  20.10.17
I0920 05:14:44.445506    7432 command_runner.go:130] > RuntimeApiVersion:  1.41.0
I0920 05:14:44.445506    7432 start.go:480] Version:  0.1.0
RuntimeName:  docker
RuntimeVersion:  20.10.17
RuntimeApiVersion:  1.41.0
I0920 05:14:44.456007    7432 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0920 05:14:44.487475    7432 command_runner.go:130] > 20.10.17
I0920 05:14:44.502680    7432 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0920 05:14:44.592632    7432 command_runner.go:130] > 20.10.17
I0920 05:14:44.599642    7432 out.go:204] * Preparing Kubernetes v1.24.3 on Docker 20.10.17 ...
I0920 05:14:44.612341    7432 cli_runner.go:164] Run: docker exec -t minikube dig +short host.docker.internal
I0920 05:14:44.875118    7432 network.go:96] got host ip for mount in container by digging dns: 192.168.65.2
I0920 05:14:44.893429    7432 ssh_runner.go:195] Run: grep 192.168.65.2	host.minikube.internal$ /etc/hosts
I0920 05:14:44.897809    7432 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\thost.minikube.internal$' "/etc/hosts"; echo "192.168.65.2	host.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0920 05:14:44.917911    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I0920 05:14:45.060548    7432 preload.go:132] Checking if preload exists for k8s version v1.24.3 and runtime docker
I0920 05:14:45.071108    7432 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0920 05:14:45.098334    7432 command_runner.go:130] > k8s.gcr.io/kube-apiserver:v1.24.3
I0920 05:14:45.098334    7432 command_runner.go:130] > k8s.gcr.io/kube-scheduler:v1.24.3
I0920 05:14:45.098334    7432 command_runner.go:130] > k8s.gcr.io/kube-controller-manager:v1.24.3
I0920 05:14:45.098334    7432 command_runner.go:130] > k8s.gcr.io/kube-proxy:v1.24.3
I0920 05:14:45.098334    7432 command_runner.go:130] > k8s.gcr.io/etcd:3.5.3-0
I0920 05:14:45.098334    7432 command_runner.go:130] > k8s.gcr.io/pause:3.7
I0920 05:14:45.098334    7432 command_runner.go:130] > k8s.gcr.io/coredns/coredns:v1.8.6
I0920 05:14:45.098334    7432 command_runner.go:130] > gcr.io/k8s-minikube/storage-provisioner:v5
I0920 05:14:45.099406    7432 docker.go:611] Got preloaded images: -- stdout --
k8s.gcr.io/kube-apiserver:v1.24.3
k8s.gcr.io/kube-scheduler:v1.24.3
k8s.gcr.io/kube-controller-manager:v1.24.3
k8s.gcr.io/kube-proxy:v1.24.3
k8s.gcr.io/etcd:3.5.3-0
k8s.gcr.io/pause:3.7
k8s.gcr.io/coredns/coredns:v1.8.6
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I0920 05:14:45.099406    7432 docker.go:542] Images already preloaded, skipping extraction
I0920 05:14:45.111418    7432 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0920 05:14:45.139083    7432 command_runner.go:130] > k8s.gcr.io/kube-apiserver:v1.24.3
I0920 05:14:45.139083    7432 command_runner.go:130] > k8s.gcr.io/kube-controller-manager:v1.24.3
I0920 05:14:45.139083    7432 command_runner.go:130] > k8s.gcr.io/kube-scheduler:v1.24.3
I0920 05:14:45.139083    7432 command_runner.go:130] > k8s.gcr.io/kube-proxy:v1.24.3
I0920 05:14:45.139083    7432 command_runner.go:130] > k8s.gcr.io/etcd:3.5.3-0
I0920 05:14:45.139083    7432 command_runner.go:130] > k8s.gcr.io/pause:3.7
I0920 05:14:45.139083    7432 command_runner.go:130] > k8s.gcr.io/coredns/coredns:v1.8.6
I0920 05:14:45.139083    7432 command_runner.go:130] > gcr.io/k8s-minikube/storage-provisioner:v5
I0920 05:14:45.140170    7432 docker.go:611] Got preloaded images: -- stdout --
k8s.gcr.io/kube-apiserver:v1.24.3
k8s.gcr.io/kube-controller-manager:v1.24.3
k8s.gcr.io/kube-scheduler:v1.24.3
k8s.gcr.io/kube-proxy:v1.24.3
k8s.gcr.io/etcd:3.5.3-0
k8s.gcr.io/pause:3.7
k8s.gcr.io/coredns/coredns:v1.8.6
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I0920 05:14:45.140170    7432 cache_images.go:84] Images are preloaded, skipping loading
I0920 05:14:45.151242    7432 ssh_runner.go:195] Run: docker info --format {{.CgroupDriver}}
I0920 05:14:45.219089    7432 command_runner.go:130] > cgroupfs
I0920 05:14:45.219089    7432 cni.go:95] Creating CNI manager for ""
I0920 05:14:45.219089    7432 cni.go:156] 1 nodes found, recommending kindnet
I0920 05:14:45.219089    7432 kubeadm.go:87] Using pod CIDR: 10.244.0.0/16
I0920 05:14:45.219089    7432 kubeadm.go:158] kubeadm options: {CertDir:/var/lib/minikube/certs ServiceCIDR:10.96.0.0/12 PodSubnet:10.244.0.0/16 AdvertiseAddress:192.168.49.2 APIServerPort:8443 KubernetesVersion:v1.24.3 EtcdDataDir:/var/lib/minikube/etcd EtcdExtraArgs:map[] ClusterName:minikube NodeName:minikube DNSDomain:cluster.local CRISocket:/var/run/cri-dockerd.sock ImageRepository: ComponentOptions:[{Component:apiServer ExtraArgs:map[enable-admission-plugins:NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota] Pairs:map[certSANs:["127.0.0.1", "localhost", "192.168.49.2"]]} {Component:controllerManager ExtraArgs:map[allocate-node-cidrs:true leader-elect:false] Pairs:map[]} {Component:scheduler ExtraArgs:map[leader-elect:false] Pairs:map[]}] FeatureArgs:map[] NoTaintMaster:true NodeIP:192.168.49.2 CgroupDriver:cgroupfs ClientCAFile:/var/lib/minikube/certs/ca.crt StaticPodPath:/etc/kubernetes/manifests ControlPlaneAddress:control-plane.minikube.internal KubeProxyOptions:map[]}
I0920 05:14:45.219089    7432 kubeadm.go:162] kubeadm config:
apiVersion: kubeadm.k8s.io/v1beta3
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.49.2
  bindPort: 8443
bootstrapTokens:
  - groups:
      - system:bootstrappers:kubeadm:default-node-token
    ttl: 24h0m0s
    usages:
      - signing
      - authentication
nodeRegistration:
  criSocket: /var/run/cri-dockerd.sock
  name: "minikube"
  kubeletExtraArgs:
    node-ip: 192.168.49.2
  taints: []
---
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
apiServer:
  certSANs: ["127.0.0.1", "localhost", "192.168.49.2"]
  extraArgs:
    enable-admission-plugins: "NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota"
controllerManager:
  extraArgs:
    allocate-node-cidrs: "true"
    leader-elect: "false"
scheduler:
  extraArgs:
    leader-elect: "false"
certificatesDir: /var/lib/minikube/certs
clusterName: mk
controlPlaneEndpoint: control-plane.minikube.internal:8443
etcd:
  local:
    dataDir: /var/lib/minikube/etcd
    extraArgs:
      proxy-refresh-interval: "70000"
kubernetesVersion: v1.24.3
networking:
  dnsDomain: cluster.local
  podSubnet: "10.244.0.0/16"
  serviceSubnet: 10.96.0.0/12
---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
authentication:
  x509:
    clientCAFile: /var/lib/minikube/certs/ca.crt
cgroupDriver: cgroupfs
clusterDomain: "cluster.local"
# disable disk resource management by default
imageGCHighThresholdPercent: 100
evictionHard:
  nodefs.available: "0%"
  nodefs.inodesFree: "0%"
  imagefs.available: "0%"
failSwapOn: false
staticPodPath: /etc/kubernetes/manifests
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
clusterCIDR: "10.244.0.0/16"
metricsBindAddress: 0.0.0.0:10249
conntrack:
  maxPerCore: 0
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_established"
  tcpEstablishedTimeout: 0s
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_close"
  tcpCloseWaitTimeout: 0s

I0920 05:14:45.219619    7432 kubeadm.go:961] kubelet [Unit]
Wants=docker.socket

[Service]
ExecStart=
ExecStart=/var/lib/minikube/binaries/v1.24.3/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --config=/var/lib/kubelet/config.yaml --container-runtime=remote --container-runtime-endpoint=/var/run/cri-dockerd.sock --hostname-override=minikube --image-service-endpoint=/var/run/cri-dockerd.sock --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=192.168.49.2 --runtime-request-timeout=15m

[Install]
 config:
{KubernetesVersion:v1.24.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:}
I0920 05:14:45.226502    7432 ssh_runner.go:195] Run: sudo ls /var/lib/minikube/binaries/v1.24.3
I0920 05:14:45.235641    7432 command_runner.go:130] > kubeadm
I0920 05:14:45.235641    7432 command_runner.go:130] > kubectl
I0920 05:14:45.235641    7432 command_runner.go:130] > kubelet
I0920 05:14:45.236147    7432 binaries.go:44] Found k8s binaries, skipping transfer
I0920 05:14:45.242521    7432 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/kubelet.service.d /lib/systemd/system /var/tmp/minikube
I0920 05:14:45.250973    7432 ssh_runner.go:362] scp memory --> /etc/systemd/system/kubelet.service.d/10-kubeadm.conf (470 bytes)
I0920 05:14:45.264679    7432 ssh_runner.go:362] scp memory --> /lib/systemd/system/kubelet.service (352 bytes)
I0920 05:14:45.278942    7432 ssh_runner.go:362] scp memory --> /var/tmp/minikube/kubeadm.yaml.new (2031 bytes)
I0920 05:14:45.310933    7432 ssh_runner.go:195] Run: grep 192.168.49.2	control-plane.minikube.internal$ /etc/hosts
I0920 05:14:45.315834    7432 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\tcontrol-plane.minikube.internal$' "/etc/hosts"; echo "192.168.49.2	control-plane.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0920 05:14:45.325833    7432 certs.go:54] Setting up C:\Users\Esteban\.minikube\profiles\minikube for IP: 192.168.49.2
I0920 05:14:45.326359    7432 certs.go:182] skipping minikubeCA CA generation: C:\Users\Esteban\.minikube\ca.key
I0920 05:14:45.326359    7432 certs.go:182] skipping proxyClientCA CA generation: C:\Users\Esteban\.minikube\proxy-client-ca.key
I0920 05:14:45.326863    7432 certs.go:302] generating minikube-user signed cert: C:\Users\Esteban\.minikube\profiles\minikube\client.key
I0920 05:14:45.326879    7432 crypto.go:68] Generating cert C:\Users\Esteban\.minikube\profiles\minikube\client.crt with IP's: []
I0920 05:14:45.640501    7432 crypto.go:156] Writing cert to C:\Users\Esteban\.minikube\profiles\minikube\client.crt ...
I0920 05:14:45.640501    7432 lock.go:35] WriteFile acquiring C:\Users\Esteban\.minikube\profiles\minikube\client.crt: {Name:mkeb516ac61b6281ea785e28af2ac8a5a8ed3d98 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0920 05:14:45.641502    7432 crypto.go:164] Writing key to C:\Users\Esteban\.minikube\profiles\minikube\client.key ...
I0920 05:14:45.641502    7432 lock.go:35] WriteFile acquiring C:\Users\Esteban\.minikube\profiles\minikube\client.key: {Name:mkcd9ffc8b0fe78d562825c8c08bfaa3e8e906e2 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0920 05:14:45.641502    7432 certs.go:302] generating minikube signed cert: C:\Users\Esteban\.minikube\profiles\minikube\apiserver.key.dd3b5fb2
I0920 05:14:45.641502    7432 crypto.go:68] Generating cert C:\Users\Esteban\.minikube\profiles\minikube\apiserver.crt.dd3b5fb2 with IP's: [192.168.49.2 10.96.0.1 127.0.0.1 10.0.0.1]
I0920 05:14:45.773053    7432 crypto.go:156] Writing cert to C:\Users\Esteban\.minikube\profiles\minikube\apiserver.crt.dd3b5fb2 ...
I0920 05:14:45.773053    7432 lock.go:35] WriteFile acquiring C:\Users\Esteban\.minikube\profiles\minikube\apiserver.crt.dd3b5fb2: {Name:mk955cc16007eb4127e73f3001c31676541b7e16 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0920 05:14:45.773053    7432 crypto.go:164] Writing key to C:\Users\Esteban\.minikube\profiles\minikube\apiserver.key.dd3b5fb2 ...
I0920 05:14:45.773053    7432 lock.go:35] WriteFile acquiring C:\Users\Esteban\.minikube\profiles\minikube\apiserver.key.dd3b5fb2: {Name:mkab9f8727af11a00b584272e660bc8301e36411 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0920 05:14:45.774054    7432 certs.go:320] copying C:\Users\Esteban\.minikube\profiles\minikube\apiserver.crt.dd3b5fb2 -> C:\Users\Esteban\.minikube\profiles\minikube\apiserver.crt
I0920 05:14:45.785052    7432 certs.go:324] copying C:\Users\Esteban\.minikube\profiles\minikube\apiserver.key.dd3b5fb2 -> C:\Users\Esteban\.minikube\profiles\minikube\apiserver.key
I0920 05:14:45.786067    7432 certs.go:302] generating aggregator signed cert: C:\Users\Esteban\.minikube\profiles\minikube\proxy-client.key
I0920 05:14:45.786067    7432 crypto.go:68] Generating cert C:\Users\Esteban\.minikube\profiles\minikube\proxy-client.crt with IP's: []
I0920 05:14:45.895054    7432 crypto.go:156] Writing cert to C:\Users\Esteban\.minikube\profiles\minikube\proxy-client.crt ...
I0920 05:14:45.895054    7432 lock.go:35] WriteFile acquiring C:\Users\Esteban\.minikube\profiles\minikube\proxy-client.crt: {Name:mk3a9d72c7e119b06db26901de5540eb12d6af31 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0920 05:14:45.896053    7432 crypto.go:164] Writing key to C:\Users\Esteban\.minikube\profiles\minikube\proxy-client.key ...
I0920 05:14:45.896053    7432 lock.go:35] WriteFile acquiring C:\Users\Esteban\.minikube\profiles\minikube\proxy-client.key: {Name:mkcd342358400afe54770e5084d88814f41d4f90 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0920 05:14:45.897056    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\profiles\minikube\apiserver.crt -> /var/lib/minikube/certs/apiserver.crt
I0920 05:14:45.897056    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\profiles\minikube\apiserver.key -> /var/lib/minikube/certs/apiserver.key
I0920 05:14:45.897056    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\profiles\minikube\proxy-client.crt -> /var/lib/minikube/certs/proxy-client.crt
I0920 05:14:45.900052    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\profiles\minikube\proxy-client.key -> /var/lib/minikube/certs/proxy-client.key
I0920 05:14:45.901052    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\ca.crt -> /var/lib/minikube/certs/ca.crt
I0920 05:14:45.901052    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\ca.key -> /var/lib/minikube/certs/ca.key
I0920 05:14:45.902053    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\proxy-client-ca.crt -> /var/lib/minikube/certs/proxy-client-ca.crt
I0920 05:14:45.902053    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\proxy-client-ca.key -> /var/lib/minikube/certs/proxy-client-ca.key
I0920 05:14:45.902053    7432 certs.go:388] found cert: C:\Users\Esteban\.minikube\certs\C:\Users\Esteban\.minikube\certs\ca-key.pem (1675 bytes)
I0920 05:14:45.902053    7432 certs.go:388] found cert: C:\Users\Esteban\.minikube\certs\C:\Users\Esteban\.minikube\certs\ca.pem (1082 bytes)
I0920 05:14:45.902053    7432 certs.go:388] found cert: C:\Users\Esteban\.minikube\certs\C:\Users\Esteban\.minikube\certs\cert.pem (1123 bytes)
I0920 05:14:45.902053    7432 certs.go:388] found cert: C:\Users\Esteban\.minikube\certs\C:\Users\Esteban\.minikube\certs\key.pem (1679 bytes)
I0920 05:14:45.902053    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\ca.crt -> /usr/share/ca-certificates/minikubeCA.pem
I0920 05:14:45.903052    7432 ssh_runner.go:362] scp C:\Users\Esteban\.minikube\profiles\minikube\apiserver.crt --> /var/lib/minikube/certs/apiserver.crt (1399 bytes)
I0920 05:14:45.923554    7432 ssh_runner.go:362] scp C:\Users\Esteban\.minikube\profiles\minikube\apiserver.key --> /var/lib/minikube/certs/apiserver.key (1679 bytes)
I0920 05:14:45.945065    7432 ssh_runner.go:362] scp C:\Users\Esteban\.minikube\profiles\minikube\proxy-client.crt --> /var/lib/minikube/certs/proxy-client.crt (1147 bytes)
I0920 05:14:45.964737    7432 ssh_runner.go:362] scp C:\Users\Esteban\.minikube\profiles\minikube\proxy-client.key --> /var/lib/minikube/certs/proxy-client.key (1675 bytes)
I0920 05:14:45.987292    7432 ssh_runner.go:362] scp C:\Users\Esteban\.minikube\ca.crt --> /var/lib/minikube/certs/ca.crt (1111 bytes)
I0920 05:14:46.006922    7432 ssh_runner.go:362] scp C:\Users\Esteban\.minikube\ca.key --> /var/lib/minikube/certs/ca.key (1675 bytes)
I0920 05:14:46.026021    7432 ssh_runner.go:362] scp C:\Users\Esteban\.minikube\proxy-client-ca.crt --> /var/lib/minikube/certs/proxy-client-ca.crt (1119 bytes)
I0920 05:14:46.045225    7432 ssh_runner.go:362] scp C:\Users\Esteban\.minikube\proxy-client-ca.key --> /var/lib/minikube/certs/proxy-client-ca.key (1675 bytes)
I0920 05:14:46.065112    7432 ssh_runner.go:362] scp C:\Users\Esteban\.minikube\ca.crt --> /usr/share/ca-certificates/minikubeCA.pem (1111 bytes)
I0920 05:14:46.085277    7432 ssh_runner.go:362] scp memory --> /var/lib/minikube/kubeconfig (738 bytes)
I0920 05:14:46.105499    7432 ssh_runner.go:195] Run: openssl version
I0920 05:14:46.111397    7432 command_runner.go:130] > OpenSSL 1.1.1f  31 Mar 2020
I0920 05:14:46.118371    7432 ssh_runner.go:195] Run: sudo /bin/bash -c "test -s /usr/share/ca-certificates/minikubeCA.pem && ln -fs /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem"
I0920 05:14:46.133461    7432 ssh_runner.go:195] Run: ls -la /usr/share/ca-certificates/minikubeCA.pem
I0920 05:14:46.137177    7432 command_runner.go:130] > -rw-r--r-- 1 root root 1111 Sep 20 09:09 /usr/share/ca-certificates/minikubeCA.pem
I0920 05:14:46.137177    7432 certs.go:431] hashing: -rw-r--r-- 1 root root 1111 Sep 20 09:09 /usr/share/ca-certificates/minikubeCA.pem
I0920 05:14:46.144602    7432 ssh_runner.go:195] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
I0920 05:14:46.149912    7432 command_runner.go:130] > b5213941
I0920 05:14:46.156781    7432 ssh_runner.go:195] Run: sudo /bin/bash -c "test -L /etc/ssl/certs/b5213941.0 || ln -fs /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0"
I0920 05:14:46.165176    7432 kubeadm.go:395] StartCluster: {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 Memory:2200 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.24.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.24.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:true ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:C:\Users\Esteban:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath:}
I0920 05:14:46.176329    7432 ssh_runner.go:195] Run: docker ps --filter status=paused --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I0920 05:14:46.211240    7432 ssh_runner.go:195] Run: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd
I0920 05:14:46.219362    7432 command_runner.go:130] ! ls: cannot access '/var/lib/kubelet/kubeadm-flags.env': No such file or directory
I0920 05:14:46.219362    7432 command_runner.go:130] ! ls: cannot access '/var/lib/kubelet/config.yaml': No such file or directory
I0920 05:14:46.219362    7432 command_runner.go:130] ! ls: cannot access '/var/lib/minikube/etcd': No such file or directory
I0920 05:14:46.227242    7432 ssh_runner.go:195] Run: sudo cp /var/tmp/minikube/kubeadm.yaml.new /var/tmp/minikube/kubeadm.yaml
I0920 05:14:46.235204    7432 kubeadm.go:221] ignoring SystemVerification for kubeadm because of docker driver
I0920 05:14:46.242045    7432 ssh_runner.go:195] Run: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf
I0920 05:14:46.250115    7432 command_runner.go:130] ! ls: cannot access '/etc/kubernetes/admin.conf': No such file or directory
I0920 05:14:46.250115    7432 command_runner.go:130] ! ls: cannot access '/etc/kubernetes/kubelet.conf': No such file or directory
I0920 05:14:46.250115    7432 command_runner.go:130] ! ls: cannot access '/etc/kubernetes/controller-manager.conf': No such file or directory
I0920 05:14:46.250115    7432 command_runner.go:130] ! ls: cannot access '/etc/kubernetes/scheduler.conf': No such file or directory
I0920 05:14:46.251162    7432 kubeadm.go:152] config check failed, skipping stale config cleanup: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf: Process exited with status 2
stdout:

stderr:
ls: cannot access '/etc/kubernetes/admin.conf': No such file or directory
ls: cannot access '/etc/kubernetes/kubelet.conf': No such file or directory
ls: cannot access '/etc/kubernetes/controller-manager.conf': No such file or directory
ls: cannot access '/etc/kubernetes/scheduler.conf': No such file or directory
I0920 05:14:46.251162    7432 ssh_runner.go:286] Start: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.24.3:$PATH" kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap,Mem,SystemVerification,FileContent--proc-sys-net-bridge-bridge-nf-call-iptables"
I0920 05:14:46.284838    7432 command_runner.go:130] ! W0920 10:14:46.283725    1196 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme "unix" to the "criSocket" with value "/var/run/cri-dockerd.sock". Please update your configuration!
I0920 05:14:46.317429    7432 command_runner.go:130] ! 	[WARNING Swap]: swap is enabled; production deployments should disable swap unless testing the NodeSwap feature gate of the kubelet
I0920 05:14:46.379606    7432 command_runner.go:130] ! 	[WARNING Service-Kubelet]: kubelet service is not enabled, please run 'systemctl enable kubelet.service'
I0920 05:15:04.472597    7432 command_runner.go:130] > [init] Using Kubernetes version: v1.24.3
I0920 05:15:04.472597    7432 command_runner.go:130] > [preflight] Running pre-flight checks
I0920 05:15:04.472597    7432 command_runner.go:130] > [preflight] Pulling images required for setting up a Kubernetes cluster
I0920 05:15:04.473133    7432 command_runner.go:130] > [preflight] This might take a minute or two, depending on the speed of your internet connection
I0920 05:15:04.473133    7432 command_runner.go:130] > [preflight] You can also perform this action in beforehand using 'kubeadm config images pull'
I0920 05:15:04.475246    7432 out.go:204]   - Generating certificates and keys ...
I0920 05:15:04.473133    7432 command_runner.go:130] > [certs] Using certificateDir folder "/var/lib/minikube/certs"
I0920 05:15:04.475246    7432 command_runner.go:130] > [certs] Using existing ca certificate authority
I0920 05:15:04.475246    7432 command_runner.go:130] > [certs] Using existing apiserver certificate and key on disk
I0920 05:15:04.475777    7432 command_runner.go:130] > [certs] Generating "apiserver-kubelet-client" certificate and key
I0920 05:15:04.475777    7432 command_runner.go:130] > [certs] Generating "front-proxy-ca" certificate and key
I0920 05:15:04.475777    7432 command_runner.go:130] > [certs] Generating "front-proxy-client" certificate and key
I0920 05:15:04.475777    7432 command_runner.go:130] > [certs] Generating "etcd/ca" certificate and key
I0920 05:15:04.475777    7432 command_runner.go:130] > [certs] Generating "etcd/server" certificate and key
I0920 05:15:04.475777    7432 command_runner.go:130] > [certs] etcd/server serving cert is signed for DNS names [localhost minikube] and IPs [192.168.49.2 127.0.0.1 ::1]
I0920 05:15:04.475777    7432 command_runner.go:130] > [certs] Generating "etcd/peer" certificate and key
I0920 05:15:04.476313    7432 command_runner.go:130] > [certs] etcd/peer serving cert is signed for DNS names [localhost minikube] and IPs [192.168.49.2 127.0.0.1 ::1]
I0920 05:15:04.476313    7432 command_runner.go:130] > [certs] Generating "etcd/healthcheck-client" certificate and key
I0920 05:15:04.476313    7432 command_runner.go:130] > [certs] Generating "apiserver-etcd-client" certificate and key
I0920 05:15:04.476313    7432 command_runner.go:130] > [certs] Generating "sa" key and public key
I0920 05:15:04.476313    7432 command_runner.go:130] > [kubeconfig] Using kubeconfig folder "/etc/kubernetes"
I0920 05:15:04.476313    7432 command_runner.go:130] > [kubeconfig] Writing "admin.conf" kubeconfig file
I0920 05:15:04.476313    7432 command_runner.go:130] > [kubeconfig] Writing "kubelet.conf" kubeconfig file
I0920 05:15:04.476313    7432 command_runner.go:130] > [kubeconfig] Writing "controller-manager.conf" kubeconfig file
I0920 05:15:04.476313    7432 command_runner.go:130] > [kubeconfig] Writing "scheduler.conf" kubeconfig file
I0920 05:15:04.476850    7432 command_runner.go:130] > [kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
I0920 05:15:04.476850    7432 command_runner.go:130] > [kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
I0920 05:15:04.476850    7432 command_runner.go:130] > [kubelet-start] Starting the kubelet
I0920 05:15:04.476850    7432 command_runner.go:130] > [control-plane] Using manifest folder "/etc/kubernetes/manifests"
I0920 05:15:04.479004    7432 out.go:204]   - Booting up control plane ...
I0920 05:15:04.479004    7432 command_runner.go:130] > [control-plane] Creating static Pod manifest for "kube-apiserver"
I0920 05:15:04.479004    7432 command_runner.go:130] > [control-plane] Creating static Pod manifest for "kube-controller-manager"
I0920 05:15:04.479004    7432 command_runner.go:130] > [control-plane] Creating static Pod manifest for "kube-scheduler"
I0920 05:15:04.479004    7432 command_runner.go:130] > [etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests"
I0920 05:15:04.479553    7432 command_runner.go:130] > [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory "/etc/kubernetes/manifests". This can take up to 4m0s
I0920 05:15:04.479553    7432 command_runner.go:130] > [apiclient] All control plane components are healthy after 14.503840 seconds
I0920 05:15:04.479553    7432 command_runner.go:130] > [upload-config] Storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace
I0920 05:15:04.479553    7432 command_runner.go:130] > [kubelet] Creating a ConfigMap "kubelet-config" in namespace kube-system with the configuration for the kubelets in the cluster
I0920 05:15:04.479553    7432 command_runner.go:130] > [upload-certs] Skipping phase. Please see --upload-certs
I0920 05:15:04.479553    7432 command_runner.go:130] > [mark-control-plane] Marking the node minikube as control-plane by adding the labels: [node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]
I0920 05:15:04.482820    7432 out.go:204]   - Configuring RBAC rules ...
I0920 05:15:04.480062    7432 command_runner.go:130] > [bootstrap-token] Using token: z0s297.w6ob0b9gtme8rn28
I0920 05:15:04.482820    7432 command_runner.go:130] > [bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
I0920 05:15:04.483365    7432 command_runner.go:130] > [bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to get nodes
I0920 05:15:04.483365    7432 command_runner.go:130] > [bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
I0920 05:15:04.483365    7432 command_runner.go:130] > [bootstrap-token] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
I0920 05:15:04.483365    7432 command_runner.go:130] > [bootstrap-token] Configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
I0920 05:15:04.483365    7432 command_runner.go:130] > [bootstrap-token] Creating the "cluster-info" ConfigMap in the "kube-public" namespace
I0920 05:15:04.483878    7432 command_runner.go:130] > [kubelet-finalize] Updating "/etc/kubernetes/kubelet.conf" to point to a rotatable kubelet client certificate and key
I0920 05:15:04.483878    7432 command_runner.go:130] > [addons] Applied essential addon: CoreDNS
I0920 05:15:04.483878    7432 command_runner.go:130] > [addons] Applied essential addon: kube-proxy
I0920 05:15:04.483878    7432 command_runner.go:130] > Your Kubernetes control-plane has initialized successfully!
I0920 05:15:04.483878    7432 command_runner.go:130] > To start using your cluster, you need to run the following as a regular user:
I0920 05:15:04.483878    7432 command_runner.go:130] >   mkdir -p $HOME/.kube
I0920 05:15:04.483878    7432 command_runner.go:130] >   sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
I0920 05:15:04.483878    7432 command_runner.go:130] >   sudo chown $(id -u):$(id -g) $HOME/.kube/config
I0920 05:15:04.484402    7432 command_runner.go:130] > Alternatively, if you are the root user, you can run:
I0920 05:15:04.484402    7432 command_runner.go:130] >   export KUBECONFIG=/etc/kubernetes/admin.conf
I0920 05:15:04.484402    7432 command_runner.go:130] > You should now deploy a pod network to the cluster.
I0920 05:15:04.484402    7432 command_runner.go:130] > Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
I0920 05:15:04.484402    7432 command_runner.go:130] >   https://kubernetes.io/docs/concepts/cluster-administration/addons/
I0920 05:15:04.484402    7432 command_runner.go:130] > You can now join any number of control-plane nodes by copying certificate authorities
I0920 05:15:04.484402    7432 command_runner.go:130] > and service account keys on each node and then running the following as root:
I0920 05:15:04.484923    7432 command_runner.go:130] >   kubeadm join control-plane.minikube.internal:8443 --token z0s297.w6ob0b9gtme8rn28 \
I0920 05:15:04.484923    7432 command_runner.go:130] > 	--discovery-token-ca-cert-hash sha256:73202b2265c3b3018d12119f3c78685654b918967fd5f268db3bf3b4d7e92013 \
I0920 05:15:04.484923    7432 command_runner.go:130] > 	--control-plane 
I0920 05:15:04.484923    7432 command_runner.go:130] > Then you can join any number of worker nodes by running the following on each as root:
I0920 05:15:04.484923    7432 command_runner.go:130] > kubeadm join control-plane.minikube.internal:8443 --token z0s297.w6ob0b9gtme8rn28 \
I0920 05:15:04.484923    7432 command_runner.go:130] > 	--discovery-token-ca-cert-hash sha256:73202b2265c3b3018d12119f3c78685654b918967fd5f268db3bf3b4d7e92013 
I0920 05:15:04.484923    7432 cni.go:95] Creating CNI manager for ""
I0920 05:15:04.484923    7432 cni.go:156] 1 nodes found, recommending kindnet
I0920 05:15:04.489200    7432 out.go:177] * Configuring CNI (Container Networking Interface) ...
I0920 05:15:04.507926    7432 ssh_runner.go:195] Run: stat /opt/cni/bin/portmap
I0920 05:15:04.536178    7432 command_runner.go:130] >   File: /opt/cni/bin/portmap
I0920 05:15:04.536178    7432 command_runner.go:130] >   Size: 2828728   	Blocks: 5528       IO Block: 4096   regular file
I0920 05:15:04.536178    7432 command_runner.go:130] > Device: 100011h/1048593d	Inode: 98512       Links: 1
I0920 05:15:04.536178    7432 command_runner.go:130] > Access: (0755/-rwxr-xr-x)  Uid: (    0/    root)   Gid: (    0/    root)
I0920 05:15:04.536178    7432 command_runner.go:130] > Access: 2022-05-18 18:39:21.000000000 +0000
I0920 05:15:04.536178    7432 command_runner.go:130] > Modify: 2022-05-18 18:39:21.000000000 +0000
I0920 05:15:04.536178    7432 command_runner.go:130] > Change: 2022-09-20 09:07:54.348968000 +0000
I0920 05:15:04.536178    7432 command_runner.go:130] >  Birth: -
I0920 05:15:04.536178    7432 cni.go:189] applying CNI manifest using /var/lib/minikube/binaries/v1.24.3/kubectl ...
I0920 05:15:04.536178    7432 ssh_runner.go:362] scp memory --> /var/tmp/minikube/cni.yaml (2429 bytes)
I0920 05:15:04.563392    7432 ssh_runner.go:195] Run: sudo /var/lib/minikube/binaries/v1.24.3/kubectl apply --kubeconfig=/var/lib/minikube/kubeconfig -f /var/tmp/minikube/cni.yaml
I0920 05:15:05.971862    7432 command_runner.go:130] > clusterrole.rbac.authorization.k8s.io/kindnet created
I0920 05:15:05.971862    7432 command_runner.go:130] > clusterrolebinding.rbac.authorization.k8s.io/kindnet created
I0920 05:15:05.971862    7432 command_runner.go:130] > serviceaccount/kindnet created
I0920 05:15:05.971862    7432 command_runner.go:130] > daemonset.apps/kindnet created
I0920 05:15:05.971862    7432 ssh_runner.go:235] Completed: sudo /var/lib/minikube/binaries/v1.24.3/kubectl apply --kubeconfig=/var/lib/minikube/kubeconfig -f /var/tmp/minikube/cni.yaml: (1.4084694s)
I0920 05:15:05.971862    7432 ssh_runner.go:195] Run: /bin/bash -c "cat /proc/$(pgrep kube-apiserver)/oom_adj"
I0920 05:15:05.979444    7432 command_runner.go:130] > -16
I0920 05:15:05.979444    7432 ops.go:34] apiserver oom_adj: -16
I0920 05:15:05.981043    7432 ssh_runner.go:195] Run: sudo /var/lib/minikube/binaries/v1.24.3/kubectl label nodes minikube.k8s.io/version=v1.26.1 minikube.k8s.io/commit=62e108c3dfdec8029a890ad6d8ef96b6461426dc minikube.k8s.io/name=minikube minikube.k8s.io/updated_at=2022_09_20T05_15_05_0700 minikube.k8s.io/primary=true --all --overwrite --kubeconfig=/var/lib/minikube/kubeconfig
I0920 05:15:05.982640    7432 ssh_runner.go:195] Run: sudo /var/lib/minikube/binaries/v1.24.3/kubectl create clusterrolebinding minikube-rbac --clusterrole=cluster-admin --serviceaccount=kube-system:default --kubeconfig=/var/lib/minikube/kubeconfig
I0920 05:15:06.049413    7432 command_runner.go:130] > node/minikube labeled
I0920 05:15:06.049413    7432 command_runner.go:130] > clusterrolebinding.rbac.authorization.k8s.io/minikube-rbac created
I0920 05:15:06.049413    7432 kubeadm.go:1045] duration metric: took 77.5511ms to wait for elevateKubeSystemPrivileges.
I0920 05:15:06.049413    7432 kubeadm.go:397] StartCluster complete in 19.884237s
I0920 05:15:06.049413    7432 settings.go:142] acquiring lock: {Name:mkde5d9e1a0e909149121562a1b3a53757a9972f Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0920 05:15:06.049413    7432 settings.go:150] Updating kubeconfig:  C:\Users\Esteban\.kube\config
I0920 05:15:06.049941    7432 lock.go:35] WriteFile acquiring C:\Users\Esteban\.kube\config: {Name:mk4c8b40f2da3a85ca70096479e8c468d096d99f Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0920 05:15:06.055746    7432 loader.go:372] Config loaded from file:  C:\Users\Esteban\.kube\config
I0920 05:15:06.056276    7432 kapi.go:59] client config for minikube: &rest.Config{Host:"https://127.0.0.1:55725", APIPath:"", ContentConfig:rest.ContentConfig{AcceptContentTypes:"", ContentType:"", GroupVersion:(*schema.GroupVersion)(nil), NegotiatedSerializer:runtime.NegotiatedSerializer(nil)}, Username:"", Password:"", BearerToken:"", BearerTokenFile:"", Impersonate:rest.ImpersonationConfig{UserName:"", UID:"", Groups:[]string(nil), Extra:map[string][]string(nil)}, AuthProvider:<nil>, AuthConfigPersister:rest.AuthProviderConfigPersister(nil), ExecProvider:<nil>, TLSClientConfig:rest.sanitizedTLSClientConfig{Insecure:false, ServerName:"", CertFile:"C:\\Users\\Esteban\\.minikube\\profiles\\minikube\\client.crt", KeyFile:"C:\\Users\\Esteban\\.minikube\\profiles\\minikube\\client.key", CAFile:"C:\\Users\\Esteban\\.minikube\\ca.crt", CertData:[]uint8(nil), KeyData:[]uint8(nil), CAData:[]uint8(nil), NextProtos:[]string(nil)}, UserAgent:"", DisableCompression:false, Transport:http.RoundTripper(nil), WrapTransport:(transport.WrapperFunc)(0x1803b20), QPS:0, Burst:0, RateLimiter:flowcontrol.RateLimiter(nil), WarningHandler:rest.WarningHandler(nil), Timeout:0, Dial:(func(context.Context, string, string) (net.Conn, error))(nil), Proxy:(func(*http.Request) (*url.URL, error))(nil)}
I0920 05:15:06.056798    7432 cert_rotation.go:137] Starting client certificate rotation controller
I0920 05:15:06.057304    7432 round_trippers.go:466] curl -v -XGET  -H "Accept: application/json, */*" -H "User-Agent: minikube.exe/v0.0.0 (windows/amd64) kubernetes/$Format" 'https://127.0.0.1:55725/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale'
I0920 05:15:06.057323    7432 round_trippers.go:510] HTTP Trace: Dial to tcp:127.0.0.1:55725 succeed
I0920 05:15:06.068772    7432 round_trippers.go:553] GET https://127.0.0.1:55725/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale 200 OK in 11 milliseconds
I0920 05:15:06.068772    7432 round_trippers.go:570] HTTP Statistics: DNSLookup 0 ms Dial 0 ms TLSHandshake 8 ms ServerProcessing 3 ms Duration 11 ms
I0920 05:15:06.068772    7432 round_trippers.go:577] Response Headers:
I0920 05:15:06.068772    7432 round_trippers.go:580]     X-Kubernetes-Pf-Flowschema-Uid: 02cd4939-01f5-4b09-a0a9-02b620700246
I0920 05:15:06.068772    7432 round_trippers.go:580]     X-Kubernetes-Pf-Prioritylevel-Uid: fd684f0e-e7d0-4d27-979b-454254971228
I0920 05:15:06.068772    7432 round_trippers.go:580]     Content-Length: 291
I0920 05:15:06.068772    7432 round_trippers.go:580]     Date: Tue, 20 Sep 2022 10:15:06 GMT
I0920 05:15:06.068772    7432 round_trippers.go:580]     Audit-Id: a743f7cb-9130-418d-879d-6bd46e3f1b52
I0920 05:15:06.068772    7432 round_trippers.go:580]     Cache-Control: no-cache, private
I0920 05:15:06.068772    7432 round_trippers.go:580]     Content-Type: application/json
I0920 05:15:06.068772    7432 request.go:1073] Response Body: {"kind":"Scale","apiVersion":"autoscaling/v1","metadata":{"name":"coredns","namespace":"kube-system","uid":"8c3d174c-c040-4e0d-b8c3-3c7403b16914","resourceVersion":"236","creationTimestamp":"2022-09-20T10:15:04Z"},"spec":{"replicas":2},"status":{"replicas":0,"selector":"k8s-app=kube-dns"}}
I0920 05:15:06.069299    7432 request.go:1073] Request Body: {"kind":"Scale","apiVersion":"autoscaling/v1","metadata":{"name":"coredns","namespace":"kube-system","uid":"8c3d174c-c040-4e0d-b8c3-3c7403b16914","resourceVersion":"236","creationTimestamp":"2022-09-20T10:15:04Z"},"spec":{"replicas":1},"status":{"replicas":0,"selector":"k8s-app=kube-dns"}}
I0920 05:15:06.069299    7432 round_trippers.go:466] curl -v -XPUT  -H "Accept: application/json, */*" -H "Content-Type: application/json" -H "User-Agent: minikube.exe/v0.0.0 (windows/amd64) kubernetes/$Format" 'https://127.0.0.1:55725/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale'
I0920 05:15:06.073032    7432 round_trippers.go:553] PUT https://127.0.0.1:55725/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale 200 OK in 3 milliseconds
I0920 05:15:06.073032    7432 round_trippers.go:570] HTTP Statistics: GetConnection 0 ms ServerProcessing 3 ms Duration 3 ms
I0920 05:15:06.073032    7432 round_trippers.go:577] Response Headers:
I0920 05:15:06.073032    7432 round_trippers.go:580]     Date: Tue, 20 Sep 2022 10:15:06 GMT
I0920 05:15:06.073032    7432 round_trippers.go:580]     Audit-Id: a89a94c4-c286-453f-922f-a32ef312494c
I0920 05:15:06.073032    7432 round_trippers.go:580]     Cache-Control: no-cache, private
I0920 05:15:06.073032    7432 round_trippers.go:580]     Content-Type: application/json
I0920 05:15:06.073032    7432 round_trippers.go:580]     X-Kubernetes-Pf-Flowschema-Uid: 02cd4939-01f5-4b09-a0a9-02b620700246
I0920 05:15:06.073032    7432 round_trippers.go:580]     X-Kubernetes-Pf-Prioritylevel-Uid: fd684f0e-e7d0-4d27-979b-454254971228
I0920 05:15:06.073032    7432 round_trippers.go:580]     Content-Length: 291
I0920 05:15:06.073032    7432 request.go:1073] Response Body: {"kind":"Scale","apiVersion":"autoscaling/v1","metadata":{"name":"coredns","namespace":"kube-system","uid":"8c3d174c-c040-4e0d-b8c3-3c7403b16914","resourceVersion":"268","creationTimestamp":"2022-09-20T10:15:04Z"},"spec":{"replicas":1},"status":{"replicas":0,"selector":"k8s-app=kube-dns"}}
I0920 05:15:06.582251    7432 round_trippers.go:466] curl -v -XGET  -H "Accept: application/json, */*" -H "User-Agent: minikube.exe/v0.0.0 (windows/amd64) kubernetes/$Format" 'https://127.0.0.1:55725/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale'
I0920 05:15:06.585787    7432 round_trippers.go:553] GET https://127.0.0.1:55725/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale 200 OK in 3 milliseconds
I0920 05:15:06.585787    7432 round_trippers.go:570] HTTP Statistics: GetConnection 0 ms ServerProcessing 3 ms Duration 3 ms
I0920 05:15:06.585787    7432 round_trippers.go:577] Response Headers:
I0920 05:15:06.585787    7432 round_trippers.go:580]     Audit-Id: 4be527bd-da83-490c-a1c2-afd329bcc86d
I0920 05:15:06.585787    7432 round_trippers.go:580]     Cache-Control: no-cache, private
I0920 05:15:06.585787    7432 round_trippers.go:580]     Content-Type: application/json
I0920 05:15:06.585787    7432 round_trippers.go:580]     X-Kubernetes-Pf-Flowschema-Uid: 02cd4939-01f5-4b09-a0a9-02b620700246
I0920 05:15:06.585787    7432 round_trippers.go:580]     X-Kubernetes-Pf-Prioritylevel-Uid: fd684f0e-e7d0-4d27-979b-454254971228
I0920 05:15:06.585787    7432 round_trippers.go:580]     Content-Length: 291
I0920 05:15:06.585787    7432 round_trippers.go:580]     Date: Tue, 20 Sep 2022 10:15:06 GMT
I0920 05:15:06.585787    7432 request.go:1073] Response Body: {"kind":"Scale","apiVersion":"autoscaling/v1","metadata":{"name":"coredns","namespace":"kube-system","uid":"8c3d174c-c040-4e0d-b8c3-3c7403b16914","resourceVersion":"268","creationTimestamp":"2022-09-20T10:15:04Z"},"spec":{"replicas":1},"status":{"replicas":0,"selector":"k8s-app=kube-dns"}}
I0920 05:15:06.585787    7432 kapi.go:244] deployment "coredns" in namespace "kube-system" and context "minikube" rescaled to 1
I0920 05:15:06.585787    7432 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml"
I0920 05:15:06.585787    7432 start.go:211] Will wait 6m0s for node &{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.24.3 ContainerRuntime:docker ControlPlane:true Worker:true}
I0920 05:15:06.589061    7432 out.go:177] * Verifying Kubernetes components...
I0920 05:15:06.586343    7432 addons.go:412] enableAddons start: toEnable=map[], additional=[]
I0920 05:15:06.586343    7432 config.go:180] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.24.3
I0920 05:15:06.589061    7432 addons.go:65] Setting storage-provisioner=true in profile "minikube"
I0920 05:15:06.589061    7432 addons.go:65] Setting default-storageclass=true in profile "minikube"
I0920 05:15:06.590688    7432 addons_storage_classes.go:33] enableOrDisableStorageClasses default-storageclass=true on "minikube"
I0920 05:15:06.590688    7432 addons.go:153] Setting addon storage-provisioner=true in "minikube"
W0920 05:15:06.590688    7432 addons.go:162] addon storage-provisioner should already be in state true
I0920 05:15:06.591226    7432 host.go:66] Checking if "minikube" exists ...
I0920 05:15:06.599824    7432 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service kubelet
I0920 05:15:06.619368    7432 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0920 05:15:06.619892    7432 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0920 05:15:06.651833    7432 command_runner.go:130] > apiVersion: v1
I0920 05:15:06.651833    7432 command_runner.go:130] > data:
I0920 05:15:06.651833    7432 command_runner.go:130] >   Corefile: |
I0920 05:15:06.651833    7432 command_runner.go:130] >     .:53 {
I0920 05:15:06.651833    7432 command_runner.go:130] >         errors
I0920 05:15:06.651833    7432 command_runner.go:130] >         health {
I0920 05:15:06.651833    7432 command_runner.go:130] >            lameduck 5s
I0920 05:15:06.651833    7432 command_runner.go:130] >         }
I0920 05:15:06.651833    7432 command_runner.go:130] >         ready
I0920 05:15:06.651833    7432 command_runner.go:130] >         kubernetes cluster.local in-addr.arpa ip6.arpa {
I0920 05:15:06.651833    7432 command_runner.go:130] >            pods insecure
I0920 05:15:06.651833    7432 command_runner.go:130] >            fallthrough in-addr.arpa ip6.arpa
I0920 05:15:06.651833    7432 command_runner.go:130] >            ttl 30
I0920 05:15:06.651833    7432 command_runner.go:130] >         }
I0920 05:15:06.651833    7432 command_runner.go:130] >         prometheus :9153
I0920 05:15:06.651833    7432 command_runner.go:130] >         forward . /etc/resolv.conf {
I0920 05:15:06.651833    7432 command_runner.go:130] >            max_concurrent 1000
I0920 05:15:06.651833    7432 command_runner.go:130] >         }
I0920 05:15:06.651833    7432 command_runner.go:130] >         cache 30
I0920 05:15:06.651833    7432 command_runner.go:130] >         loop
I0920 05:15:06.651833    7432 command_runner.go:130] >         reload
I0920 05:15:06.651833    7432 command_runner.go:130] >         loadbalance
I0920 05:15:06.651833    7432 command_runner.go:130] >     }
I0920 05:15:06.651833    7432 command_runner.go:130] > kind: ConfigMap
I0920 05:15:06.651833    7432 command_runner.go:130] > metadata:
I0920 05:15:06.651833    7432 command_runner.go:130] >   creationTimestamp: "2022-09-20T10:15:04Z"
I0920 05:15:06.651833    7432 command_runner.go:130] >   name: coredns
I0920 05:15:06.651833    7432 command_runner.go:130] >   namespace: kube-system
I0920 05:15:06.651833    7432 command_runner.go:130] >   resourceVersion: "232"
I0920 05:15:06.651833    7432 command_runner.go:130] >   uid: e03b1162-b98e-4f73-99f1-02b9f88688bd
I0920 05:15:06.652379    7432 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml | sed '/^        forward . \/etc\/resolv.conf.*/i \        hosts {\n           192.168.65.2 host.minikube.internal\n           fallthrough\n        }' | sudo /var/lib/minikube/binaries/v1.24.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig replace -f -"
I0920 05:15:06.672444    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I0920 05:15:06.850462    7432 out.go:177]   - Using image gcr.io/k8s-minikube/storage-provisioner:v5
I0920 05:15:06.864460    7432 loader.go:372] Config loaded from file:  C:\Users\Esteban\.kube\config
I0920 05:15:06.870459    7432 addons.go:345] installing /etc/kubernetes/addons/storage-provisioner.yaml
I0920 05:15:06.870459    7432 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storage-provisioner.yaml (2676 bytes)
I0920 05:15:06.870459    7432 kapi.go:59] client config for minikube: &rest.Config{Host:"https://127.0.0.1:55725", APIPath:"", ContentConfig:rest.ContentConfig{AcceptContentTypes:"", ContentType:"", GroupVersion:(*schema.GroupVersion)(nil), NegotiatedSerializer:runtime.NegotiatedSerializer(nil)}, Username:"", Password:"", BearerToken:"", BearerTokenFile:"", Impersonate:rest.ImpersonationConfig{UserName:"", UID:"", Groups:[]string(nil), Extra:map[string][]string(nil)}, AuthProvider:<nil>, AuthConfigPersister:rest.AuthProviderConfigPersister(nil), ExecProvider:<nil>, TLSClientConfig:rest.sanitizedTLSClientConfig{Insecure:false, ServerName:"", CertFile:"C:\\Users\\Esteban\\.minikube\\profiles\\minikube\\client.crt", KeyFile:"C:\\Users\\Esteban\\.minikube\\profiles\\minikube\\client.key", CAFile:"C:\\Users\\Esteban\\.minikube\\ca.crt", CertData:[]uint8(nil), KeyData:[]uint8(nil), CAData:[]uint8(nil), NextProtos:[]string(nil)}, UserAgent:"", DisableCompression:false, Transport:http.RoundTripper(nil), WrapTransport:(transport.WrapperFunc)(0x1803b20), QPS:0, Burst:0, RateLimiter:flowcontrol.RateLimiter(nil), WarningHandler:rest.WarningHandler(nil), Timeout:0, Dial:(func(context.Context, string, string) (net.Conn, error))(nil), Proxy:(func(*http.Request) (*url.URL, error))(nil)}
I0920 05:15:06.871461    7432 round_trippers.go:466] curl -v -XGET  -H "Accept: application/json, */*" -H "User-Agent: minikube.exe/v0.0.0 (windows/amd64) kubernetes/$Format" 'https://127.0.0.1:55725/apis/storage.k8s.io/v1/storageclasses'
I0920 05:15:06.874460    7432 round_trippers.go:553] GET https://127.0.0.1:55725/apis/storage.k8s.io/v1/storageclasses 200 OK in 2 milliseconds
I0920 05:15:06.874460    7432 round_trippers.go:570] HTTP Statistics: GetConnection 0 ms ServerProcessing 2 ms Duration 2 ms
I0920 05:15:06.874460    7432 round_trippers.go:577] Response Headers:
I0920 05:15:06.874460    7432 round_trippers.go:580]     X-Kubernetes-Pf-Prioritylevel-Uid: fd684f0e-e7d0-4d27-979b-454254971228
I0920 05:15:06.874460    7432 round_trippers.go:580]     Content-Length: 109
I0920 05:15:06.874460    7432 round_trippers.go:580]     Date: Tue, 20 Sep 2022 10:15:06 GMT
I0920 05:15:06.874460    7432 round_trippers.go:580]     Audit-Id: 72d8ad2e-06cd-43cb-8068-872047311580
I0920 05:15:06.874460    7432 round_trippers.go:580]     Cache-Control: no-cache, private
I0920 05:15:06.874460    7432 round_trippers.go:580]     Content-Type: application/json
I0920 05:15:06.874460    7432 round_trippers.go:580]     X-Kubernetes-Pf-Flowschema-Uid: 02cd4939-01f5-4b09-a0a9-02b620700246
I0920 05:15:06.874460    7432 request.go:1073] Response Body: {"kind":"StorageClassList","apiVersion":"storage.k8s.io/v1","metadata":{"resourceVersion":"268"},"items":[]}
I0920 05:15:06.874460    7432 addons.go:153] Setting addon default-storageclass=true in "minikube"
W0920 05:15:06.874460    7432 addons.go:162] addon default-storageclass should already be in state true
I0920 05:15:06.874460    7432 host.go:66] Checking if "minikube" exists ...
I0920 05:15:06.874460    7432 loader.go:372] Config loaded from file:  C:\Users\Esteban\.kube\config
I0920 05:15:06.874460    7432 kapi.go:59] client config for minikube: &rest.Config{Host:"https://127.0.0.1:55725", APIPath:"", ContentConfig:rest.ContentConfig{AcceptContentTypes:"", ContentType:"", GroupVersion:(*schema.GroupVersion)(nil), NegotiatedSerializer:runtime.NegotiatedSerializer(nil)}, Username:"", Password:"", BearerToken:"", BearerTokenFile:"", Impersonate:rest.ImpersonationConfig{UserName:"", UID:"", Groups:[]string(nil), Extra:map[string][]string(nil)}, AuthProvider:<nil>, AuthConfigPersister:rest.AuthProviderConfigPersister(nil), ExecProvider:<nil>, TLSClientConfig:rest.sanitizedTLSClientConfig{Insecure:false, ServerName:"", CertFile:"C:\\Users\\Esteban\\.minikube\\profiles\\minikube\\client.crt", KeyFile:"C:\\Users\\Esteban\\.minikube\\profiles\\minikube\\client.key", CAFile:"C:\\Users\\Esteban\\.minikube\\ca.crt", CertData:[]uint8(nil), KeyData:[]uint8(nil), CAData:[]uint8(nil), NextProtos:[]string(nil)}, UserAgent:"", DisableCompression:false, Transport:http.RoundTripper(nil), WrapTransport:(transport.WrapperFunc)(0x1803b20), QPS:0, Burst:0, RateLimiter:flowcontrol.RateLimiter(nil), WarningHandler:rest.WarningHandler(nil), Timeout:0, Dial:(func(context.Context, string, string) (net.Conn, error))(nil), Proxy:(func(*http.Request) (*url.URL, error))(nil)}
I0920 05:15:06.875461    7432 api_server.go:51] waiting for apiserver process to appear ...
I0920 05:15:06.883460    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0920 05:15:06.884461    7432 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0920 05:15:06.900460    7432 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0920 05:15:06.955389    7432 command_runner.go:130] > configmap/coredns replaced
I0920 05:15:06.955389    7432 start.go:809] {"host.minikube.internal": 192.168.65.2} host record injected into CoreDNS
I0920 05:15:06.955389    7432 command_runner.go:130] > 1986
I0920 05:15:06.955389    7432 api_server.go:71] duration metric: took 369.071ms to wait for apiserver process to appear ...
I0920 05:15:06.955389    7432 api_server.go:87] waiting for apiserver healthz status ...
I0920 05:15:06.955389    7432 api_server.go:240] Checking apiserver healthz at https://127.0.0.1:55725/healthz ...
I0920 05:15:06.962451    7432 api_server.go:266] https://127.0.0.1:55725/healthz returned 200:
ok
I0920 05:15:06.962991    7432 round_trippers.go:466] curl -v -XGET  -H "Accept: application/json, */*" -H "User-Agent: minikube.exe/v0.0.0 (windows/amd64) kubernetes/$Format" 'https://127.0.0.1:55725/version'
I0920 05:15:06.964577    7432 round_trippers.go:553] GET https://127.0.0.1:55725/version 200 OK in 1 milliseconds
I0920 05:15:06.964599    7432 round_trippers.go:570] HTTP Statistics: GetConnection 0 ms ServerProcessing 1 ms Duration 1 ms
I0920 05:15:06.964616    7432 round_trippers.go:577] Response Headers:
I0920 05:15:06.964629    7432 round_trippers.go:580]     Date: Tue, 20 Sep 2022 10:15:06 GMT
I0920 05:15:06.964629    7432 round_trippers.go:580]     Audit-Id: 89b95a3e-5c5c-4882-aa93-8c006dbfd069
I0920 05:15:06.964629    7432 round_trippers.go:580]     Cache-Control: no-cache, private
I0920 05:15:06.964629    7432 round_trippers.go:580]     Content-Type: application/json
I0920 05:15:06.964629    7432 round_trippers.go:580]     X-Kubernetes-Pf-Flowschema-Uid: 02cd4939-01f5-4b09-a0a9-02b620700246
I0920 05:15:06.964629    7432 round_trippers.go:580]     X-Kubernetes-Pf-Prioritylevel-Uid: fd684f0e-e7d0-4d27-979b-454254971228
I0920 05:15:06.964629    7432 round_trippers.go:580]     Content-Length: 263
I0920 05:15:06.964629    7432 request.go:1073] Response Body: {
  "major": "1",
  "minor": "24",
  "gitVersion": "v1.24.3",
  "gitCommit": "aef86a93758dc3cb2c658dd9657ab4ad4afc21cb",
  "gitTreeState": "clean",
  "buildDate": "2022-07-13T14:23:26Z",
  "goVersion": "go1.18.3",
  "compiler": "gc",
  "platform": "linux/amd64"
}
I0920 05:15:06.964629    7432 api_server.go:140] control plane version: v1.24.3
I0920 05:15:06.964629    7432 api_server.go:130] duration metric: took 9.2404ms to wait for apiserver health ...
I0920 05:15:06.964629    7432 system_pods.go:43] waiting for kube-system pods to appear ...
I0920 05:15:06.964629    7432 round_trippers.go:466] curl -v -XGET  -H "Accept: application/json, */*" -H "User-Agent: minikube.exe/v0.0.0 (windows/amd64) kubernetes/$Format" 'https://127.0.0.1:55725/api/v1/namespaces/kube-system/pods'
I0920 05:15:06.968386    7432 round_trippers.go:553] GET https://127.0.0.1:55725/api/v1/namespaces/kube-system/pods 200 OK in 3 milliseconds
I0920 05:15:06.968386    7432 round_trippers.go:570] HTTP Statistics: GetConnection 0 ms ServerProcessing 3 ms Duration 3 ms
I0920 05:15:06.968386    7432 round_trippers.go:577] Response Headers:
I0920 05:15:06.968386    7432 round_trippers.go:580]     X-Kubernetes-Pf-Prioritylevel-Uid: fd684f0e-e7d0-4d27-979b-454254971228
I0920 05:15:06.968386    7432 round_trippers.go:580]     Date: Tue, 20 Sep 2022 10:15:06 GMT
I0920 05:15:06.968386    7432 round_trippers.go:580]     Audit-Id: c1a4ae37-d92b-4fd2-bf94-512010016e0d
I0920 05:15:06.968386    7432 round_trippers.go:580]     Cache-Control: no-cache, private
I0920 05:15:06.968386    7432 round_trippers.go:580]     Content-Type: application/json
I0920 05:15:06.968386    7432 round_trippers.go:580]     X-Kubernetes-Pf-Flowschema-Uid: 02cd4939-01f5-4b09-a0a9-02b620700246
I0920 05:15:06.968386    7432 request.go:1073] Response Body: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"270"},"items":[{"metadata":{"name":"etcd-minikube","namespace":"kube-system","uid":"7cb2727e-d1c6-42b4-b686-029bc2e720cb","resourceVersion":"256","creationTimestamp":"2022-09-20T10:15:05Z","labels":{"component":"etcd","tier":"control-plane"},"annotations":{"kubeadm.kubernetes.io/etcd.advertise-client-urls":"https://192.168.49.2:2379","kubernetes.io/config.hash":"906edd533192a4db2396a938662a5271","kubernetes.io/config.mirror":"906edd533192a4db2396a938662a5271","kubernetes.io/config.seen":"2022-09-20T10:15:04.541683400Z","kubernetes.io/config.source":"file","seccomp.security.alpha.kubernetes.io/pod":"runtime/default"},"ownerReferences":[{"apiVersion":"v1","kind":"Node","name":"minikube","uid":"88395272-a0b5-4a2c-bb07-daf0b9548da3","controller":true}],"managedFields":[{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-09-20T10:15:05Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:kubeadm.kubernetes.io/etcd.advertise-client-urls":{},"f:kubernetes.io/config.hash":{},"f:kubernetes.io/config.mirror":{},"f:kubernetes.io/config.seen":{},"f:kubernetes.io/config.source":{}},"f:labels":{".":{},"f:component":{},"f:tier":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"88395272-a0b5-4a2c-bb07-daf0b9548da3\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"etcd\"}":{".":{},"f:command":{},"f:image":{},"f:imagePullPolicy":{},"f:livenessProbe":{".":{},"f:failureThreshold":{},"f:httpGet":{".":{},"f:host":{},"f:path":{},"f:port":{},"f:scheme":{}},"f:initialDelaySeconds":{},"f:periodSeconds":{},"f:successThreshold":{},"f:timeoutSeconds":{}},"f:name":{},"f:resources":{".":{},"f:requests":{".":{},"f:cpu":{},"f:memory":{}}},"f:startupProbe":{".":{},"f:failureThreshold":{},"f:httpGet":{".":{},"f:host":{},"f:path":{},"f:port":{},"f:scheme":{}},"f:initialDelaySeconds":{},"f:periodSeconds":{},"f:successThreshold":{},"f:timeoutSeconds":{}},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{},"f:volumeMounts":{".":{},"k:{\"mountPath\":\"/var/lib/minikube/certs/etcd\"}":{".":{},"f:mountPath":{},"f:name":{}},"k:{\"mountPath\":\"/var/lib/minikube/etcd\"}":{".":{},"f:mountPath":{},"f:name":{}}}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:hostNetwork":{},"f:nodeName":{},"f:priorityClassName":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{".":{},"f:seccompProfile":{".":{},"f:type":{}}},"f:terminationGracePeriodSeconds":{},"f:tolerations":{},"f:volumes":{".":{},"k:{\"name\":\"etcd-certs\"}":{".":{},"f:hostPath":{".":{},"f:path":{},"f:type":{}},"f:name":{}},"k:{\"name\":\"etcd-data\"}":{".":{},"f:hostPath":{".":{},"f:path":{},"f:type":{}},"f:name":{}}}}}}]},"spec":{"volumes":[{"name":"etcd-certs","hostPath":{"path":"/var/lib/minikube/certs/etcd","type":"DirectoryOrCreate"}},{"name":"etcd-data","hostPath":{"path":"/var/lib/minikube/etcd","type":"DirectoryOrCreate"}}],"containers":[{"name":"etcd","image":"k8s.gcr.io/etcd:3.5.3-0","command":["etcd","--advertise-client-urls=https://192.168.49.2:2379","--cert-file=/var/lib/minikube/certs/etcd/server.crt","--client-cert-auth=true","--data-dir=/var/lib/minikube/etcd","--experimental-initial-corrupt-check=true","--initial-advertise-peer-urls=https://192.168.49.2:2380","--initial-cluster=minikube=https://192.168.49.2:2380","--key-file=/var/lib/minikube/certs/etcd/server.key","--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379","--listen-metrics-urls=http://127.0.0.1:2381","--listen-peer-urls=https://192.168.49.2:2380","--name=minikube","--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt","--peer-client-cert-auth=true","--peer-key-file=/var/lib/minikube/certs/etcd/peer.key","--peer-trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt","--proxy-refresh-interval=70000","--snapshot-count=10000","--trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt"],"resources":{"requests":{"cpu":"100m","memory":"100Mi"}},"volumeMounts":[{"name":"etcd-data","mountPath":"/var/lib/minikube/etcd"},{"name":"etcd-certs","mountPath":"/var/lib/minikube/certs/etcd"}],"livenessProbe":{"httpGet":{"path":"/health","port":2381,"host":"127.0.0.1","scheme":"HTTP"},"initialDelaySeconds":10,"timeoutSeconds":15,"periodSeconds":10,"successThreshold":1,"failureThreshold":8},"startupProbe":{"httpGet":{"path":"/health","port":2381,"host":"127.0.0.1","scheme":"HTTP"},"initialDelaySeconds":10,"timeoutSeconds":15,"periodSeconds":10,"successThreshold":1,"failureThreshold":24},"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent"}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","nodeName":"minikube","hostNetwork":true,"securityContext":{"seccompProfile":{"type":"RuntimeDefault"}},"schedulerName":"default-scheduler","tolerations":[{"operator":"Exists","effect":"NoExecute"}],"priorityClassName":"system-node-critical","priority":2000001000,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Pending","qosClass":"Burstable"}},{"metadata":{"name":"kube-apiserver-minikube","namespace":"kube-system","uid":"bd782385-5c30-4bcb-bb71-c0ca71cfb039","resourceVersion":"257","creationTimestamp":"2022-09-20T10:15:05Z","labels":{"component":"kube-apiserver","tier":"control-plane"},"annotations":{"kubeadm.kubernetes.io/kube-apiserver.advertise-address.endpoint":"192.168.49.2:8443","kubernetes.io/config.hash":"af8a252bb89a737e9c95199d01283487","kubernetes.io/config.mirror":"af8a252bb89a737e9c95199d01283487","kubernetes.io/config.seen":"2022-09-20T10:15:04.541662400Z","kubernetes.io/config.source":"file","seccomp.security.alpha.kubernetes.io/pod":"runtime/default"},"ownerReferences":[{"apiVersion":"v1","kind":"Node","name":"minikube","uid":"88395272-a0b5-4a2c-bb07-daf0b9548da3","controller":true}],"managedFields":[{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-09-20T10:15:05Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:kubeadm.kubernetes.io/kube-apiserver.advertise-address.endpoint":{},"f:kubernetes.io/config.hash":{},"f:kubernetes.io/config.mirror":{},"f:kubernetes.io/config.seen":{},"f:kubernetes.io/config.source":{}},"f:labels":{".":{},"f:component":{},"f:tier":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"88395272-a0b5-4a2c-bb07-daf0b9548da3\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"kube-apiserver\"}":{".":{},"f:command":{},"f:image":{},"f:imagePullPolicy":{},"f:livenessProbe":{".":{},"f:failureThreshold":{},"f:httpGet":{".":{},"f:host":{},"f:path":{},"f:port":{},"f:scheme":{}},"f:initialDelaySeconds":{},"f:periodSeconds":{},"f:successThreshold":{},"f:timeoutSeconds":{}},"f:name":{},"f:readinessProbe":{".":{},"f:failureThreshold":{},"f:httpGet":{".":{},"f:host":{},"f:path":{},"f:port":{},"f:scheme":{}},"f:periodSeconds":{},"f:successThreshold":{},"f:timeoutSeconds":{}},"f:resources":{".":{},"f:requests":{".":{},"f:cpu":{}}},"f:startupProbe":{".":{},"f:failureThreshold":{},"f:httpGet":{".":{},"f:host":{},"f:path":{},"f:port":{},"f:scheme":{}},"f:initialDelaySeconds":{},"f:periodSeconds":{},"f:successThreshold":{},"f:timeoutSeconds":{}},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{},"f:volumeMounts":{".":{},"k:{\"mountPath\":\"/etc/ca-certificates\"}":{".":{},"f:mountPath":{},"f:name":{},"f:readOnly":{}},"k:{\"mountPath\":\"/etc/ssl/certs\"}":{".":{},"f:mountPath":{},"f:name":{},"f:readOnly":{}},"k:{\"mountPath\":\"/usr/local/share/ca-certificates\"}":{".":{},"f:mountPath":{},"f:name":{},"f:readOnly":{}},"k:{\"mountPath\":\"/usr/share/ca-certificates\"}":{".":{},"f:mountPath":{},"f:name":{},"f:readOnly":{}},"k:{\"mountPath\":\"/var/lib/minikube/certs\"}":{".":{},"f:mountPath":{},"f:name":{},"f:readOnly":{}}}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:hostNetwork":{},"f:nodeName":{},"f:priorityClassName":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{".":{},"f:seccompProfile":{".":{},"f:type":{}}},"f:terminationGracePeriodSeconds":{},"f:tolerations":{},"f:volumes":{".":{},"k:{\"name\":\"ca-certs\"}":{".":{},"f:hostPath":{".":{},"f:path":{},"f:type":{}},"f:name":{}},"k:{\"name\":\"etc-ca-certificates\"}":{".":{},"f:hostPath":{".":{},"f:path":{},"f:type":{}},"f:name":{}},"k:{\"name\":\"k8s-certs\"}":{".":{},"f:hostPath":{".":{},"f:path":{},"f:type":{}},"f:name":{}},"k:{\"name\":\"usr-local-share-ca-certificates\"}":{".":{},"f:hostPath":{".":{},"f:path":{},"f:type":{}},"f:name":{}},"k:{\"name\":\"usr-share-ca-certificates\"}":{".":{},"f:hostPath":{".":{},"f:path":{},"f:type":{}},"f:name":{}}}}}}]},"spec":{"volumes":[{"name":"ca-certs","hostPath":{"path":"/etc/ssl/certs","type":"DirectoryOrCreate"}},{"name":"etc-ca-certificates","hostPath":{"path":"/etc/ca-certificates","type":"DirectoryOrCreate"}},{"name":"k8s-certs","hostPath":{"path":"/var/lib/minikube/certs","type":"DirectoryOrCreate"}},{"name":"usr-local-share-ca-certificates","hostPath":{"path":"/usr/local/share/ca-certificates","type":"DirectoryOrCreate"}},{"name":"usr-share-ca-certificates","hostPath":{"path":"/usr/share/ca-certificates","type":"DirectoryOrCreate"}}],"containers":[{"name":"kube-apiserver","image":"k8s.gcr.io/kube-apiserver:v1.24.3","command":["kube-apiserver","--advertise-address=192.168.49.2","--allow-privileged=true","--authorization-mode=Node,RBAC","--client-ca-file=/var/lib/minikube/certs/ca.crt","--enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota","--enable-bootstrap-token-auth=true","--etcd-cafile=/var/lib/minikube/certs/etcd/ca.crt","--etcd-certfile=/var/lib/minikube/certs/apiserver-etcd-client.crt","--etcd-keyfile=/var/lib/minikube/certs/apiserver-etcd-client.key","--etcd-servers=https://127.0.0.1:2379","--kubelet-client-certificate=/var/lib/minikube/certs/apiserver-kubelet-client.crt","--kubelet-client-key=/var/lib/minikube/certs/apiserver-kubelet-client.key","--kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname","--proxy-client-cert-file=/var/lib/minikube/certs/front-proxy-client.crt","--proxy-client-key-file=/var/lib/minikube/certs/front-proxy-client.key","--requestheader-allowed-names=front-proxy-client","--requestheader-client-ca-file=/var/lib/minikube/certs/front-proxy-ca.crt","--requestheader-extra-headers-prefix=X-Remote-Extra-","--requestheader-group-headers=X-Remote-Group","--requestheader-username-headers=X-Remote-User","--secure-port=8443","--service-account-issuer=https://kubernetes.default.svc.cluster.local","--service-account-key-file=/var/lib/minikube/certs/sa.pub","--service-account-signing-key-file=/var/lib/minikube/certs/sa.key","--service-cluster-ip-range=10.96.0.0/12","--tls-cert-file=/var/lib/minikube/certs/apiserver.crt","--tls-private-key-file=/var/lib/minikube/certs/apiserver.key"],"resources":{"requests":{"cpu":"250m"}},"volumeMounts":[{"name":"ca-certs","readOnly":true,"mountPath":"/etc/ssl/certs"},{"name":"etc-ca-certificates","readOnly":true,"mountPath":"/etc/ca-certificates"},{"name":"k8s-certs","readOnly":true,"mountPath":"/var/lib/minikube/certs"},{"name":"usr-local-share-ca-certificates","readOnly":true,"mountPath":"/usr/local/share/ca-certificates"},{"name":"usr-share-ca-certificates","readOnly":true,"mountPath":"/usr/share/ca-certificates"}],"livenessProbe":{"httpGet":{"path":"/livez","port":8443,"host":"192.168.49.2","scheme":"HTTPS"},"initialDelaySeconds":10,"timeoutSeconds":15,"periodSeconds":10,"successThreshold":1,"failureThreshold":8},"readinessProbe":{"httpGet":{"path":"/readyz","port":8443,"host":"192.168.49.2","scheme":"HTTPS"},"timeoutSeconds":15,"periodSeconds":1,"successThreshold":1,"failureThreshold":3},"startupProbe":{"httpGet":{"path":"/livez","port":8443,"host":"192.168.49.2","scheme":"HTTPS"},"initialDelaySeconds":10,"timeoutSeconds":15,"periodSeconds":10,"successThreshold":1,"failureThreshold":24},"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent"}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","nodeName":"minikube","hostNetwork":true,"securityContext":{"seccompProfile":{"type":"RuntimeDefault"}},"schedulerName":"default-scheduler","tolerations":[{"operator":"Exists","effect":"NoExecute"}],"priorityClassName":"system-node-critical","priority":2000001000,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Pending","qosClass":"Burstable"}},{"metadata":{"name":"kube-controller-manager-minikube","namespace":"kube-system","uid":"22d69073-a2ea-462c-8ce4-0d189461c92f","resourceVersion":"258","creationTimestamp":"2022-09-20T10:15:05Z","labels":{"component":"kube-controller-manager","tier":"control-plane"},"annotations":{"kubernetes.io/config.hash":"76444121a189d8a30add20fb32ab6d4e","kubernetes.io/config.mirror":"76444121a189d8a30add20fb32ab6d4e","kubernetes.io/config.seen":"2022-09-20T10:15:04.541678800Z","kubernetes.io/config.source":"file","seccomp.security.alpha.kubernetes.io/pod":"runtime/default"},"ownerReferences":[{"apiVersion":"v1","kind":"Node","name":"minikube","uid":"88395272-a0b5-4a2c-bb07-daf0b9548da3","controller":true}],"managedFields":[{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-09-20T10:15:05Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:kubernetes.io/config.hash":{},"f:kubernetes.io/config.mirror":{},"f:kubernetes.io/config.seen":{},"f:kubernetes.io/config.source":{}},"f:labels":{".":{},"f:component":{},"f:tier":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"88395272-a0b5-4a2c-bb07-daf0b9548da3\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"kube-controller-manager\"}":{".":{},"f:command":{},"f:image":{},"f:imagePullPolicy":{},"f:livenessProbe":{".":{},"f:failureThreshold":{},"f:httpGet":{".":{},"f:host":{},"f:path":{},"f:port":{},"f:scheme":{}},"f:initialDelaySeconds":{},"f:periodSeconds":{},"f:successThreshold":{},"f:timeoutSeconds":{}},"f:name":{},"f:resources":{".":{},"f:requests":{".":{},"f:cpu":{}}},"f:startupProbe":{".":{},"f:failureThreshold":{},"f:httpGet":{".":{},"f:host":{},"f:path":{},"f:port":{},"f:scheme":{}},"f:initialDelaySeconds":{},"f:periodSeconds":{},"f:successThreshold":{},"f:timeoutSeconds":{}},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{},"f:volumeMounts":{".":{},"k:{\"mountPath\":\"/etc/ca-certificates\"}":{".":{},"f:mountPath":{},"f:name":{},"f:readOnly":{}},"k:{\"mountPath\":\"/etc/kubernetes/controller-manager.conf\"}":{".":{},"f:mountPath":{},"f:name":{},"f:readOnly":{}},"k:{\"mountPath\":\"/etc/ssl/certs\"}":{".":{},"f:mountPath":{},"f:name":{},"f:readOnly":{}},"k:{\"mountPath\":\"/usr/libexec/kubernetes/kubelet-plugins/volume/exec\"}":{".":{},"f:mountPath":{},"f:name":{}},"k:{\"mountPath\":\"/usr/local/share/ca-certificates\"}":{".":{},"f:mountPath":{},"f:name":{},"f:readOnly":{}},"k:{\"mountPath\":\"/usr/share/ca-certificates\"}":{".":{},"f:mountPath":{},"f:name":{},"f:readOnly":{}},"k:{\"mountPath\":\"/var/lib/minikube/certs\"}":{".":{},"f:mountPath":{},"f:name":{},"f:readOnly":{}}}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:hostNetwork":{},"f:nodeName":{},"f:priorityClassName":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{".":{},"f:seccompProfile":{".":{},"f:type":{}}},"f:terminationGracePeriodSeconds":{},"f:tolerations":{},"f:volumes":{".":{},"k:{\"name\":\"ca-certs\"}":{".":{},"f:hostPath":{".":{},"f:path":{},"f:type":{}},"f:name":{}},"k:{\"name\":\"etc-ca-certificates\"}":{".":{},"f:hostPath":{".":{},"f:path":{},"f:type":{}},"f:name":{}},"k:{\"name\":\"flexvolume-dir\"}":{".":{},"f:hostPath":{".":{},"f:path":{},"f:type":{}},"f:name":{}},"k:{\"name\":\"k8s-certs\"}":{".":{},"f:hostPath":{".":{},"f:path":{},"f:type":{}},"f:name":{}},"k:{\"name\":\"kubeconfig\"}":{".":{},"f:hostPath":{".":{},"f:path":{},"f:type":{}},"f:name":{}},"k:{\"name\":\"usr-local-share-ca-certificates\"}":{".":{},"f:hostPath":{".":{},"f:path":{},"f:type":{}},"f:name":{}},"k:{\"name\":\"usr-share-ca-certificates\"}":{".":{},"f:hostPath":{".":{},"f:path":{},"f:type":{}},"f:name":{}}}}}}]},"spec":{"volumes":[{"name":"ca-certs","hostPath":{"path":"/etc/ssl/certs","type":"DirectoryOrCreate"}},{"name":"etc-ca-certificates","hostPath":{"path":"/etc/ca-certificates","type":"DirectoryOrCreate"}},{"name":"flexvolume-dir","hostPath":{"path":"/usr/libexec/kubernetes/kubelet-plugins/volume/exec","type":"DirectoryOrCreate"}},{"name":"k8s-certs","hostPath":{"path":"/var/lib/minikube/certs","type":"DirectoryOrCreate"}},{"name":"kubeconfig","hostPath":{"path":"/etc/kubernetes/controller-manager.conf","type":"FileOrCreate"}},{"name":"usr-local-share-ca-certificates","hostPath":{"path":"/usr/local/share/ca-certificates","type":"DirectoryOrCreate"}},{"name":"usr-share-ca-certificates","hostPath":{"path":"/usr/share/ca-certificates","type":"DirectoryOrCreate"}}],"containers":[{"name":"kube-controller-manager","image":"k8s.gcr.io/kube-controller-manager:v1.24.3","command":["kube-controller-manager","--allocate-node-cidrs=true","--authentication-kubeconfig=/etc/kubernetes/controller-manager.conf","--authorization-kubeconfig=/etc/kubernetes/controller-manager.conf","--bind-address=127.0.0.1","--client-ca-file=/var/lib/minikube/certs/ca.crt","--cluster-cidr=10.244.0.0/16","--cluster-name=mk","--cluster-signing-cert-file=/var/lib/minikube/certs/ca.crt","--cluster-signing-key-file=/var/lib/minikube/certs/ca.key","--controllers=*,bootstrapsigner,tokencleaner","--kubeconfig=/etc/kubernetes/controller-manager.conf","--leader-elect=false","--requestheader-client-ca-file=/var/lib/minikube/certs/front-proxy-ca.crt","--root-ca-file=/var/lib/minikube/certs/ca.crt","--service-account-private-key-file=/var/lib/minikube/certs/sa.key","--service-cluster-ip-range=10.96.0.0/12","--use-service-account-credentials=true"],"resources":{"requests":{"cpu":"200m"}},"volumeMounts":[{"name":"ca-certs","readOnly":true,"mountPath":"/etc/ssl/certs"},{"name":"etc-ca-certificates","readOnly":true,"mountPath":"/etc/ca-certificates"},{"name":"flexvolume-dir","mountPath":"/usr/libexec/kubernetes/kubelet-plugins/volume/exec"},{"name":"k8s-certs","readOnly":true,"mountPath":"/var/lib/minikube/certs"},{"name":"kubeconfig","readOnly":true,"mountPath":"/etc/kubernetes/controller-manager.conf"},{"name":"usr-local-share-ca-certificates","readOnly":true,"mountPath":"/usr/local/share/ca-certificates"},{"name":"usr-share-ca-certificates","readOnly":true,"mountPath":"/usr/share/ca-certificates"}],"livenessProbe":{"httpGet":{"path":"/healthz","port":10257,"host":"127.0.0.1","scheme":"HTTPS"},"initialDelaySeconds":10,"timeoutSeconds":15,"periodSeconds":10,"successThreshold":1,"failureThreshold":8},"startupProbe":{"httpGet":{"path":"/healthz","port":10257,"host":"127.0.0.1","scheme":"HTTPS"},"initialDelaySeconds":10,"timeoutSeconds":15,"periodSeconds":10,"successThreshold":1,"failureThreshold":24},"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent"}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","nodeName":"minikube","hostNetwork":true,"securityContext":{"seccompProfile":{"type":"RuntimeDefault"}},"schedulerName":"default-scheduler","tolerations":[{"operator":"Exists","effect":"NoExecute"}],"priorityClassName":"system-node-critical","priority":2000001000,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Pending","qosClass":"Burstable"}},{"metadata":{"name":"kube-scheduler-minikube","namespace":"kube-system","uid":"0f9f2acb-df47-4f47-b611-649f280c7a6d","resourceVersion":"269","creationTimestamp":"2022-09-20T10:15:05Z","labels":{"component":"kube-scheduler","tier":"control-plane"},"annotations":{"kubernetes.io/config.hash":"2e95d5efbc70e877d20097c03ba4ff89","kubernetes.io/config.mirror":"2e95d5efbc70e877d20097c03ba4ff89","kubernetes.io/config.seen":"2022-09-20T10:15:04.541681200Z","kubernetes.io/config.source":"file","seccomp.security.alpha.kubernetes.io/pod":"runtime/default"},"ownerReferences":[{"apiVersion":"v1","kind":"Node","name":"minikube","uid":"88395272-a0b5-4a2c-bb07-daf0b9548da3","controller":true}],"managedFields":[{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-09-20T10:15:05Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:kubernetes.io/config.hash":{},"f:kubernetes.io/config.mirror":{},"f:kubernetes.io/config.seen":{},"f:kubernetes.io/config.source":{}},"f:labels":{".":{},"f:component":{},"f:tier":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"88395272-a0b5-4a2c-bb07-daf0b9548da3\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"kube-scheduler\"}":{".":{},"f:command":{},"f:image":{},"f:imagePullPolicy":{},"f:livenessProbe":{".":{},"f:failureThreshold":{},"f:httpGet":{".":{},"f:host":{},"f:path":{},"f:port":{},"f:scheme":{}},"f:initialDelaySeconds":{},"f:periodSeconds":{},"f:successThreshold":{},"f:timeoutSeconds":{}},"f:name":{},"f:resources":{".":{},"f:requests":{".":{},"f:cpu":{}}},"f:startupProbe":{".":{},"f:failureThreshold":{},"f:httpGet":{".":{},"f:host":{},"f:path":{},"f:port":{},"f:scheme":{}},"f:initialDelaySeconds":{},"f:periodSeconds":{},"f:successThreshold":{},"f:timeoutSeconds":{}},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{},"f:volumeMounts":{".":{},"k:{\"mountPath\":\"/etc/kubernetes/scheduler.conf\"}":{".":{},"f:mountPath":{},"f:name":{},"f:readOnly":{}}}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:hostNetwork":{},"f:nodeName":{},"f:priorityClassName":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{".":{},"f:seccompProfile":{".":{},"f:type":{}}},"f:terminationGracePeriodSeconds":{},"f:tolerations":{},"f:volumes":{".":{},"k:{\"name\":\"kubeconfig\"}":{".":{},"f:hostPath":{".":{},"f:path":{},"f:type":{}},"f:name":{}}}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-09-20T10:15:06Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{".":{},"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"PodScheduled\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.49.2\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kubeconfig","hostPath":{"path":"/etc/kubernetes/scheduler.conf","type":"FileOrCreate"}}],"containers":[{"name":"kube-scheduler","image":"k8s.gcr.io/kube-scheduler:v1.24.3","command":["kube-scheduler","--authentication-kubeconfig=/etc/kubernetes/scheduler.conf","--authorization-kubeconfig=/etc/kubernetes/scheduler.conf","--bind-address=127.0.0.1","--kubeconfig=/etc/kubernetes/scheduler.conf","--leader-elect=false"],"resources":{"requests":{"cpu":"100m"}},"volumeMounts":[{"name":"kubeconfig","readOnly":true,"mountPath":"/etc/kubernetes/scheduler.conf"}],"livenessProbe":{"httpGet":{"path":"/healthz","port":10259,"host":"127.0.0.1","scheme":"HTTPS"},"initialDelaySeconds":10,"timeoutSeconds":15,"periodSeconds":10,"successThreshold":1,"failureThreshold":8},"startupProbe":{"httpGet":{"path":"/healthz","port":10259,"host":"127.0.0.1","scheme":"HTTPS"},"initialDelaySeconds":10,"timeoutSeconds":15,"periodSeconds":10,"successThreshold":1,"failureThreshold":24},"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent"}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","nodeName":"minikube","hostNetwork":true,"securityContext":{"seccompProfile":{"type":"RuntimeDefault"}},"schedulerName":"default-scheduler","tolerations":[{"operator":"Exists","effect":"NoExecute"}],"priorityClassName":"system-node-critical","priority":2000001000,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-09-20T10:15:05Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-09-20T10:15:05Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-09-20T10:15:05Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-09-20T10:15:05Z"}],"hostIP":"192.168.49.2","podIP":"192.168.49.2","podIPs":[{"ip":"192.168.49.2"}],"startTime":"2022-09-20T10:15:05Z","containerStatuses":[{"name":"kube-scheduler","state":{"running":{"startedAt":"2022-09-20T10:14:57Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"k8s.gcr.io/kube-scheduler:v1.24.3","imageID":"docker-pullable://k8s.gcr.io/kube-scheduler@sha256:e199523298224cd9f2a9a43c7c2c37fa57aff87648ed1e1de9984eba6f6005f0","containerID":"docker://d6c87055ded52f8a22cc37f881f907e28f36be3dd072e8b804d5540ce7773e9f","started":true}],"qosClass":"Burstable"}}]}
I0920 05:15:06.971090    7432 system_pods.go:59] 4 kube-system pods found
I0920 05:15:06.971107    7432 system_pods.go:61] "etcd-minikube" [7cb2727e-d1c6-42b4-b686-029bc2e720cb] Pending
I0920 05:15:06.971121    7432 system_pods.go:61] "kube-apiserver-minikube" [bd782385-5c30-4bcb-bb71-c0ca71cfb039] Pending
I0920 05:15:06.971127    7432 system_pods.go:61] "kube-controller-manager-minikube" [22d69073-a2ea-462c-8ce4-0d189461c92f] Pending
I0920 05:15:06.971127    7432 system_pods.go:61] "kube-scheduler-minikube" [0f9f2acb-df47-4f47-b611-649f280c7a6d] Running
I0920 05:15:06.971127    7432 system_pods.go:74] duration metric: took 6.4983ms to wait for pod list to return data ...
I0920 05:15:06.971127    7432 kubeadm.go:572] duration metric: took 384.8097ms to wait for : map[apiserver:true system_pods:true] ...
I0920 05:15:06.971127    7432 node_conditions.go:102] verifying NodePressure condition ...
I0920 05:15:06.971127    7432 round_trippers.go:466] curl -v -XGET  -H "Accept: application/json, */*" -H "User-Agent: minikube.exe/v0.0.0 (windows/amd64) kubernetes/$Format" 'https://127.0.0.1:55725/api/v1/nodes'
I0920 05:15:06.974940    7432 round_trippers.go:553] GET https://127.0.0.1:55725/api/v1/nodes 200 OK in 3 milliseconds
I0920 05:15:06.974940    7432 round_trippers.go:570] HTTP Statistics: GetConnection 0 ms ServerProcessing 3 ms Duration 3 ms
I0920 05:15:06.974940    7432 round_trippers.go:577] Response Headers:
I0920 05:15:06.974940    7432 round_trippers.go:580]     Content-Type: application/json
I0920 05:15:06.974940    7432 round_trippers.go:580]     X-Kubernetes-Pf-Flowschema-Uid: 02cd4939-01f5-4b09-a0a9-02b620700246
I0920 05:15:06.974940    7432 round_trippers.go:580]     X-Kubernetes-Pf-Prioritylevel-Uid: fd684f0e-e7d0-4d27-979b-454254971228
I0920 05:15:06.974940    7432 round_trippers.go:580]     Date: Tue, 20 Sep 2022 10:15:06 GMT
I0920 05:15:06.974940    7432 round_trippers.go:580]     Audit-Id: 2258281d-3bac-48d9-a0aa-b8bdaa08c690
I0920 05:15:06.974940    7432 round_trippers.go:580]     Cache-Control: no-cache, private
I0920 05:15:06.974940    7432 request.go:1073] Response Body: {"kind":"NodeList","apiVersion":"v1","metadata":{"resourceVersion":"270"},"items":[{"metadata":{"name":"minikube","uid":"88395272-a0b5-4a2c-bb07-daf0b9548da3","resourceVersion":"267","creationTimestamp":"2022-09-20T10:15:01Z","labels":{"beta.kubernetes.io/arch":"amd64","beta.kubernetes.io/os":"linux","kubernetes.io/arch":"amd64","kubernetes.io/hostname":"minikube","kubernetes.io/os":"linux","minikube.k8s.io/commit":"62e108c3dfdec8029a890ad6d8ef96b6461426dc","minikube.k8s.io/name":"minikube","minikube.k8s.io/primary":"true","minikube.k8s.io/updated_at":"2022_09_20T05_15_05_0700","minikube.k8s.io/version":"v1.26.1","node-role.kubernetes.io/control-plane":"","node.kubernetes.io/exclude-from-external-load-balancers":""},"annotations":{"kubeadm.alpha.kubernetes.io/cri-socket":"unix:///var/run/cri-dockerd.sock","volumes.kubernetes.io/controller-managed-attach-detach":"true"},"managedFields":[{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-09-20T10:15:01Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:volumes.kubernetes.io/controller-managed-attach-detach":{}},"f:labels":{".":{},"f:beta.kubernetes.io/arch":{},"f:beta.kubernetes.io/os":{},"f:kubernetes.io/arch":{},"f:kubernetes.io/hostname":{},"f:kubernetes.io/os":{}}}}},{"manager":"kubeadm","operation":"Update","apiVersion":"v1","time":"2022-09-20T10:15:04Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{"f:kubeadm.alpha.kubernetes.io/cri-socket":{}},"f:labels":{"f:node-role.kubernetes.io/control-plane":{},"f:node.kubernetes.io/exclude-from-external-load-balancers":{}}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-09-20T10:15:04Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"DiskPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"MemoryPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"PIDPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"Ready\"}":{"f:lastHeartbeatTime":{},"f:message":{}}},"f:images":{}}},"subresource":"status"},{"manager":"kubectl-label","operation":"Update","apiVersion":"v1","time":"2022-09-20T10:15:06Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:labels":{"f:minikube.k8s.io/commit":{},"f:minikube.k8s.io/name":{},"f:minikube.k8s.io/primary":{},"f:minikube.k8s.io/updated_at":{},"f:minikube.k8s.io/version":{}}}}}]},"spec":{"taints":[{"key":"node.kubernetes.io/not-ready","effect":"NoSchedule"}]},"status":{"capacity":{"cpu":"12","ephemeral-storage":"263174212Ki","hugepages-1Gi":"0","hugepages-2Mi":"0","memory":"12923048Ki","pods":"110"},"allocatable":{"cpu":"12","ephemeral-storage":"263174212Ki","hugepages-1Gi":"0","hugepages-2Mi":"0","memory":"12923048Ki","pods":"110"},"conditions":[{"type":"MemoryPressure","status":"False","lastHeartbeatTime":"2022-09-20T10:15:04Z","lastTransitionTime":"2022-09-20T10:15:01Z","reason":"KubeletHasSufficientMemory","message":"kubelet has sufficient memory available"},{"type":"DiskPressure","status":"False","lastHeartbeatTime":"2022-09-20T10:15:04Z","lastTransitionTime":"2022-09-20T10:15:01Z","reason":"KubeletHasNoDiskPressure","message":"kubelet has no disk pressure"},{"type":"PIDPressure","status":"False","lastHeartbeatTime":"2022-09-20T10:15:04Z","lastTransitionTime":"2022-09-20T10:15:01Z","reason":"KubeletHasSufficientPID","message":"kubelet has sufficient PID available"},{"type":"Ready","status":"False","lastHeartbeatTime":"2022-09-20T10:15:04Z","lastTransitionTime":"2022-09-20T10:15:01Z","reason":"KubeletNotReady","message":"[container runtime status check may not have completed yet, container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:docker: network plugin is not ready: cni config uninitialized]"}],"addresses":[{"type":"InternalIP","address":"192.168.49.2"},{"type":"Hostname","address":"minikube"}],"daemonEndpoints":{"kubeletEndpoint":{"Port":10250}},"nodeInfo":{"machineID":"4c192b04687c403f8fbb9bc7975b21b3","systemUUID":"4c192b04687c403f8fbb9bc7975b21b3","bootID":"de31de94-2a42-4516-a4e6-7cb2de739fde","kernelVersion":"5.10.102.1-microsoft-standard-WSL2","osImage":"Ubuntu 20.04.4 LTS","containerRuntimeVersion":"docker://20.10.17","kubeletVersion":"v1.24.3","kubeProxyVersion":"v1.24.3","operatingSystem":"linux","architecture":"amd64"},"images":[{"names":["k8s.gcr.io/etcd@sha256:13f53ed1d91e2e11aac476ee9a0269fdda6cc4874eba903efd40daf50c55eee5","k8s.gcr.io/etcd:3.5.3-0"],"sizeBytes":299495233},{"names":["k8s.gcr.io/kube-apiserver@sha256:a04609b85962da7e6531d32b75f652b4fb9f5fe0b0ee0aa160856faad8ec5d96","k8s.gcr.io/kube-apiserver:v1.24.3"],"sizeBytes":129710737},{"names":["k8s.gcr.io/kube-controller-manager@sha256:f504eead8b8674ebc9067370ef51abbdc531b4a81813bfe464abccb8c76b6a53","k8s.gcr.io/kube-controller-manager:v1.24.3"],"sizeBytes":119360464},{"names":["k8s.gcr.io/kube-proxy@sha256:c1b135231b5b1a6799346cd701da4b59e5b7ef8e694ec7b04fb23b8dbe144137","k8s.gcr.io/kube-proxy:v1.24.3"],"sizeBytes":109939784},{"names":["k8s.gcr.io/kube-scheduler@sha256:e199523298224cd9f2a9a43c7c2c37fa57aff87648ed1e1de9984eba6f6005f0","k8s.gcr.io/kube-scheduler:v1.24.3"],"sizeBytes":50989989},{"names":["k8s.gcr.io/coredns/coredns@sha256:5b6ec0d6de9baaf3e92d0f66cd96a25b9edbce8716f5f15dcd1a616b3abd590e","k8s.gcr.io/coredns/coredns:v1.8.6"],"sizeBytes":46829283},{"names":["gcr.io/k8s-minikube/storage-provisioner@sha256:18eb69d1418e854ad5a19e399310e52808a8321e4c441c1dddad8977a0d7a944","gcr.io/k8s-minikube/storage-provisioner:v5"],"sizeBytes":31465472},{"names":["k8s.gcr.io/pause@sha256:bb6ed397957e9ca7c65ada0db5c5d1c707c9c8afc80a94acbe69f3ae76988f0c","k8s.gcr.io/pause:3.7"],"sizeBytes":711184},{"names":["k8s.gcr.io/pause@sha256:3d380ca8864549e74af4b29c10f9cb0956236dfb01c40ca076fb6c37253234db","k8s.gcr.io/pause:3.6"],"sizeBytes":682696}]}}]}
I0920 05:15:06.976006    7432 node_conditions.go:122] node storage ephemeral capacity is 263174212Ki
I0920 05:15:06.976006    7432 node_conditions.go:123] node cpu capacity is 12
I0920 05:15:06.976006    7432 node_conditions.go:105] duration metric: took 4.8781ms to run NodePressure ...
I0920 05:15:06.976006    7432 start.go:216] waiting for startup goroutines ...
I0920 05:15:07.062414    7432 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:55721 SSHKeyPath:C:\Users\Esteban\.minikube\machines\minikube\id_rsa Username:docker}
I0920 05:15:07.077301    7432 addons.go:345] installing /etc/kubernetes/addons/storageclass.yaml
I0920 05:15:07.077301    7432 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storageclass.yaml (271 bytes)
I0920 05:15:07.090146    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0920 05:15:07.181005    7432 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.24.3/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml
I0920 05:15:07.261961    7432 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:55721 SSHKeyPath:C:\Users\Esteban\.minikube\machines\minikube\id_rsa Username:docker}
I0920 05:15:07.368645    7432 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.24.3/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml
I0920 05:15:07.383520    7432 command_runner.go:130] > serviceaccount/storage-provisioner created
I0920 05:15:07.383520    7432 command_runner.go:130] > clusterrolebinding.rbac.authorization.k8s.io/storage-provisioner created
I0920 05:15:07.383520    7432 command_runner.go:130] > role.rbac.authorization.k8s.io/system:persistent-volume-provisioner created
I0920 05:15:07.383520    7432 command_runner.go:130] > rolebinding.rbac.authorization.k8s.io/system:persistent-volume-provisioner created
I0920 05:15:07.383520    7432 command_runner.go:130] > endpoints/k8s.io-minikube-hostpath created
I0920 05:15:07.383520    7432 command_runner.go:130] > pod/storage-provisioner created
I0920 05:15:07.539001    7432 command_runner.go:130] > storageclass.storage.k8s.io/standard created
I0920 05:15:07.545454    7432 out.go:177] * Enabled addons: storage-provisioner, default-storageclass
I0920 05:15:07.547573    7432 addons.go:414] enableAddons completed in 961.2296ms
I0920 05:15:07.550209    7432 out.go:177] 
I0920 05:15:07.552869    7432 config.go:180] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.24.3
I0920 05:15:07.552869    7432 profile.go:148] Saving config to C:\Users\Esteban\.minikube\profiles\minikube\config.json ...
I0920 05:15:07.557769    7432 out.go:177] * Starting worker node minikube-m02 in cluster minikube
I0920 05:15:07.560435    7432 cache.go:120] Beginning downloading kic base image for docker with docker
I0920 05:15:07.565715    7432 out.go:177] * Pulling base image ...
I0920 05:15:07.567859    7432 preload.go:132] Checking if preload exists for k8s version v1.24.3 and runtime docker
I0920 05:15:07.567859    7432 cache.go:57] Caching tarball of preloaded images
I0920 05:15:07.567859    7432 image.go:75] Checking for gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 in local docker daemon
I0920 05:15:07.567859    7432 preload.go:174] Found C:\Users\Esteban\.minikube\cache\preloaded-tarball\preloaded-images-k8s-v18-v1.24.3-docker-overlay2-amd64.tar.lz4 in cache, skipping download
I0920 05:15:07.567859    7432 cache.go:60] Finished verifying existence of preloaded tar for  v1.24.3 on docker
I0920 05:15:07.567859    7432 profile.go:148] Saving config to C:\Users\Esteban\.minikube\profiles\minikube\config.json ...
I0920 05:15:07.726968    7432 image.go:79] Found gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 in local docker daemon, skipping pull
I0920 05:15:07.726968    7432 cache.go:142] gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 exists in daemon, skipping load
I0920 05:15:07.726968    7432 cache.go:208] Successfully downloaded all kic artifacts
I0920 05:15:07.726968    7432 start.go:371] acquiring machines lock for minikube-m02: {Name:mkae95bbcd48f3fd5d8c3d393037555313458e36 Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I0920 05:15:07.726968    7432 start.go:375] acquired machines lock for "minikube-m02" in 0s
I0920 05:15:07.726968    7432 start.go:92] Provisioning new machine with config: &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 Memory:2200 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.24.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.24.3 ContainerRuntime:docker ControlPlane:true Worker:true} {Name:m02 IP: Port:0 KubernetesVersion:v1.24.3 ContainerRuntime:docker ControlPlane:false Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:true ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:C:\Users\Esteban:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath:} &{Name:m02 IP: Port:0 KubernetesVersion:v1.24.3 ContainerRuntime:docker ControlPlane:false Worker:true}
I0920 05:15:07.727474    7432 start.go:132] createHost starting for "m02" (driver="docker")
I0920 05:15:07.730170    7432 out.go:204] * Creating docker container (CPUs=2, Memory=2200MB) ...
I0920 05:15:07.730170    7432 start.go:166] libmachine.API.Create for "minikube" (driver="docker")
I0920 05:15:07.730170    7432 client.go:168] LocalClient.Create starting
I0920 05:15:07.730170    7432 main.go:134] libmachine: Reading certificate data from C:\Users\Esteban\.minikube\certs\ca.pem
I0920 05:15:07.730691    7432 main.go:134] libmachine: Decoding PEM data...
I0920 05:15:07.730691    7432 main.go:134] libmachine: Parsing certificate...
I0920 05:15:07.730691    7432 main.go:134] libmachine: Reading certificate data from C:\Users\Esteban\.minikube\certs\cert.pem
I0920 05:15:07.730691    7432 main.go:134] libmachine: Decoding PEM data...
I0920 05:15:07.730691    7432 main.go:134] libmachine: Parsing certificate...
I0920 05:15:07.745439    7432 cli_runner.go:164] Run: docker network inspect minikube --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}"
I0920 05:15:07.898495    7432 network_create.go:76] Found existing network {name:minikube subnet:0xc00120ffb0 gateway:[0 0 0 0 0 0 0 0 0 0 255 255 192 168 49 1] mtu:1500}
I0920 05:15:07.898495    7432 kic.go:106] calculated static IP "192.168.49.3" for the "minikube-m02" container
I0920 05:15:07.919270    7432 cli_runner.go:164] Run: docker ps -a --format {{.Names}}
I0920 05:15:08.079112    7432 cli_runner.go:164] Run: docker volume create minikube-m02 --label name.minikube.sigs.k8s.io=minikube-m02 --label created_by.minikube.sigs.k8s.io=true
I0920 05:15:08.225169    7432 oci.go:103] Successfully created a docker volume minikube-m02
I0920 05:15:08.236393    7432 cli_runner.go:164] Run: docker run --rm --name minikube-m02-preload-sidecar --label created_by.minikube.sigs.k8s.io=true --label name.minikube.sigs.k8s.io=minikube-m02 --entrypoint /usr/bin/test -v minikube-m02:/var gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 -d /var/lib
I0920 05:15:09.605619    7432 cli_runner.go:217] Completed: docker run --rm --name minikube-m02-preload-sidecar --label created_by.minikube.sigs.k8s.io=true --label name.minikube.sigs.k8s.io=minikube-m02 --entrypoint /usr/bin/test -v minikube-m02:/var gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 -d /var/lib: (1.3692256s)
I0920 05:15:09.605619    7432 oci.go:107] Successfully prepared a docker volume minikube-m02
I0920 05:15:09.605619    7432 preload.go:132] Checking if preload exists for k8s version v1.24.3 and runtime docker
I0920 05:15:09.605619    7432 kic.go:179] Starting extracting preloaded images to volume ...
I0920 05:15:09.615797    7432 cli_runner.go:164] Run: docker run --rm --entrypoint /usr/bin/tar -v C:\Users\Esteban\.minikube\cache\preloaded-tarball\preloaded-images-k8s-v18-v1.24.3-docker-overlay2-amd64.tar.lz4:/preloaded.tar:ro -v minikube-m02:/extractDir gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 -I lz4 -xf /preloaded.tar -C /extractDir
I0920 05:15:38.483136    7432 cli_runner.go:217] Completed: docker run --rm --entrypoint /usr/bin/tar -v C:\Users\Esteban\.minikube\cache\preloaded-tarball\preloaded-images-k8s-v18-v1.24.3-docker-overlay2-amd64.tar.lz4:/preloaded.tar:ro -v minikube-m02:/extractDir gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 -I lz4 -xf /preloaded.tar -C /extractDir: (28.8673395s)
I0920 05:15:38.483136    7432 kic.go:188] duration metric: took 28.877518 seconds to extract preloaded images to volume
I0920 05:15:38.499837    7432 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0920 05:15:39.353503    7432 info.go:265] docker info: {ID:L7ZV:4RQ3:VGXF:PEOU:J5XA:5F73:RDPM:ANUF:ZH5V:B6LC:XKSZ:SFZC Containers:1 ContainersRunning:1 ContainersPaused:0 ContainersStopped:0 Images:6 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:true KernelMemoryTCP:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:62 OomKillDisable:true NGoroutines:57 SystemTime:2022-09-20 10:15:38.7203505 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:5 KernelVersion:5.10.102.1-microsoft-standard-WSL2 OperatingSystem:Docker Desktop OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:12 MemTotal:13233201152 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http.docker.internal:3128 HTTPSProxy:http.docker.internal:3128 NoProxy:hubproxy.docker.internal Name:docker-desktop Labels:[] ExperimentalBuild:false ServerVersion:20.10.16 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:212e8b6fa2f44b9c21b2798135fc6fb7c53efc16 Expected:212e8b6fa2f44b9c21b2798135fc6fb7c53efc16} RuncCommit:{ID:v1.1.1-0-g52de29d Expected:v1.1.1-0-g52de29d} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=default] ProductLicense: Warnings:[WARNING: No blkio throttle.read_bps_device support WARNING: No blkio throttle.write_bps_device support WARNING: No blkio throttle.read_iops_device support WARNING: No blkio throttle.write_iops_device support] ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:C:\Program Files\Docker\cli-plugins\docker-buildx.exe SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.8.2] map[Name:compose Path:C:\Program Files\Docker\cli-plugins\docker-compose.exe SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.6.0] map[Name:sbom Path:C:\Program Files\Docker\cli-plugins\docker-sbom.exe SchemaVersion:0.1.0 ShortDescription:View the packaged-based Software Bill Of Materials (SBOM) for an image URL:https://github.com/docker/sbom-cli-plugin Vendor:Anchore Inc. Version:0.6.0] map[Name:scan Path:C:\Program Files\Docker\cli-plugins\docker-scan.exe SchemaVersion:0.1.0 ShortDescription:Docker Scan Vendor:Docker Inc. Version:v0.17.0]] Warnings:<nil>}}
I0920 05:15:39.365547    7432 cli_runner.go:164] Run: docker info --format "'{{json .SecurityOptions}}'"
I0920 05:15:39.784660    7432 cli_runner.go:164] Run: docker run -d -t --privileged --security-opt seccomp=unconfined --tmpfs /tmp --tmpfs /run -v /lib/modules:/lib/modules:ro --hostname minikube-m02 --name minikube-m02 --label created_by.minikube.sigs.k8s.io=true --label name.minikube.sigs.k8s.io=minikube-m02 --label role.minikube.sigs.k8s.io= --label mode.minikube.sigs.k8s.io=minikube-m02 --network minikube --ip 192.168.49.3 --volume minikube-m02:/var --security-opt apparmor=unconfined --memory=2200mb --memory-swap=2200mb --cpus=2 -e container=docker --expose 8443 --publish=127.0.0.1::8443 --publish=127.0.0.1::22 --publish=127.0.0.1::2376 --publish=127.0.0.1::5000 --publish=127.0.0.1::32443 gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8
I0920 05:15:41.552081    7432 cli_runner.go:217] Completed: docker run -d -t --privileged --security-opt seccomp=unconfined --tmpfs /tmp --tmpfs /run -v /lib/modules:/lib/modules:ro --hostname minikube-m02 --name minikube-m02 --label created_by.minikube.sigs.k8s.io=true --label name.minikube.sigs.k8s.io=minikube-m02 --label role.minikube.sigs.k8s.io= --label mode.minikube.sigs.k8s.io=minikube-m02 --network minikube --ip 192.168.49.3 --volume minikube-m02:/var --security-opt apparmor=unconfined --memory=2200mb --memory-swap=2200mb --cpus=2 -e container=docker --expose 8443 --publish=127.0.0.1::8443 --publish=127.0.0.1::22 --publish=127.0.0.1::2376 --publish=127.0.0.1::5000 --publish=127.0.0.1::32443 gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8: (1.7673302s)
I0920 05:15:41.566217    7432 cli_runner.go:164] Run: docker container inspect minikube-m02 --format={{.State.Running}}
I0920 05:15:41.841726    7432 cli_runner.go:164] Run: docker container inspect minikube-m02 --format={{.State.Status}}
I0920 05:15:42.117120    7432 cli_runner.go:164] Run: docker exec minikube-m02 stat /var/lib/dpkg/alternatives/iptables
I0920 05:15:42.441996    7432 oci.go:144] the created container "minikube-m02" has a running status.
I0920 05:15:42.441996    7432 kic.go:210] Creating ssh key for kic: C:\Users\Esteban\.minikube\machines\minikube-m02\id_rsa...
I0920 05:15:42.863761    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\machines\minikube-m02\id_rsa.pub -> /home/docker/.ssh/authorized_keys
I0920 05:15:42.874762    7432 kic_runner.go:191] docker (temp): C:\Users\Esteban\.minikube\machines\minikube-m02\id_rsa.pub --> /home/docker/.ssh/authorized_keys (381 bytes)
I0920 05:15:43.303362    7432 cli_runner.go:164] Run: docker container inspect minikube-m02 --format={{.State.Status}}
I0920 05:15:43.638359    7432 kic_runner.go:93] Run: chown docker:docker /home/docker/.ssh/authorized_keys
I0920 05:15:43.638359    7432 kic_runner.go:114] Args: [docker exec --privileged minikube-m02 chown docker:docker /home/docker/.ssh/authorized_keys]
I0920 05:15:44.704219    7432 kic_runner.go:123] Done: [docker exec --privileged minikube-m02 chown docker:docker /home/docker/.ssh/authorized_keys]: (1.0658598s)
I0920 05:15:44.711707    7432 kic.go:250] ensuring only current user has permissions to key file located at : C:\Users\Esteban\.minikube\machines\minikube-m02\id_rsa...
I0920 05:15:45.325053    7432 cli_runner.go:164] Run: docker container inspect minikube-m02 --format={{.State.Status}}
I0920 05:15:45.520906    7432 machine.go:88] provisioning docker machine ...
I0920 05:15:45.520906    7432 ubuntu.go:169] provisioning hostname "minikube-m02"
I0920 05:15:45.532173    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube-m02
I0920 05:15:45.750084    7432 main.go:134] libmachine: Using SSH client type: native
I0920 05:15:45.750084    7432 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x8d3da0] 0x8d6c00 <nil>  [] 0s} 127.0.0.1 55785 <nil> <nil>}
I0920 05:15:45.750084    7432 main.go:134] libmachine: About to run SSH command:
sudo hostname minikube-m02 && echo "minikube-m02" | sudo tee /etc/hostname
I0920 05:15:45.888911    7432 main.go:134] libmachine: SSH cmd err, output: <nil>: minikube-m02

I0920 05:15:45.901146    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube-m02
I0920 05:15:46.098749    7432 main.go:134] libmachine: Using SSH client type: native
I0920 05:15:46.099312    7432 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x8d3da0] 0x8d6c00 <nil>  [] 0s} 127.0.0.1 55785 <nil> <nil>}
I0920 05:15:46.099312    7432 main.go:134] libmachine: About to run SSH command:

		if ! grep -xq '.*\sminikube-m02' /etc/hosts; then
			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 minikube-m02/g' /etc/hosts;
			else 
				echo '127.0.1.1 minikube-m02' | sudo tee -a /etc/hosts; 
			fi
		fi
I0920 05:15:46.269025    7432 main.go:134] libmachine: SSH cmd err, output: <nil>: 
I0920 05:15:46.269025    7432 ubuntu.go:175] set auth options {CertDir:C:\Users\Esteban\.minikube CaCertPath:C:\Users\Esteban\.minikube\certs\ca.pem CaPrivateKeyPath:C:\Users\Esteban\.minikube\certs\ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:C:\Users\Esteban\.minikube\machines\server.pem ServerKeyPath:C:\Users\Esteban\.minikube\machines\server-key.pem ClientKeyPath:C:\Users\Esteban\.minikube\certs\key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:C:\Users\Esteban\.minikube\certs\cert.pem ServerCertSANs:[] StorePath:C:\Users\Esteban\.minikube}
I0920 05:15:46.269025    7432 ubuntu.go:177] setting up certificates
I0920 05:15:46.269025    7432 provision.go:83] configureAuth start
I0920 05:15:46.285171    7432 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube-m02
I0920 05:15:46.497616    7432 provision.go:138] copyHostCerts
I0920 05:15:46.497616    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\certs\ca.pem -> C:\Users\Esteban\.minikube/ca.pem
I0920 05:15:46.497616    7432 exec_runner.go:144] found C:\Users\Esteban\.minikube/ca.pem, removing ...
I0920 05:15:46.497616    7432 exec_runner.go:207] rm: C:\Users\Esteban\.minikube\ca.pem
I0920 05:15:46.497616    7432 exec_runner.go:151] cp: C:\Users\Esteban\.minikube\certs\ca.pem --> C:\Users\Esteban\.minikube/ca.pem (1082 bytes)
I0920 05:15:46.499301    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\certs\cert.pem -> C:\Users\Esteban\.minikube/cert.pem
I0920 05:15:46.499301    7432 exec_runner.go:144] found C:\Users\Esteban\.minikube/cert.pem, removing ...
I0920 05:15:46.499301    7432 exec_runner.go:207] rm: C:\Users\Esteban\.minikube\cert.pem
I0920 05:15:46.499301    7432 exec_runner.go:151] cp: C:\Users\Esteban\.minikube\certs\cert.pem --> C:\Users\Esteban\.minikube/cert.pem (1123 bytes)
I0920 05:15:46.500354    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\certs\key.pem -> C:\Users\Esteban\.minikube/key.pem
I0920 05:15:46.500354    7432 exec_runner.go:144] found C:\Users\Esteban\.minikube/key.pem, removing ...
I0920 05:15:46.500354    7432 exec_runner.go:207] rm: C:\Users\Esteban\.minikube\key.pem
I0920 05:15:46.500877    7432 exec_runner.go:151] cp: C:\Users\Esteban\.minikube\certs\key.pem --> C:\Users\Esteban\.minikube/key.pem (1679 bytes)
I0920 05:15:46.501926    7432 provision.go:112] generating server cert: C:\Users\Esteban\.minikube\machines\server.pem ca-key=C:\Users\Esteban\.minikube\certs\ca.pem private-key=C:\Users\Esteban\.minikube\certs\ca-key.pem org=Esteban.minikube-m02 san=[192.168.49.3 127.0.0.1 localhost 127.0.0.1 minikube minikube-m02]
I0920 05:15:46.629938    7432 provision.go:172] copyRemoteCerts
I0920 05:15:46.637938    7432 ssh_runner.go:195] Run: sudo mkdir -p /etc/docker /etc/docker /etc/docker
I0920 05:15:46.649938    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube-m02
I0920 05:15:47.049725    7432 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:55785 SSHKeyPath:C:\Users\Esteban\.minikube\machines\minikube-m02\id_rsa Username:docker}
I0920 05:15:47.153860    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\certs\ca.pem -> /etc/docker/ca.pem
I0920 05:15:47.153860    7432 ssh_runner.go:362] scp C:\Users\Esteban\.minikube\certs\ca.pem --> /etc/docker/ca.pem (1082 bytes)
I0920 05:15:47.174230    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\machines\server.pem -> /etc/docker/server.pem
I0920 05:15:47.174778    7432 ssh_runner.go:362] scp C:\Users\Esteban\.minikube\machines\server.pem --> /etc/docker/server.pem (1216 bytes)
I0920 05:15:47.198454    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\machines\server-key.pem -> /etc/docker/server-key.pem
I0920 05:15:47.198454    7432 ssh_runner.go:362] scp C:\Users\Esteban\.minikube\machines\server-key.pem --> /etc/docker/server-key.pem (1675 bytes)
I0920 05:15:47.221842    7432 provision.go:86] duration metric: configureAuth took 952.8171ms
I0920 05:15:47.221842    7432 ubuntu.go:193] setting minikube options for container-runtime
I0920 05:15:47.240066    7432 config.go:180] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.24.3
I0920 05:15:47.251641    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube-m02
I0920 05:15:47.474331    7432 main.go:134] libmachine: Using SSH client type: native
I0920 05:15:47.474331    7432 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x8d3da0] 0x8d6c00 <nil>  [] 0s} 127.0.0.1 55785 <nil> <nil>}
I0920 05:15:47.474331    7432 main.go:134] libmachine: About to run SSH command:
df --output=fstype / | tail -n 1
I0920 05:15:47.609324    7432 main.go:134] libmachine: SSH cmd err, output: <nil>: overlay

I0920 05:15:47.609324    7432 ubuntu.go:71] root file system type: overlay
I0920 05:15:47.609860    7432 provision.go:309] Updating docker unit: /lib/systemd/system/docker.service ...
I0920 05:15:47.621519    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube-m02
I0920 05:15:47.787720    7432 main.go:134] libmachine: Using SSH client type: native
I0920 05:15:47.788268    7432 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x8d3da0] 0x8d6c00 <nil>  [] 0s} 127.0.0.1 55785 <nil> <nil>}
I0920 05:15:47.788268    7432 main.go:134] libmachine: About to run SSH command:
sudo mkdir -p /lib/systemd/system && printf %s "[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure

Environment="NO_PROXY=192.168.49.2"


# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP \$MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target
" | sudo tee /lib/systemd/system/docker.service.new
I0920 05:15:47.918064    7432 main.go:134] libmachine: SSH cmd err, output: <nil>: [Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure

Environment=NO_PROXY=192.168.49.2


# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP $MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target

I0920 05:15:47.931697    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube-m02
I0920 05:15:48.126776    7432 main.go:134] libmachine: Using SSH client type: native
I0920 05:15:48.127282    7432 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x8d3da0] 0x8d6c00 <nil>  [] 0s} 127.0.0.1 55785 <nil> <nil>}
I0920 05:15:48.127282    7432 main.go:134] libmachine: About to run SSH command:
sudo diff -u /lib/systemd/system/docker.service /lib/systemd/system/docker.service.new || { sudo mv /lib/systemd/system/docker.service.new /lib/systemd/system/docker.service; sudo systemctl -f daemon-reload && sudo systemctl -f enable docker && sudo systemctl -f restart docker; }
I0920 05:15:48.947623    7432 main.go:134] libmachine: SSH cmd err, output: <nil>: --- /lib/systemd/system/docker.service	2022-06-06 23:01:03.000000000 +0000
+++ /lib/systemd/system/docker.service.new	2022-09-20 10:15:47.905928000 +0000
@@ -1,30 +1,33 @@
 [Unit]
 Description=Docker Application Container Engine
 Documentation=https://docs.docker.com
-After=network-online.target docker.socket firewalld.service containerd.service
+BindsTo=containerd.service
+After=network-online.target firewalld.service containerd.service
 Wants=network-online.target
-Requires=docker.socket containerd.service
+Requires=docker.socket
+StartLimitBurst=3
+StartLimitIntervalSec=60
 
 [Service]
 Type=notify
-# the default is not to use systemd for cgroups because the delegate issues still
-# exists and systemd currently does not support the cgroup feature set required
-# for containers run by docker
-ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock
-ExecReload=/bin/kill -s HUP $MAINPID
-TimeoutSec=0
-RestartSec=2
-Restart=always
-
-# Note that StartLimit* options were moved from "Service" to "Unit" in systemd 229.
-# Both the old, and new location are accepted by systemd 229 and up, so using the old location
-# to make them work for either version of systemd.
-StartLimitBurst=3
+Restart=on-failure
 
-# Note that StartLimitInterval was renamed to StartLimitIntervalSec in systemd 230.
-# Both the old, and new name are accepted by systemd 230 and up, so using the old name to make
-# this option work for either version of systemd.
-StartLimitInterval=60s
+Environment=NO_PROXY=192.168.49.2
+
+
+# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
+# The base configuration already specifies an 'ExecStart=...' command. The first directive
+# here is to clear out that command inherited from the base configuration. Without this,
+# the command from the base configuration and the command specified here are treated as
+# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
+# will catch this invalid input and refuse to start the service with an error like:
+#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.
+
+# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
+# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
+ExecStart=
+ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
+ExecReload=/bin/kill -s HUP $MAINPID
 
 # Having non-zero Limit*s causes performance problems due to accounting overhead
 # in the kernel. We recommend using cgroups to do container-local accounting.
@@ -32,16 +35,16 @@
 LimitNPROC=infinity
 LimitCORE=infinity
 
-# Comment TasksMax if your systemd version does not support it.
-# Only systemd 226 and above support this option.
+# Uncomment TasksMax if your systemd version supports it.
+# Only systemd 226 and above support this version.
 TasksMax=infinity
+TimeoutStartSec=0
 
 # set delegate yes so that systemd does not reset the cgroups of docker containers
 Delegate=yes
 
 # kill only the docker process, not all processes in the cgroup
 KillMode=process
-OOMScoreAdjust=-500
 
 [Install]
 WantedBy=multi-user.target
Synchronizing state of docker.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable docker

I0920 05:15:48.947623    7432 machine.go:91] provisioned docker machine in 3.4267167s
I0920 05:15:48.947623    7432 client.go:171] LocalClient.Create took 41.2174532s
I0920 05:15:48.947623    7432 start.go:174] duration metric: libmachine.API.Create for "minikube" took 41.2174532s
I0920 05:15:48.947623    7432 start.go:307] post-start starting for "minikube-m02" (driver="docker")
I0920 05:15:48.947623    7432 start.go:335] creating required directories: [/etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs]
I0920 05:15:48.957485    7432 ssh_runner.go:195] Run: sudo mkdir -p /etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs
I0920 05:15:48.972465    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube-m02
I0920 05:15:49.136078    7432 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:55785 SSHKeyPath:C:\Users\Esteban\.minikube\machines\minikube-m02\id_rsa Username:docker}
I0920 05:15:49.211340    7432 ssh_runner.go:195] Run: cat /etc/os-release
I0920 05:15:49.216206    7432 command_runner.go:130] > NAME="Ubuntu"
I0920 05:15:49.216206    7432 command_runner.go:130] > VERSION="20.04.4 LTS (Focal Fossa)"
I0920 05:15:49.216206    7432 command_runner.go:130] > ID=ubuntu
I0920 05:15:49.216206    7432 command_runner.go:130] > ID_LIKE=debian
I0920 05:15:49.216206    7432 command_runner.go:130] > PRETTY_NAME="Ubuntu 20.04.4 LTS"
I0920 05:15:49.216206    7432 command_runner.go:130] > VERSION_ID="20.04"
I0920 05:15:49.216206    7432 command_runner.go:130] > HOME_URL="https://www.ubuntu.com/"
I0920 05:15:49.216206    7432 command_runner.go:130] > SUPPORT_URL="https://help.ubuntu.com/"
I0920 05:15:49.216206    7432 command_runner.go:130] > BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
I0920 05:15:49.216206    7432 command_runner.go:130] > PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
I0920 05:15:49.216206    7432 command_runner.go:130] > VERSION_CODENAME=focal
I0920 05:15:49.216206    7432 command_runner.go:130] > UBUNTU_CODENAME=focal
I0920 05:15:49.216206    7432 main.go:134] libmachine: Couldn't set key PRIVACY_POLICY_URL, no corresponding struct field found
I0920 05:15:49.216713    7432 main.go:134] libmachine: Couldn't set key VERSION_CODENAME, no corresponding struct field found
I0920 05:15:49.216713    7432 main.go:134] libmachine: Couldn't set key UBUNTU_CODENAME, no corresponding struct field found
I0920 05:15:49.216713    7432 info.go:137] Remote host: Ubuntu 20.04.4 LTS
I0920 05:15:49.216752    7432 filesync.go:126] Scanning C:\Users\Esteban\.minikube\addons for local assets ...
I0920 05:15:49.216752    7432 filesync.go:126] Scanning C:\Users\Esteban\.minikube\files for local assets ...
I0920 05:15:49.216752    7432 start.go:310] post-start completed in 269.1292ms
I0920 05:15:49.234598    7432 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube-m02
I0920 05:15:49.413445    7432 profile.go:148] Saving config to C:\Users\Esteban\.minikube\profiles\minikube\config.json ...
I0920 05:15:49.433930    7432 ssh_runner.go:195] Run: sh -c "df -h /var | awk 'NR==2{print $5}'"
I0920 05:15:49.445101    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube-m02
I0920 05:15:49.661563    7432 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:55785 SSHKeyPath:C:\Users\Esteban\.minikube\machines\minikube-m02\id_rsa Username:docker}
I0920 05:15:49.750324    7432 command_runner.go:130] > 3%
I0920 05:15:49.771278    7432 ssh_runner.go:195] Run: sh -c "df -BG /var | awk 'NR==2{print $4}'"
I0920 05:15:49.778347    7432 command_runner.go:130] > 233G
I0920 05:15:49.778347    7432 start.go:135] duration metric: createHost completed in 42.0508723s
I0920 05:15:49.778347    7432 start.go:82] releasing machines lock for "minikube-m02", held for 42.0513788s
I0920 05:15:49.790583    7432 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube-m02
I0920 05:15:49.955957    7432 out.go:177] * Found network options:
I0920 05:15:49.958479    7432 out.go:177]   - NO_PROXY=192.168.49.2
W0920 05:15:49.960083    7432 proxy.go:118] fail to check proxy env: Error ip not in block
I0920 05:15:49.962240    7432 out.go:177]   - no_proxy=192.168.49.2
W0920 05:15:49.963825    7432 proxy.go:118] fail to check proxy env: Error ip not in block
W0920 05:15:49.963825    7432 proxy.go:118] fail to check proxy env: Error ip not in block
I0920 05:15:49.968064    7432 ssh_runner.go:195] Run: curl -sS -m 2 https://k8s.gcr.io/
I0920 05:15:49.972917    7432 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/cri-docker.service.d
I0920 05:15:49.980345    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube-m02
I0920 05:15:49.988305    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube-m02
I0920 05:15:50.159060    7432 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:55785 SSHKeyPath:C:\Users\Esteban\.minikube\machines\minikube-m02\id_rsa Username:docker}
I0920 05:15:50.174185    7432 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:55785 SSHKeyPath:C:\Users\Esteban\.minikube\machines\minikube-m02\id_rsa Username:docker}
I0920 05:15:50.558383    7432 command_runner.go:130] > <HTML><HEAD><meta http-equiv="content-type" content="text/html;charset=utf-8">
I0920 05:15:50.558383    7432 command_runner.go:130] > <TITLE>302 Moved</TITLE></HEAD><BODY>
I0920 05:15:50.558383    7432 command_runner.go:130] > <H1>302 Moved</H1>
I0920 05:15:50.558383    7432 command_runner.go:130] > The document has moved
I0920 05:15:50.558383    7432 command_runner.go:130] > <A HREF="https://cloud.google.com/container-registry/">here</A>.
I0920 05:15:50.558383    7432 command_runner.go:130] > </BODY></HTML>
I0920 05:15:50.558383    7432 ssh_runner.go:362] scp memory --> /etc/systemd/system/cri-docker.service.d/10-cni.conf (234 bytes)
I0920 05:15:50.580865    7432 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0920 05:15:50.699582    7432 ssh_runner.go:195] Run: sudo systemctl restart cri-docker
I0920 05:15:50.791695    7432 ssh_runner.go:195] Run: sudo systemctl cat docker.service
I0920 05:15:50.804096    7432 command_runner.go:130] > # /lib/systemd/system/docker.service
I0920 05:15:50.804096    7432 command_runner.go:130] > [Unit]
I0920 05:15:50.804096    7432 command_runner.go:130] > Description=Docker Application Container Engine
I0920 05:15:50.804096    7432 command_runner.go:130] > Documentation=https://docs.docker.com
I0920 05:15:50.804096    7432 command_runner.go:130] > BindsTo=containerd.service
I0920 05:15:50.804096    7432 command_runner.go:130] > After=network-online.target firewalld.service containerd.service
I0920 05:15:50.804096    7432 command_runner.go:130] > Wants=network-online.target
I0920 05:15:50.804096    7432 command_runner.go:130] > Requires=docker.socket
I0920 05:15:50.804096    7432 command_runner.go:130] > StartLimitBurst=3
I0920 05:15:50.804096    7432 command_runner.go:130] > StartLimitIntervalSec=60
I0920 05:15:50.804096    7432 command_runner.go:130] > [Service]
I0920 05:15:50.804096    7432 command_runner.go:130] > Type=notify
I0920 05:15:50.804096    7432 command_runner.go:130] > Restart=on-failure
I0920 05:15:50.804096    7432 command_runner.go:130] > Environment=NO_PROXY=192.168.49.2
I0920 05:15:50.804096    7432 command_runner.go:130] > # This file is a systemd drop-in unit that inherits from the base dockerd configuration.
I0920 05:15:50.804096    7432 command_runner.go:130] > # The base configuration already specifies an 'ExecStart=...' command. The first directive
I0920 05:15:50.804096    7432 command_runner.go:130] > # here is to clear out that command inherited from the base configuration. Without this,
I0920 05:15:50.804096    7432 command_runner.go:130] > # the command from the base configuration and the command specified here are treated as
I0920 05:15:50.804096    7432 command_runner.go:130] > # a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
I0920 05:15:50.804096    7432 command_runner.go:130] > # will catch this invalid input and refuse to start the service with an error like:
I0920 05:15:50.804096    7432 command_runner.go:130] > #  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.
I0920 05:15:50.804096    7432 command_runner.go:130] > # NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
I0920 05:15:50.804096    7432 command_runner.go:130] > # container runtimes. If left unlimited, it may result in OOM issues with MySQL.
I0920 05:15:50.804096    7432 command_runner.go:130] > ExecStart=
I0920 05:15:50.804602    7432 command_runner.go:130] > ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
I0920 05:15:50.804602    7432 command_runner.go:130] > ExecReload=/bin/kill -s HUP $MAINPID
I0920 05:15:50.804602    7432 command_runner.go:130] > # Having non-zero Limit*s causes performance problems due to accounting overhead
I0920 05:15:50.804621    7432 command_runner.go:130] > # in the kernel. We recommend using cgroups to do container-local accounting.
I0920 05:15:50.804627    7432 command_runner.go:130] > LimitNOFILE=infinity
I0920 05:15:50.804627    7432 command_runner.go:130] > LimitNPROC=infinity
I0920 05:15:50.804627    7432 command_runner.go:130] > LimitCORE=infinity
I0920 05:15:50.804627    7432 command_runner.go:130] > # Uncomment TasksMax if your systemd version supports it.
I0920 05:15:50.804627    7432 command_runner.go:130] > # Only systemd 226 and above support this version.
I0920 05:15:50.804627    7432 command_runner.go:130] > TasksMax=infinity
I0920 05:15:50.804627    7432 command_runner.go:130] > TimeoutStartSec=0
I0920 05:15:50.804627    7432 command_runner.go:130] > # set delegate yes so that systemd does not reset the cgroups of docker containers
I0920 05:15:50.804627    7432 command_runner.go:130] > Delegate=yes
I0920 05:15:50.804627    7432 command_runner.go:130] > # kill only the docker process, not all processes in the cgroup
I0920 05:15:50.804627    7432 command_runner.go:130] > KillMode=process
I0920 05:15:50.804627    7432 command_runner.go:130] > [Install]
I0920 05:15:50.804627    7432 command_runner.go:130] > WantedBy=multi-user.target
I0920 05:15:50.804627    7432 cruntime.go:273] skipping containerd shutdown because we are bound to it
I0920 05:15:50.811574    7432 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service crio
I0920 05:15:50.822698    7432 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %s "runtime-endpoint: unix:///var/run/cri-dockerd.sock
image-endpoint: unix:///var/run/cri-dockerd.sock
" | sudo tee /etc/crictl.yaml"
I0920 05:15:50.837268    7432 command_runner.go:130] > runtime-endpoint: unix:///var/run/cri-dockerd.sock
I0920 05:15:50.837268    7432 command_runner.go:130] > image-endpoint: unix:///var/run/cri-dockerd.sock
I0920 05:15:50.844142    7432 ssh_runner.go:195] Run: sudo systemctl unmask docker.service
I0920 05:15:50.943139    7432 ssh_runner.go:195] Run: sudo systemctl enable docker.socket
I0920 05:15:51.042177    7432 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0920 05:15:51.156215    7432 ssh_runner.go:195] Run: sudo systemctl restart docker
I0920 05:15:51.420849    7432 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I0920 05:15:51.430849    7432 command_runner.go:130] ! Created symlink /etc/systemd/system/sockets.target.wants/cri-docker.socket → /lib/systemd/system/cri-docker.socket.
I0920 05:15:51.522358    7432 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0920 05:15:51.632724    7432 ssh_runner.go:195] Run: sudo systemctl start cri-docker.socket
I0920 05:15:51.646508    7432 start.go:450] Will wait 60s for socket path /var/run/cri-dockerd.sock
I0920 05:15:51.665103    7432 ssh_runner.go:195] Run: stat /var/run/cri-dockerd.sock
I0920 05:15:51.669940    7432 command_runner.go:130] >   File: /var/run/cri-dockerd.sock
I0920 05:15:51.669940    7432 command_runner.go:130] >   Size: 0         	Blocks: 0          IO Block: 4096   socket
I0920 05:15:51.669940    7432 command_runner.go:130] > Device: 10008ah/1048714d	Inode: 136         Links: 1
I0920 05:15:51.669940    7432 command_runner.go:130] > Access: (0660/srw-rw----)  Uid: (    0/    root)   Gid: (  999/  docker)
I0920 05:15:51.669940    7432 command_runner.go:130] > Access: 2022-09-20 10:15:50.695928000 +0000
I0920 05:15:51.669940    7432 command_runner.go:130] > Modify: 2022-09-20 10:15:50.695928000 +0000
I0920 05:15:51.669940    7432 command_runner.go:130] > Change: 2022-09-20 10:15:50.695928000 +0000
I0920 05:15:51.669940    7432 command_runner.go:130] >  Birth: -
I0920 05:15:51.669940    7432 start.go:471] Will wait 60s for crictl version
I0920 05:15:51.676804    7432 ssh_runner.go:195] Run: sudo crictl version
I0920 05:15:51.705235    7432 command_runner.go:130] > Version:  0.1.0
I0920 05:15:51.705251    7432 command_runner.go:130] > RuntimeName:  docker
I0920 05:15:51.705276    7432 command_runner.go:130] > RuntimeVersion:  20.10.17
I0920 05:15:51.705299    7432 command_runner.go:130] > RuntimeApiVersion:  1.41.0
I0920 05:15:51.705307    7432 start.go:480] Version:  0.1.0
RuntimeName:  docker
RuntimeVersion:  20.10.17
RuntimeApiVersion:  1.41.0
I0920 05:15:51.716650    7432 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0920 05:15:51.751713    7432 command_runner.go:130] > 20.10.17
I0920 05:15:51.763500    7432 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0920 05:15:51.794508    7432 command_runner.go:130] > 20.10.17
I0920 05:15:51.798239    7432 out.go:204] * Preparing Kubernetes v1.24.3 on Docker 20.10.17 ...
I0920 05:15:51.800380    7432 out.go:177]   - env NO_PROXY=192.168.49.2
I0920 05:15:51.813003    7432 cli_runner.go:164] Run: docker exec -t minikube-m02 dig +short host.docker.internal
I0920 05:15:52.102198    7432 network.go:96] got host ip for mount in container by digging dns: 192.168.65.2
I0920 05:15:52.120607    7432 ssh_runner.go:195] Run: grep 192.168.65.2	host.minikube.internal$ /etc/hosts
I0920 05:15:52.125210    7432 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\thost.minikube.internal$' "/etc/hosts"; echo "192.168.65.2	host.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0920 05:15:52.135825    7432 certs.go:54] Setting up C:\Users\Esteban\.minikube\profiles\minikube for IP: 192.168.49.3
I0920 05:15:52.135825    7432 certs.go:182] skipping minikubeCA CA generation: C:\Users\Esteban\.minikube\ca.key
I0920 05:15:52.136894    7432 certs.go:182] skipping proxyClientCA CA generation: C:\Users\Esteban\.minikube\proxy-client-ca.key
I0920 05:15:52.136894    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\ca.crt -> /var/lib/minikube/certs/ca.crt
I0920 05:15:52.136894    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\ca.key -> /var/lib/minikube/certs/ca.key
I0920 05:15:52.136894    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\proxy-client-ca.crt -> /var/lib/minikube/certs/proxy-client-ca.crt
I0920 05:15:52.136894    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\proxy-client-ca.key -> /var/lib/minikube/certs/proxy-client-ca.key
I0920 05:15:52.137433    7432 certs.go:388] found cert: C:\Users\Esteban\.minikube\certs\C:\Users\Esteban\.minikube\certs\ca-key.pem (1675 bytes)
I0920 05:15:52.137433    7432 certs.go:388] found cert: C:\Users\Esteban\.minikube\certs\C:\Users\Esteban\.minikube\certs\ca.pem (1082 bytes)
I0920 05:15:52.137433    7432 certs.go:388] found cert: C:\Users\Esteban\.minikube\certs\C:\Users\Esteban\.minikube\certs\cert.pem (1123 bytes)
I0920 05:15:52.137952    7432 certs.go:388] found cert: C:\Users\Esteban\.minikube\certs\C:\Users\Esteban\.minikube\certs\key.pem (1679 bytes)
I0920 05:15:52.137998    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\ca.crt -> /usr/share/ca-certificates/minikubeCA.pem
I0920 05:15:52.137998    7432 ssh_runner.go:362] scp C:\Users\Esteban\.minikube\ca.crt --> /var/lib/minikube/certs/ca.crt (1111 bytes)
I0920 05:15:52.159871    7432 ssh_runner.go:362] scp C:\Users\Esteban\.minikube\ca.key --> /var/lib/minikube/certs/ca.key (1675 bytes)
I0920 05:15:52.183006    7432 ssh_runner.go:362] scp C:\Users\Esteban\.minikube\proxy-client-ca.crt --> /var/lib/minikube/certs/proxy-client-ca.crt (1119 bytes)
I0920 05:15:52.206022    7432 ssh_runner.go:362] scp C:\Users\Esteban\.minikube\proxy-client-ca.key --> /var/lib/minikube/certs/proxy-client-ca.key (1675 bytes)
I0920 05:15:52.227098    7432 ssh_runner.go:362] scp C:\Users\Esteban\.minikube\ca.crt --> /usr/share/ca-certificates/minikubeCA.pem (1111 bytes)
I0920 05:15:52.256544    7432 ssh_runner.go:195] Run: openssl version
I0920 05:15:52.262359    7432 command_runner.go:130] > OpenSSL 1.1.1f  31 Mar 2020
I0920 05:15:52.269229    7432 ssh_runner.go:195] Run: sudo /bin/bash -c "test -s /usr/share/ca-certificates/minikubeCA.pem && ln -fs /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem"
I0920 05:15:52.284176    7432 ssh_runner.go:195] Run: ls -la /usr/share/ca-certificates/minikubeCA.pem
I0920 05:15:52.288520    7432 command_runner.go:130] > -rw-r--r-- 1 root root 1111 Sep 20 09:09 /usr/share/ca-certificates/minikubeCA.pem
I0920 05:15:52.288520    7432 certs.go:431] hashing: -rw-r--r-- 1 root root 1111 Sep 20 09:09 /usr/share/ca-certificates/minikubeCA.pem
I0920 05:15:52.295970    7432 ssh_runner.go:195] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
I0920 05:15:52.301412    7432 command_runner.go:130] > b5213941
I0920 05:15:52.308246    7432 ssh_runner.go:195] Run: sudo /bin/bash -c "test -L /etc/ssl/certs/b5213941.0 || ln -fs /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0"
I0920 05:15:52.329257    7432 ssh_runner.go:195] Run: docker info --format {{.CgroupDriver}}
I0920 05:15:52.405220    7432 command_runner.go:130] > cgroupfs
I0920 05:15:52.406491    7432 cni.go:95] Creating CNI manager for ""
I0920 05:15:52.406491    7432 cni.go:156] 2 nodes found, recommending kindnet
I0920 05:15:52.406491    7432 kubeadm.go:87] Using pod CIDR: 10.244.0.0/16
I0920 05:15:52.406491    7432 kubeadm.go:158] kubeadm options: {CertDir:/var/lib/minikube/certs ServiceCIDR:10.96.0.0/12 PodSubnet:10.244.0.0/16 AdvertiseAddress:192.168.49.3 APIServerPort:8443 KubernetesVersion:v1.24.3 EtcdDataDir:/var/lib/minikube/etcd EtcdExtraArgs:map[] ClusterName:minikube NodeName:minikube-m02 DNSDomain:cluster.local CRISocket:/var/run/cri-dockerd.sock ImageRepository: ComponentOptions:[{Component:apiServer ExtraArgs:map[enable-admission-plugins:NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota] Pairs:map[certSANs:["127.0.0.1", "localhost", "192.168.49.2"]]} {Component:controllerManager ExtraArgs:map[allocate-node-cidrs:true leader-elect:false] Pairs:map[]} {Component:scheduler ExtraArgs:map[leader-elect:false] Pairs:map[]}] FeatureArgs:map[] NoTaintMaster:true NodeIP:192.168.49.3 CgroupDriver:cgroupfs ClientCAFile:/var/lib/minikube/certs/ca.crt StaticPodPath:/etc/kubernetes/manifests ControlPlaneAddress:control-plane.minikube.internal KubeProxyOptions:map[]}
I0920 05:15:52.406491    7432 kubeadm.go:162] kubeadm config:
apiVersion: kubeadm.k8s.io/v1beta3
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.49.3
  bindPort: 8443
bootstrapTokens:
  - groups:
      - system:bootstrappers:kubeadm:default-node-token
    ttl: 24h0m0s
    usages:
      - signing
      - authentication
nodeRegistration:
  criSocket: /var/run/cri-dockerd.sock
  name: "minikube-m02"
  kubeletExtraArgs:
    node-ip: 192.168.49.3
  taints: []
---
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
apiServer:
  certSANs: ["127.0.0.1", "localhost", "192.168.49.2"]
  extraArgs:
    enable-admission-plugins: "NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota"
controllerManager:
  extraArgs:
    allocate-node-cidrs: "true"
    leader-elect: "false"
scheduler:
  extraArgs:
    leader-elect: "false"
certificatesDir: /var/lib/minikube/certs
clusterName: mk
controlPlaneEndpoint: control-plane.minikube.internal:8443
etcd:
  local:
    dataDir: /var/lib/minikube/etcd
    extraArgs:
      proxy-refresh-interval: "70000"
kubernetesVersion: v1.24.3
networking:
  dnsDomain: cluster.local
  podSubnet: "10.244.0.0/16"
  serviceSubnet: 10.96.0.0/12
---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
authentication:
  x509:
    clientCAFile: /var/lib/minikube/certs/ca.crt
cgroupDriver: cgroupfs
clusterDomain: "cluster.local"
# disable disk resource management by default
imageGCHighThresholdPercent: 100
evictionHard:
  nodefs.available: "0%"
  nodefs.inodesFree: "0%"
  imagefs.available: "0%"
failSwapOn: false
staticPodPath: /etc/kubernetes/manifests
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
clusterCIDR: "10.244.0.0/16"
metricsBindAddress: 0.0.0.0:10249
conntrack:
  maxPerCore: 0
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_established"
  tcpEstablishedTimeout: 0s
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_close"
  tcpCloseWaitTimeout: 0s

I0920 05:15:52.406491    7432 kubeadm.go:961] kubelet [Unit]
Wants=docker.socket

[Service]
ExecStart=
ExecStart=/var/lib/minikube/binaries/v1.24.3/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --config=/var/lib/kubelet/config.yaml --container-runtime=remote --container-runtime-endpoint=/var/run/cri-dockerd.sock --hostname-override=minikube-m02 --image-service-endpoint=/var/run/cri-dockerd.sock --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=192.168.49.3 --runtime-request-timeout=15m

[Install]
 config:
{KubernetesVersion:v1.24.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:}
I0920 05:15:52.413414    7432 ssh_runner.go:195] Run: sudo ls /var/lib/minikube/binaries/v1.24.3
I0920 05:15:52.422930    7432 command_runner.go:130] > kubeadm
I0920 05:15:52.422930    7432 command_runner.go:130] > kubectl
I0920 05:15:52.422930    7432 command_runner.go:130] > kubelet
I0920 05:15:52.422954    7432 binaries.go:44] Found k8s binaries, skipping transfer
I0920 05:15:52.430056    7432 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/kubelet.service.d /lib/systemd/system
I0920 05:15:52.439328    7432 ssh_runner.go:362] scp memory --> /etc/systemd/system/kubelet.service.d/10-kubeadm.conf (474 bytes)
I0920 05:15:52.454684    7432 ssh_runner.go:362] scp memory --> /lib/systemd/system/kubelet.service (352 bytes)
I0920 05:15:52.488922    7432 ssh_runner.go:195] Run: grep 192.168.49.2	control-plane.minikube.internal$ /etc/hosts
I0920 05:15:52.493589    7432 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\tcontrol-plane.minikube.internal$' "/etc/hosts"; echo "192.168.49.2	control-plane.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0920 05:15:52.504181    7432 host.go:66] Checking if "minikube" exists ...
I0920 05:15:52.504775    7432 config.go:180] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.24.3
I0920 05:15:52.505306    7432 start.go:285] JoinCluster: &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 Memory:2200 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.24.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.24.3 ContainerRuntime:docker ControlPlane:true Worker:true} {Name:m02 IP:192.168.49.3 Port:0 KubernetesVersion:v1.24.3 ContainerRuntime:docker ControlPlane:false Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:true ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:C:\Users\Esteban:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath:}
I0920 05:15:52.506356    7432 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.24.3:$PATH" kubeadm token create --print-join-command --ttl=0"
I0920 05:15:52.516496    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0920 05:15:52.671364    7432 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:55721 SSHKeyPath:C:\Users\Esteban\.minikube\machines\minikube\id_rsa Username:docker}
I0920 05:15:52.824254    7432 command_runner.go:130] > kubeadm join control-plane.minikube.internal:8443 --token iiorww.1c1gyh48sue0xo39 --discovery-token-ca-cert-hash sha256:73202b2265c3b3018d12119f3c78685654b918967fd5f268db3bf3b4d7e92013 
I0920 05:15:52.824322    7432 start.go:306] trying to join worker node "m02" to cluster: &{Name:m02 IP:192.168.49.3 Port:0 KubernetesVersion:v1.24.3 ContainerRuntime:docker ControlPlane:false Worker:true}
I0920 05:15:52.824322    7432 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.24.3:$PATH" kubeadm join control-plane.minikube.internal:8443 --token iiorww.1c1gyh48sue0xo39 --discovery-token-ca-cert-hash sha256:73202b2265c3b3018d12119f3c78685654b918967fd5f268db3bf3b4d7e92013 --ignore-preflight-errors=all --cri-socket /var/run/cri-dockerd.sock --node-name=minikube-m02"
I0920 05:15:52.859170    7432 command_runner.go:130] ! W0920 10:15:52.858451    1123 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme "unix" to the "criSocket" with value "/var/run/cri-dockerd.sock". Please update your configuration!
I0920 05:15:52.887098    7432 command_runner.go:130] ! 	[WARNING Swap]: swap is enabled; production deployments should disable swap unless testing the NodeSwap feature gate of the kubelet
I0920 05:15:52.967775    7432 command_runner.go:130] ! 	[WARNING Service-Kubelet]: kubelet service is not enabled, please run 'systemctl enable kubelet.service'
I0920 05:16:06.447532    7432 command_runner.go:130] > [preflight] Running pre-flight checks
I0920 05:16:06.447532    7432 command_runner.go:130] > [preflight] Reading configuration from the cluster...
I0920 05:16:06.447532    7432 command_runner.go:130] > [preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'
I0920 05:16:06.447532    7432 command_runner.go:130] > [kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
I0920 05:16:06.447532    7432 command_runner.go:130] > [kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
I0920 05:16:06.447532    7432 command_runner.go:130] > [kubelet-start] Starting the kubelet
I0920 05:16:06.447532    7432 command_runner.go:130] > [kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...
I0920 05:16:06.447532    7432 command_runner.go:130] > This node has joined the cluster:
I0920 05:16:06.447532    7432 command_runner.go:130] > * Certificate signing request was sent to apiserver and a response was received.
I0920 05:16:06.447532    7432 command_runner.go:130] > * The Kubelet was informed of the new secure connection details.
I0920 05:16:06.447532    7432 command_runner.go:130] > Run 'kubectl get nodes' on the control-plane to see this node join the cluster.
I0920 05:16:06.447532    7432 ssh_runner.go:235] Completed: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.24.3:$PATH" kubeadm join control-plane.minikube.internal:8443 --token iiorww.1c1gyh48sue0xo39 --discovery-token-ca-cert-hash sha256:73202b2265c3b3018d12119f3c78685654b918967fd5f268db3bf3b4d7e92013 --ignore-preflight-errors=all --cri-socket /var/run/cri-dockerd.sock --node-name=minikube-m02": (13.6232103s)
I0920 05:16:06.447532    7432 ssh_runner.go:195] Run: /bin/bash -c "sudo systemctl daemon-reload && sudo systemctl enable kubelet && sudo systemctl start kubelet"
I0920 05:16:06.561820    7432 command_runner.go:130] ! Created symlink /etc/systemd/system/multi-user.target.wants/kubelet.service → /lib/systemd/system/kubelet.service.
I0920 05:16:06.636325    7432 start.go:287] JoinCluster complete in 14.1310186s
I0920 05:16:06.636325    7432 cni.go:95] Creating CNI manager for ""
I0920 05:16:06.636325    7432 cni.go:156] 2 nodes found, recommending kindnet
I0920 05:16:06.658232    7432 ssh_runner.go:195] Run: stat /opt/cni/bin/portmap
I0920 05:16:06.662626    7432 command_runner.go:130] >   File: /opt/cni/bin/portmap
I0920 05:16:06.662626    7432 command_runner.go:130] >   Size: 2828728   	Blocks: 5528       IO Block: 4096   regular file
I0920 05:16:06.662626    7432 command_runner.go:130] > Device: 100011h/1048593d	Inode: 98512       Links: 1
I0920 05:16:06.662626    7432 command_runner.go:130] > Access: (0755/-rwxr-xr-x)  Uid: (    0/    root)   Gid: (    0/    root)
I0920 05:16:06.662626    7432 command_runner.go:130] > Access: 2022-05-18 18:39:21.000000000 +0000
I0920 05:16:06.662626    7432 command_runner.go:130] > Modify: 2022-05-18 18:39:21.000000000 +0000
I0920 05:16:06.662626    7432 command_runner.go:130] > Change: 2022-09-20 09:07:54.348968000 +0000
I0920 05:16:06.662626    7432 command_runner.go:130] >  Birth: -
I0920 05:16:06.662626    7432 cni.go:189] applying CNI manifest using /var/lib/minikube/binaries/v1.24.3/kubectl ...
I0920 05:16:06.662626    7432 ssh_runner.go:362] scp memory --> /var/tmp/minikube/cni.yaml (2429 bytes)
I0920 05:16:06.684934    7432 ssh_runner.go:195] Run: sudo /var/lib/minikube/binaries/v1.24.3/kubectl apply --kubeconfig=/var/lib/minikube/kubeconfig -f /var/tmp/minikube/cni.yaml
I0920 05:16:06.856619    7432 command_runner.go:130] > clusterrole.rbac.authorization.k8s.io/kindnet unchanged
I0920 05:16:06.856619    7432 command_runner.go:130] > clusterrolebinding.rbac.authorization.k8s.io/kindnet unchanged
I0920 05:16:06.856619    7432 command_runner.go:130] > serviceaccount/kindnet unchanged
I0920 05:16:06.857619    7432 command_runner.go:130] > daemonset.apps/kindnet configured
I0920 05:16:06.857619    7432 start.go:211] Will wait 6m0s for node &{Name:m02 IP:192.168.49.3 Port:0 KubernetesVersion:v1.24.3 ContainerRuntime:docker ControlPlane:false Worker:true}
I0920 05:16:06.859618    7432 out.go:177] * Verifying Kubernetes components...
I0920 05:16:06.868618    7432 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service kubelet
I0920 05:16:06.891619    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I0920 05:16:07.070632    7432 loader.go:372] Config loaded from file:  C:\Users\Esteban\.kube\config
I0920 05:16:07.071188    7432 kapi.go:59] client config for minikube: &rest.Config{Host:"https://127.0.0.1:55725", APIPath:"", ContentConfig:rest.ContentConfig{AcceptContentTypes:"", ContentType:"", GroupVersion:(*schema.GroupVersion)(nil), NegotiatedSerializer:runtime.NegotiatedSerializer(nil)}, Username:"", Password:"", BearerToken:"", BearerTokenFile:"", Impersonate:rest.ImpersonationConfig{UserName:"", UID:"", Groups:[]string(nil), Extra:map[string][]string(nil)}, AuthProvider:<nil>, AuthConfigPersister:rest.AuthProviderConfigPersister(nil), ExecProvider:<nil>, TLSClientConfig:rest.sanitizedTLSClientConfig{Insecure:false, ServerName:"", CertFile:"C:\\Users\\Esteban\\.minikube\\profiles\\minikube\\client.crt", KeyFile:"C:\\Users\\Esteban\\.minikube\\profiles\\minikube\\client.key", CAFile:"C:\\Users\\Esteban\\.minikube\\ca.crt", CertData:[]uint8(nil), KeyData:[]uint8(nil), CAData:[]uint8(nil), NextProtos:[]string(nil)}, UserAgent:"", DisableCompression:false, Transport:http.RoundTripper(nil), WrapTransport:(transport.WrapperFunc)(0x1803b20), QPS:0, Burst:0, RateLimiter:flowcontrol.RateLimiter(nil), WarningHandler:rest.WarningHandler(nil), Timeout:0, Dial:(func(context.Context, string, string) (net.Conn, error))(nil), Proxy:(func(*http.Request) (*url.URL, error))(nil)}
I0920 05:16:07.071709    7432 kubeadm.go:572] duration metric: took 214.0897ms to wait for : map[apiserver:true system_pods:true] ...
I0920 05:16:07.071709    7432 node_conditions.go:102] verifying NodePressure condition ...
I0920 05:16:07.071709    7432 round_trippers.go:466] curl -v -XGET  -H "Accept: application/json, */*" -H "User-Agent: minikube.exe/v0.0.0 (windows/amd64) kubernetes/$Format" 'https://127.0.0.1:55725/api/v1/nodes'
I0920 05:16:07.075187    7432 round_trippers.go:553] GET https://127.0.0.1:55725/api/v1/nodes 200 OK in 3 milliseconds
I0920 05:16:07.075187    7432 round_trippers.go:570] HTTP Statistics: GetConnection 0 ms ServerProcessing 3 ms Duration 3 ms
I0920 05:16:07.075187    7432 round_trippers.go:577] Response Headers:
I0920 05:16:07.075187    7432 round_trippers.go:580]     Cache-Control: no-cache, private
I0920 05:16:07.075187    7432 round_trippers.go:580]     Content-Type: application/json
I0920 05:16:07.075187    7432 round_trippers.go:580]     X-Kubernetes-Pf-Flowschema-Uid: 02cd4939-01f5-4b09-a0a9-02b620700246
I0920 05:16:07.075187    7432 round_trippers.go:580]     X-Kubernetes-Pf-Prioritylevel-Uid: fd684f0e-e7d0-4d27-979b-454254971228
I0920 05:16:07.075187    7432 round_trippers.go:580]     Date: Tue, 20 Sep 2022 10:16:07 GMT
I0920 05:16:07.075187    7432 round_trippers.go:580]     Audit-Id: 5f9c61b2-72cd-4b60-ac7a-8ce0deb8c910
I0920 05:16:07.075187    7432 request.go:1073] Response Body: {"kind":"NodeList","apiVersion":"v1","metadata":{"resourceVersion":"449"},"items":[{"metadata":{"name":"minikube","uid":"88395272-a0b5-4a2c-bb07-daf0b9548da3","resourceVersion":"430","creationTimestamp":"2022-09-20T10:15:01Z","labels":{"beta.kubernetes.io/arch":"amd64","beta.kubernetes.io/os":"linux","kubernetes.io/arch":"amd64","kubernetes.io/hostname":"minikube","kubernetes.io/os":"linux","minikube.k8s.io/commit":"62e108c3dfdec8029a890ad6d8ef96b6461426dc","minikube.k8s.io/name":"minikube","minikube.k8s.io/primary":"true","minikube.k8s.io/updated_at":"2022_09_20T05_15_05_0700","minikube.k8s.io/version":"v1.26.1","node-role.kubernetes.io/control-plane":"","node.kubernetes.io/exclude-from-external-load-balancers":""},"annotations":{"kubeadm.alpha.kubernetes.io/cri-socket":"unix:///var/run/cri-dockerd.sock","node.alpha.kubernetes.io/ttl":"0","volumes.kubernetes.io/controller-managed-attach-detach":"true"},"managedFields":[{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-09-20T10:15:01Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:volumes.kubernetes.io/controller-managed-attach-detach":{}},"f:labels":{".":{},"f:beta.kubernetes.io/arch":{},"f:beta.kubernetes.io/os":{},"f:kubernetes.io/arch":{},"f:kubernetes.io/hostname":{},"f:kubernetes.io/os":{}}}}},{"manager":"kubeadm","operation":"Update","apiVersion":"v1","time":"2022-09-20T10:15:04Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{"f:kubeadm.alpha.kubernetes.io/cri-socket":{}},"f:labels":{"f:node-role.kubernetes.io/control-plane":{},"f:node.kubernetes.io/exclude-from-external-load-balancers":{}}}}},{"manager":"kubectl-label","operation":"Update","apiVersion":"v1","time":"2022-09-20T10:15:06Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:labels":{"f:minikube.k8s.io/commit":{},"f:minikube.k8s.io/name":{},"f:minikube.k8s.io/primary":{},"f:minikube.k8s.io/updated_at":{},"f:minikube.k8s.io/version":{}}}}},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-09-20T10:15:17Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{"f:node.alpha.kubernetes.io/ttl":{}}},"f:spec":{"f:podCIDR":{},"f:podCIDRs":{".":{},"v:\"10.244.0.0/24\"":{}}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-09-20T10:15:56Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"DiskPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"MemoryPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"PIDPressure\"}":{"f:lastHeartbeatTime":{}},"k:{\"type\":\"Ready\"}":{"f:lastHeartbeatTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{}}},"f:images":{}}},"subresource":"status"}]},"spec":{"podCIDR":"10.244.0.0/24","podCIDRs":["10.244.0.0/24"]},"status":{"capacity":{"cpu":"12","ephemeral-storage":"263174212Ki","hugepages-1Gi":"0","hugepages-2Mi":"0","memory":"12923048Ki","pods":"110"},"allocatable":{"cpu":"12","ephemeral-storage":"263174212Ki","hugepages-1Gi":"0","hugepages-2Mi":"0","memory":"12923048Ki","pods":"110"},"conditions":[{"type":"MemoryPressure","status":"False","lastHeartbeatTime":"2022-09-20T10:16:06Z","lastTransitionTime":"2022-09-20T10:15:01Z","reason":"KubeletHasSufficientMemory","message":"kubelet has sufficient memory available"},{"type":"DiskPressure","status":"False","lastHeartbeatTime":"2022-09-20T10:16:06Z","lastTransitionTime":"2022-09-20T10:15:01Z","reason":"KubeletHasNoDiskPressure","message":"kubelet has no disk pressure"},{"type":"PIDPressure","status":"False","lastHeartbeatTime":"2022-09-20T10:16:06Z","lastTransitionTime":"2022-09-20T10:15:01Z","reason":"KubeletHasSufficientPID","message":"kubelet has sufficient PID available"},{"type":"Ready","status":"True","lastHeartbeatTime":"2022-09-20T10:16:06Z","lastTransitionTime":"2022-09-20T10:15:56Z","reason":"KubeletReady","message":"kubelet is posting ready status"}],"addresses":[{"type":"InternalIP","address":"192.168.49.2"},{"type":"Hostname","address":"minikube"}],"daemonEndpoints":{"kubeletEndpoint":{"Port":10250}},"nodeInfo":{"machineID":"4c192b04687c403f8fbb9bc7975b21b3","systemUUID":"4c192b04687c403f8fbb9bc7975b21b3","bootID":"de31de94-2a42-4516-a4e6-7cb2de739fde","kernelVersion":"5.10.102.1-microsoft-standard-WSL2","osImage":"Ubuntu 20.04.4 LTS","containerRuntimeVersion":"docker://20.10.17","kubeletVersion":"v1.24.3","kubeProxyVersion":"v1.24.3","operatingSystem":"linux","architecture":"amd64"},"images":[{"names":["k8s.gcr.io/etcd@sha256:13f53ed1d91e2e11aac476ee9a0269fdda6cc4874eba903efd40daf50c55eee5","k8s.gcr.io/etcd:3.5.3-0"],"sizeBytes":299495233},{"names":["k8s.gcr.io/kube-apiserver@sha256:a04609b85962da7e6531d32b75f652b4fb9f5fe0b0ee0aa160856faad8ec5d96","k8s.gcr.io/kube-apiserver:v1.24.3"],"sizeBytes":129710737},{"names":["k8s.gcr.io/kube-controller-manager@sha256:f504eead8b8674ebc9067370ef51abbdc531b4a81813bfe464abccb8c76b6a53","k8s.gcr.io/kube-controller-manager:v1.24.3"],"sizeBytes":119360464},{"names":["k8s.gcr.io/kube-proxy@sha256:c1b135231b5b1a6799346cd701da4b59e5b7ef8e694ec7b04fb23b8dbe144137","k8s.gcr.io/kube-proxy:v1.24.3"],"sizeBytes":109939784},{"names":["kindest/kindnetd@sha256:e2d4d675dcf28a90102ad5219b75c5a0ee096c4321247dfae31dd1467611a9fb","kindest/kindnetd:v20220726-ed811e41"],"sizeBytes":61761170},{"names":["k8s.gcr.io/kube-scheduler@sha256:e199523298224cd9f2a9a43c7c2c37fa57aff87648ed1e1de9984eba6f6005f0","k8s.gcr.io/kube-scheduler:v1.24.3"],"sizeBytes":50989989},{"names":["k8s.gcr.io/coredns/coredns@sha256:5b6ec0d6de9baaf3e92d0f66cd96a25b9edbce8716f5f15dcd1a616b3abd590e","k8s.gcr.io/coredns/coredns:v1.8.6"],"sizeBytes":46829283},{"names":["gcr.io/k8s-minikube/storage-provisioner@sha256:18eb69d1418e854ad5a19e399310e52808a8321e4c441c1dddad8977a0d7a944","gcr.io/k8s-minikube/storage-provisioner:v5"],"sizeBytes":31465472},{"names":["k8s.gcr.io/pause@sha256:bb6ed397957e9ca7c65ada0db5c5d1c707c9c8afc80a94acbe69f3ae76988f0c","k8s.gcr.io/pause:3.7"],"sizeBytes":711184},{"names":["k8s.gcr.io/pause@sha256:3d380ca8864549e74af4b29c10f9cb0956236dfb01c40ca076fb6c37253234db","k8s.gcr.io/pause:3.6"],"sizeBytes":682696}]}},{"metadata":{"name":"minikube-m02","uid":"3948aa81-d5a1-41bd-b626-a754af61513f","resourceVersion":"448","creationTimestamp":"2022-09-20T10:16:06Z","labels":{"beta.kubernetes.io/arch":"amd64","beta.kubernetes.io/os":"linux","kubernetes.io/arch":"amd64","kubernetes.io/hostname":"minikube-m02","kubernetes.io/os":"linux"},"annotations":{"kubeadm.alpha.kubernetes.io/cri-socket":"/var/run/cri-dockerd.sock","node.alpha.kubernetes.io/ttl":"0","volumes.kubernetes.io/controller-managed-attach-detach":"true"},"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-09-20T10:16:06Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{"f:node.alpha.kubernetes.io/ttl":{}}},"f:spec":{"f:podCIDR":{},"f:podCIDRs":{".":{},"v:\"10.244.1.0/24\"":{}},"f:taints":{}}}},{"manager":"kubeadm","operation":"Update","apiVersion":"v1","time":"2022-09-20T10:16:06Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{"f:kubeadm.alpha.kubernetes.io/cri-socket":{}}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-09-20T10:16:06Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:volumes.kubernetes.io/controller-managed-attach-detach":{}},"f:labels":{".":{},"f:beta.kubernetes.io/arch":{},"f:beta.kubernetes.io/os":{},"f:kubernetes.io/arch":{},"f:kubernetes.io/hostname":{},"f:kubernetes.io/os":{}}}}}]},"spec":{"podCIDR":"10.244.1.0/24","podCIDRs":["10.244.1.0/24"],"taints":[{"key":"node.kubernetes.io/not-ready","effect":"NoSchedule"},{"key":"node.kubernetes.io/not-ready","effect":"NoExecute","timeAdded":"2022-09-20T10:16:06Z"}]},"status":{"capacity":{"cpu":"12","ephemeral-storage":"263174212Ki","hugepages-1Gi":"0","hugepages-2Mi":"0","memory":"12923048Ki","pods":"110"},"allocatable":{"cpu":"12","ephemeral-storage":"263174212Ki","hugepages-1Gi":"0","hugepages-2Mi":"0","memory":"12923048Ki","pods":"110"},"conditions":[{"type":"MemoryPressure","status":"False","lastHeartbeatTime":"2022-09-20T10:16:06Z","lastTransitionTime":"2022-09-20T10:16:06Z","reason":"KubeletHasSufficientMemory","message":"kubelet has sufficient memory available"},{"type":"DiskPressure","status":"False","lastHeartbeatTime":"2022-09-20T10:16:06Z","lastTransitionTime":"2022-09-20T10:16:06Z","reason":"KubeletHasNoDiskPressure","message":"kubelet has no disk pressure"},{"type":"PIDPressure","status":"False","lastHeartbeatTime":"2022-09-20T10:16:06Z","lastTransitionTime":"2022-09-20T10:16:06Z","reason":"KubeletHasSufficientPID","message":"kubelet has sufficient PID available"},{"type":"Ready","status":"False","lastHeartbeatTime":"2022-09-20T10:16:06Z","lastTransitionTime":"2022-09-20T10:16:06Z","reason":"KubeletNotReady","message":"[container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:docker: network plugin is not ready: cni config uninitialized, failed to initialize CSINode: error updating CSINode annotation: timed out waiting for the condition; caused by: nodes \"minikube-m02\" not found]"}],"addresses":[{"type":"InternalIP","address":"192.168.49.3"},{"type":"Hostname","address":"minikube-m02"}],"daemonEndpoints":{"kubeletEndpoint":{"Port":10250}},"nodeInfo":{"machineID":"4c192b04687c403f8fbb9bc7975b21b3","systemUUID":"4c192b04687c403f8fbb9bc7975b21b3","bootID":"de31de94-2a42-4516-a4e6-7cb2de739fde","kernelVersion":"5.10.102.1-microsoft-standard-WSL2","osImage":"Ubuntu 20.04.4 LTS","containerRuntimeVersion":"docker://20.10.17","kubeletVersion":"v1.24.3","kubeProxyVersion":"v1.24.3","operatingSystem":"linux","architecture":"amd64"},"images":[{"names":["k8s.gcr.io/etcd@sha256:13f53ed1d91e2e11aac476ee9a0269fdda6cc4874eba903efd40daf50c55eee5","k8s.gcr.io/etcd:3.5.3-0"],"sizeBytes":299495233},{"names":["k8s.gcr.io/kube-apiserver@sha256:a04609b85962da7e6531d32b75f652b4fb9f5fe0b0ee0aa160856faad8ec5d96","k8s.gcr.io/kube-apiserver:v1.24.3"],"sizeBytes":129710737},{"names":["k8s.gcr.io/kube-controller-manager@sha256:f504eead8b8674ebc9067370ef51abbdc531b4a81813bfe464abccb8c76b6a53","k8s.gcr.io/kube-controller-manager:v1.24.3"],"sizeBytes":119360464},{"names":["k8s.gcr.io/kube-proxy@sha256:c1b135231b5b1a6799346cd701da4b59e5b7ef8e694ec7b04fb23b8dbe144137","k8s.gcr.io/kube-proxy:v1.24.3"],"sizeBytes":109939784},{"names":["k8s.gcr.io/kube-scheduler@sha256:e199523298224cd9f2a9a43c7c2c37fa57aff87648ed1e1de9984eba6f6005f0","k8s.gcr.io/kube-scheduler:v1.24.3"],"sizeBytes":50989989},{"names":["k8s.gcr.io/coredns/coredns@sha256:5b6ec0d6de9baaf3e92d0f66cd96a25b9edbce8716f5f15dcd1a616b3abd590e","k8s.gcr.io/coredns/coredns:v1.8.6"],"sizeBytes":46829283},{"names":["gcr.io/k8s-minikube/storage-provisioner@sha256:18eb69d1418e854ad5a19e399310e52808a8321e4c441c1dddad8977a0d7a944","gcr.io/k8s-minikube/storage-provisioner:v5"],"sizeBytes":31465472},{"names":["k8s.gcr.io/pause@sha256:bb6ed397957e9ca7c65ada0db5c5d1c707c9c8afc80a94acbe69f3ae76988f0c","k8s.gcr.io/pause:3.7"],"sizeBytes":711184}]}}]}
I0920 05:16:07.075724    7432 node_conditions.go:122] node storage ephemeral capacity is 263174212Ki
I0920 05:16:07.075724    7432 node_conditions.go:123] node cpu capacity is 12
I0920 05:16:07.075724    7432 node_conditions.go:122] node storage ephemeral capacity is 263174212Ki
I0920 05:16:07.075724    7432 node_conditions.go:123] node cpu capacity is 12
I0920 05:16:07.075724    7432 node_conditions.go:105] duration metric: took 4.0158ms to run NodePressure ...
I0920 05:16:07.075724    7432 start.go:216] waiting for startup goroutines ...
I0920 05:16:07.078354    7432 out.go:177] 
I0920 05:16:07.090557    7432 config.go:180] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.24.3
I0920 05:16:07.090557    7432 profile.go:148] Saving config to C:\Users\Esteban\.minikube\profiles\minikube\config.json ...
I0920 05:16:07.095262    7432 out.go:177] * Starting worker node minikube-m03 in cluster minikube
I0920 05:16:07.098914    7432 cache.go:120] Beginning downloading kic base image for docker with docker
I0920 05:16:07.102101    7432 out.go:177] * Pulling base image ...
I0920 05:16:07.104655    7432 preload.go:132] Checking if preload exists for k8s version v1.24.3 and runtime docker
I0920 05:16:07.104655    7432 image.go:75] Checking for gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 in local docker daemon
I0920 05:16:07.104655    7432 cache.go:57] Caching tarball of preloaded images
I0920 05:16:07.104655    7432 preload.go:174] Found C:\Users\Esteban\.minikube\cache\preloaded-tarball\preloaded-images-k8s-v18-v1.24.3-docker-overlay2-amd64.tar.lz4 in cache, skipping download
I0920 05:16:07.104655    7432 cache.go:60] Finished verifying existence of preloaded tar for  v1.24.3 on docker
I0920 05:16:07.104655    7432 profile.go:148] Saving config to C:\Users\Esteban\.minikube\profiles\minikube\config.json ...
I0920 05:16:07.273831    7432 image.go:79] Found gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 in local docker daemon, skipping pull
I0920 05:16:07.273831    7432 cache.go:142] gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 exists in daemon, skipping load
I0920 05:16:07.273908    7432 cache.go:208] Successfully downloaded all kic artifacts
I0920 05:16:07.273908    7432 start.go:371] acquiring machines lock for minikube-m03: {Name:mk752ac959dfc49ad712e12dfbf96aca2783664d Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I0920 05:16:07.273908    7432 start.go:375] acquired machines lock for "minikube-m03" in 0s
I0920 05:16:07.273908    7432 start.go:92] Provisioning new machine with config: &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 Memory:2200 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.24.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.24.3 ContainerRuntime:docker ControlPlane:true Worker:true} {Name:m02 IP:192.168.49.3 Port:0 KubernetesVersion:v1.24.3 ContainerRuntime:docker ControlPlane:false Worker:true} {Name:m03 IP: Port:0 KubernetesVersion:v1.24.3 ContainerRuntime:docker ControlPlane:false Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:true ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:C:\Users\Esteban:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath:} &{Name:m03 IP: Port:0 KubernetesVersion:v1.24.3 ContainerRuntime:docker ControlPlane:false Worker:true}
I0920 05:16:07.273908    7432 start.go:132] createHost starting for "m03" (driver="docker")
I0920 05:16:07.278197    7432 out.go:204] * Creating docker container (CPUs=2, Memory=2200MB) ...
I0920 05:16:07.278721    7432 start.go:166] libmachine.API.Create for "minikube" (driver="docker")
I0920 05:16:07.278721    7432 client.go:168] LocalClient.Create starting
I0920 05:16:07.278721    7432 main.go:134] libmachine: Reading certificate data from C:\Users\Esteban\.minikube\certs\ca.pem
I0920 05:16:07.278721    7432 main.go:134] libmachine: Decoding PEM data...
I0920 05:16:07.278721    7432 main.go:134] libmachine: Parsing certificate...
I0920 05:16:07.279244    7432 main.go:134] libmachine: Reading certificate data from C:\Users\Esteban\.minikube\certs\cert.pem
I0920 05:16:07.279244    7432 main.go:134] libmachine: Decoding PEM data...
I0920 05:16:07.279244    7432 main.go:134] libmachine: Parsing certificate...
I0920 05:16:07.290785    7432 cli_runner.go:164] Run: docker network inspect minikube --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}"
I0920 05:16:07.444261    7432 network_create.go:76] Found existing network {name:minikube subnet:0xc000f125a0 gateway:[0 0 0 0 0 0 0 0 0 0 255 255 192 168 49 1] mtu:1500}
I0920 05:16:07.444261    7432 kic.go:106] calculated static IP "192.168.49.4" for the "minikube-m03" container
I0920 05:16:07.470049    7432 cli_runner.go:164] Run: docker ps -a --format {{.Names}}
I0920 05:16:07.659697    7432 cli_runner.go:164] Run: docker volume create minikube-m03 --label name.minikube.sigs.k8s.io=minikube-m03 --label created_by.minikube.sigs.k8s.io=true
I0920 05:16:07.814803    7432 oci.go:103] Successfully created a docker volume minikube-m03
I0920 05:16:07.826117    7432 cli_runner.go:164] Run: docker run --rm --name minikube-m03-preload-sidecar --label created_by.minikube.sigs.k8s.io=true --label name.minikube.sigs.k8s.io=minikube-m03 --entrypoint /usr/bin/test -v minikube-m03:/var gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 -d /var/lib
I0920 05:16:09.242022    7432 cli_runner.go:217] Completed: docker run --rm --name minikube-m03-preload-sidecar --label created_by.minikube.sigs.k8s.io=true --label name.minikube.sigs.k8s.io=minikube-m03 --entrypoint /usr/bin/test -v minikube-m03:/var gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 -d /var/lib: (1.4159052s)
I0920 05:16:09.242022    7432 oci.go:107] Successfully prepared a docker volume minikube-m03
I0920 05:16:09.242022    7432 preload.go:132] Checking if preload exists for k8s version v1.24.3 and runtime docker
I0920 05:16:09.242022    7432 kic.go:179] Starting extracting preloaded images to volume ...
I0920 05:16:09.254454    7432 cli_runner.go:164] Run: docker run --rm --entrypoint /usr/bin/tar -v C:\Users\Esteban\.minikube\cache\preloaded-tarball\preloaded-images-k8s-v18-v1.24.3-docker-overlay2-amd64.tar.lz4:/preloaded.tar:ro -v minikube-m03:/extractDir gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 -I lz4 -xf /preloaded.tar -C /extractDir
I0920 05:19:55.750976    7432 cli_runner.go:217] Completed: docker run --rm --entrypoint /usr/bin/tar -v C:\Users\Esteban\.minikube\cache\preloaded-tarball\preloaded-images-k8s-v18-v1.24.3-docker-overlay2-amd64.tar.lz4:/preloaded.tar:ro -v minikube-m03:/extractDir gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 -I lz4 -xf /preloaded.tar -C /extractDir: (3m46.4805216s)
I0920 05:19:55.761487    7432 kic.go:188] duration metric: took 226.517511 seconds to extract preloaded images to volume
I0920 05:19:55.841885    7432 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0920 05:20:05.360898    7432 cli_runner.go:217] Completed: docker system info --format "{{json .}}": (9.5173131s)
I0920 05:20:05.424094    7432 info.go:265] docker info: {ID:L7ZV:4RQ3:VGXF:PEOU:J5XA:5F73:RDPM:ANUF:ZH5V:B6LC:XKSZ:SFZC Containers:2 ContainersRunning:2 ContainersPaused:0 ContainersStopped:0 Images:6 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:true KernelMemoryTCP:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:75 OomKillDisable:true NGoroutines:62 SystemTime:2022-09-20 10:19:56.3502135 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:5 KernelVersion:5.10.102.1-microsoft-standard-WSL2 OperatingSystem:Docker Desktop OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:12 MemTotal:13233201152 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http.docker.internal:3128 HTTPSProxy:http.docker.internal:3128 NoProxy:hubproxy.docker.internal Name:docker-desktop Labels:[] ExperimentalBuild:false ServerVersion:20.10.16 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:212e8b6fa2f44b9c21b2798135fc6fb7c53efc16 Expected:212e8b6fa2f44b9c21b2798135fc6fb7c53efc16} RuncCommit:{ID:v1.1.1-0-g52de29d Expected:v1.1.1-0-g52de29d} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=default] ProductLicense: Warnings:[WARNING: No blkio throttle.read_bps_device support WARNING: No blkio throttle.write_bps_device support WARNING: No blkio throttle.read_iops_device support WARNING: No blkio throttle.write_iops_device support] ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:C:\Program Files\Docker\cli-plugins\docker-buildx.exe SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.8.2] map[Name:compose Path:C:\Program Files\Docker\cli-plugins\docker-compose.exe SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.6.0] map[Name:sbom Path:C:\Program Files\Docker\cli-plugins\docker-sbom.exe SchemaVersion:0.1.0 ShortDescription:View the packaged-based Software Bill Of Materials (SBOM) for an image URL:https://github.com/docker/sbom-cli-plugin Vendor:Anchore Inc. Version:0.6.0] map[Name:scan Path:C:\Program Files\Docker\cli-plugins\docker-scan.exe SchemaVersion:0.1.0 ShortDescription:Docker Scan Vendor:Docker Inc. Version:v0.17.0]] Warnings:<nil>}}
I0920 05:20:05.452306    7432 cli_runner.go:164] Run: docker info --format "'{{json .SecurityOptions}}'"
I0920 05:20:05.969683    7432 cli_runner.go:164] Run: docker run -d -t --privileged --security-opt seccomp=unconfined --tmpfs /tmp --tmpfs /run -v /lib/modules:/lib/modules:ro --hostname minikube-m03 --name minikube-m03 --label created_by.minikube.sigs.k8s.io=true --label name.minikube.sigs.k8s.io=minikube-m03 --label role.minikube.sigs.k8s.io= --label mode.minikube.sigs.k8s.io=minikube-m03 --network minikube --ip 192.168.49.4 --volume minikube-m03:/var --security-opt apparmor=unconfined --memory=2200mb --memory-swap=2200mb --cpus=2 -e container=docker --expose 8443 --publish=127.0.0.1::8443 --publish=127.0.0.1::22 --publish=127.0.0.1::2376 --publish=127.0.0.1::5000 --publish=127.0.0.1::32443 gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8
I0920 05:20:07.918715    7432 cli_runner.go:217] Completed: docker run -d -t --privileged --security-opt seccomp=unconfined --tmpfs /tmp --tmpfs /run -v /lib/modules:/lib/modules:ro --hostname minikube-m03 --name minikube-m03 --label created_by.minikube.sigs.k8s.io=true --label name.minikube.sigs.k8s.io=minikube-m03 --label role.minikube.sigs.k8s.io= --label mode.minikube.sigs.k8s.io=minikube-m03 --network minikube --ip 192.168.49.4 --volume minikube-m03:/var --security-opt apparmor=unconfined --memory=2200mb --memory-swap=2200mb --cpus=2 -e container=docker --expose 8443 --publish=127.0.0.1::8443 --publish=127.0.0.1::22 --publish=127.0.0.1::2376 --publish=127.0.0.1::5000 --publish=127.0.0.1::32443 gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8: (1.9490318s)
I0920 05:20:07.940419    7432 cli_runner.go:164] Run: docker container inspect minikube-m03 --format={{.State.Running}}
I0920 05:20:08.188820    7432 cli_runner.go:164] Run: docker container inspect minikube-m03 --format={{.State.Status}}
I0920 05:20:08.450673    7432 cli_runner.go:164] Run: docker exec minikube-m03 stat /var/lib/dpkg/alternatives/iptables
I0920 05:20:09.555335    7432 cli_runner.go:217] Completed: docker exec minikube-m03 stat /var/lib/dpkg/alternatives/iptables: (1.104662s)
I0920 05:20:09.555335    7432 oci.go:144] the created container "minikube-m03" has a running status.
I0920 05:20:09.556925    7432 kic.go:210] Creating ssh key for kic: C:\Users\Esteban\.minikube\machines\minikube-m03\id_rsa...
I0920 05:20:10.524630    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\machines\minikube-m03\id_rsa.pub -> /home/docker/.ssh/authorized_keys
I0920 05:20:10.977417    7432 kic_runner.go:191] docker (temp): C:\Users\Esteban\.minikube\machines\minikube-m03\id_rsa.pub --> /home/docker/.ssh/authorized_keys (381 bytes)
I0920 05:20:11.326611    7432 cli_runner.go:164] Run: docker container inspect minikube-m03 --format={{.State.Status}}
I0920 05:20:11.559035    7432 kic_runner.go:93] Run: chown docker:docker /home/docker/.ssh/authorized_keys
I0920 05:20:11.559035    7432 kic_runner.go:114] Args: [docker exec --privileged minikube-m03 chown docker:docker /home/docker/.ssh/authorized_keys]
I0920 05:20:11.849796    7432 kic.go:250] ensuring only current user has permissions to key file located at : C:\Users\Esteban\.minikube\machines\minikube-m03\id_rsa...
I0920 05:20:13.991664    7432 cli_runner.go:164] Run: docker container inspect minikube-m03 --format={{.State.Status}}
I0920 05:20:14.240964    7432 machine.go:88] provisioning docker machine ...
I0920 05:20:14.252964    7432 ubuntu.go:169] provisioning hostname "minikube-m03"
I0920 05:20:14.268964    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube-m03
I0920 05:20:14.501892    7432 main.go:134] libmachine: Using SSH client type: native
I0920 05:20:14.603413    7432 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x8d3da0] 0x8d6c00 <nil>  [] 0s} 127.0.0.1 55868 <nil> <nil>}
I0920 05:20:14.603936    7432 main.go:134] libmachine: About to run SSH command:
sudo hostname minikube-m03 && echo "minikube-m03" | sudo tee /etc/hostname
I0920 05:20:14.839972    7432 main.go:134] libmachine: SSH cmd err, output: <nil>: minikube-m03

I0920 05:20:14.854170    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube-m03
I0920 05:20:15.073460    7432 main.go:134] libmachine: Using SSH client type: native
I0920 05:20:15.074031    7432 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x8d3da0] 0x8d6c00 <nil>  [] 0s} 127.0.0.1 55868 <nil> <nil>}
I0920 05:20:15.074031    7432 main.go:134] libmachine: About to run SSH command:

		if ! grep -xq '.*\sminikube-m03' /etc/hosts; then
			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 minikube-m03/g' /etc/hosts;
			else 
				echo '127.0.1.1 minikube-m03' | sudo tee -a /etc/hosts; 
			fi
		fi
I0920 05:20:15.208473    7432 main.go:134] libmachine: SSH cmd err, output: <nil>: 
I0920 05:20:15.209469    7432 ubuntu.go:175] set auth options {CertDir:C:\Users\Esteban\.minikube CaCertPath:C:\Users\Esteban\.minikube\certs\ca.pem CaPrivateKeyPath:C:\Users\Esteban\.minikube\certs\ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:C:\Users\Esteban\.minikube\machines\server.pem ServerKeyPath:C:\Users\Esteban\.minikube\machines\server-key.pem ClientKeyPath:C:\Users\Esteban\.minikube\certs\key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:C:\Users\Esteban\.minikube\certs\cert.pem ServerCertSANs:[] StorePath:C:\Users\Esteban\.minikube}
I0920 05:20:15.210468    7432 ubuntu.go:177] setting up certificates
I0920 05:20:15.212468    7432 provision.go:83] configureAuth start
I0920 05:20:15.225468    7432 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube-m03
I0920 05:20:15.425392    7432 provision.go:138] copyHostCerts
I0920 05:20:15.425392    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\certs\ca.pem -> C:\Users\Esteban\.minikube/ca.pem
I0920 05:20:15.427046    7432 exec_runner.go:144] found C:\Users\Esteban\.minikube/ca.pem, removing ...
I0920 05:20:15.427569    7432 exec_runner.go:207] rm: C:\Users\Esteban\.minikube\ca.pem
I0920 05:20:15.429141    7432 exec_runner.go:151] cp: C:\Users\Esteban\.minikube\certs\ca.pem --> C:\Users\Esteban\.minikube/ca.pem (1082 bytes)
I0920 05:20:15.431775    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\certs\cert.pem -> C:\Users\Esteban\.minikube/cert.pem
I0920 05:20:15.432303    7432 exec_runner.go:144] found C:\Users\Esteban\.minikube/cert.pem, removing ...
I0920 05:20:15.432303    7432 exec_runner.go:207] rm: C:\Users\Esteban\.minikube\cert.pem
I0920 05:20:15.432835    7432 exec_runner.go:151] cp: C:\Users\Esteban\.minikube\certs\cert.pem --> C:\Users\Esteban\.minikube/cert.pem (1123 bytes)
I0920 05:20:15.436527    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\certs\key.pem -> C:\Users\Esteban\.minikube/key.pem
I0920 05:20:15.437576    7432 exec_runner.go:144] found C:\Users\Esteban\.minikube/key.pem, removing ...
I0920 05:20:15.437576    7432 exec_runner.go:207] rm: C:\Users\Esteban\.minikube\key.pem
I0920 05:20:15.437576    7432 exec_runner.go:151] cp: C:\Users\Esteban\.minikube\certs\key.pem --> C:\Users\Esteban\.minikube/key.pem (1679 bytes)
I0920 05:20:15.438630    7432 provision.go:112] generating server cert: C:\Users\Esteban\.minikube\machines\server.pem ca-key=C:\Users\Esteban\.minikube\certs\ca.pem private-key=C:\Users\Esteban\.minikube\certs\ca-key.pem org=Esteban.minikube-m03 san=[192.168.49.4 127.0.0.1 localhost 127.0.0.1 minikube minikube-m03]
I0920 05:20:15.789353    7432 provision.go:172] copyRemoteCerts
I0920 05:20:15.801354    7432 ssh_runner.go:195] Run: sudo mkdir -p /etc/docker /etc/docker /etc/docker
I0920 05:20:15.814353    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube-m03
I0920 05:20:16.008944    7432 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:55868 SSHKeyPath:C:\Users\Esteban\.minikube\machines\minikube-m03\id_rsa Username:docker}
I0920 05:20:16.105112    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\certs\ca.pem -> /etc/docker/ca.pem
I0920 05:20:16.105659    7432 ssh_runner.go:362] scp C:\Users\Esteban\.minikube\certs\ca.pem --> /etc/docker/ca.pem (1082 bytes)
I0920 05:20:16.134167    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\machines\server.pem -> /etc/docker/server.pem
I0920 05:20:16.134167    7432 ssh_runner.go:362] scp C:\Users\Esteban\.minikube\machines\server.pem --> /etc/docker/server.pem (1216 bytes)
I0920 05:20:16.159791    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\machines\server-key.pem -> /etc/docker/server-key.pem
I0920 05:20:16.159791    7432 ssh_runner.go:362] scp C:\Users\Esteban\.minikube\machines\server-key.pem --> /etc/docker/server-key.pem (1675 bytes)
I0920 05:20:16.186378    7432 provision.go:86] duration metric: configureAuth took 973.3721ms
I0920 05:20:16.187012    7432 ubuntu.go:193] setting minikube options for container-runtime
I0920 05:20:16.195809    7432 config.go:180] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.24.3
I0920 05:20:16.216985    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube-m03
I0920 05:20:16.432304    7432 main.go:134] libmachine: Using SSH client type: native
I0920 05:20:16.432304    7432 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x8d3da0] 0x8d6c00 <nil>  [] 0s} 127.0.0.1 55868 <nil> <nil>}
I0920 05:20:16.432304    7432 main.go:134] libmachine: About to run SSH command:
df --output=fstype / | tail -n 1
I0920 05:20:16.559229    7432 main.go:134] libmachine: SSH cmd err, output: <nil>: overlay

I0920 05:20:16.560269    7432 ubuntu.go:71] root file system type: overlay
I0920 05:20:16.581620    7432 provision.go:309] Updating docker unit: /lib/systemd/system/docker.service ...
I0920 05:20:16.593430    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube-m03
I0920 05:20:16.778148    7432 main.go:134] libmachine: Using SSH client type: native
I0920 05:20:16.778148    7432 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x8d3da0] 0x8d6c00 <nil>  [] 0s} 127.0.0.1 55868 <nil> <nil>}
I0920 05:20:16.778148    7432 main.go:134] libmachine: About to run SSH command:
sudo mkdir -p /lib/systemd/system && printf %s "[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure

Environment="NO_PROXY=192.168.49.2"
Environment="NO_PROXY=192.168.49.2,192.168.49.3"


# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP \$MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target
" | sudo tee /lib/systemd/system/docker.service.new
I0920 05:20:16.959884    7432 main.go:134] libmachine: SSH cmd err, output: <nil>: [Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure

Environment=NO_PROXY=192.168.49.2
Environment=NO_PROXY=192.168.49.2,192.168.49.3


# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP $MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target

I0920 05:20:16.974393    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube-m03
I0920 05:20:17.173740    7432 main.go:134] libmachine: Using SSH client type: native
I0920 05:20:17.173740    7432 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x8d3da0] 0x8d6c00 <nil>  [] 0s} 127.0.0.1 55868 <nil> <nil>}
I0920 05:20:17.173740    7432 main.go:134] libmachine: About to run SSH command:
sudo diff -u /lib/systemd/system/docker.service /lib/systemd/system/docker.service.new || { sudo mv /lib/systemd/system/docker.service.new /lib/systemd/system/docker.service; sudo systemctl -f daemon-reload && sudo systemctl -f enable docker && sudo systemctl -f restart docker; }
I0920 05:20:17.988910    7432 main.go:134] libmachine: SSH cmd err, output: <nil>: --- /lib/systemd/system/docker.service	2022-06-06 23:01:03.000000000 +0000
+++ /lib/systemd/system/docker.service.new	2022-09-20 10:20:16.948079000 +0000
@@ -1,30 +1,34 @@
 [Unit]
 Description=Docker Application Container Engine
 Documentation=https://docs.docker.com
-After=network-online.target docker.socket firewalld.service containerd.service
+BindsTo=containerd.service
+After=network-online.target firewalld.service containerd.service
 Wants=network-online.target
-Requires=docker.socket containerd.service
+Requires=docker.socket
+StartLimitBurst=3
+StartLimitIntervalSec=60
 
 [Service]
 Type=notify
-# the default is not to use systemd for cgroups because the delegate issues still
-# exists and systemd currently does not support the cgroup feature set required
-# for containers run by docker
-ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock
-ExecReload=/bin/kill -s HUP $MAINPID
-TimeoutSec=0
-RestartSec=2
-Restart=always
-
-# Note that StartLimit* options were moved from "Service" to "Unit" in systemd 229.
-# Both the old, and new location are accepted by systemd 229 and up, so using the old location
-# to make them work for either version of systemd.
-StartLimitBurst=3
+Restart=on-failure
 
-# Note that StartLimitInterval was renamed to StartLimitIntervalSec in systemd 230.
-# Both the old, and new name are accepted by systemd 230 and up, so using the old name to make
-# this option work for either version of systemd.
-StartLimitInterval=60s
+Environment=NO_PROXY=192.168.49.2
+Environment=NO_PROXY=192.168.49.2,192.168.49.3
+
+
+# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
+# The base configuration already specifies an 'ExecStart=...' command. The first directive
+# here is to clear out that command inherited from the base configuration. Without this,
+# the command from the base configuration and the command specified here are treated as
+# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
+# will catch this invalid input and refuse to start the service with an error like:
+#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.
+
+# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
+# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
+ExecStart=
+ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
+ExecReload=/bin/kill -s HUP $MAINPID
 
 # Having non-zero Limit*s causes performance problems due to accounting overhead
 # in the kernel. We recommend using cgroups to do container-local accounting.
@@ -32,16 +36,16 @@
 LimitNPROC=infinity
 LimitCORE=infinity
 
-# Comment TasksMax if your systemd version does not support it.
-# Only systemd 226 and above support this option.
+# Uncomment TasksMax if your systemd version supports it.
+# Only systemd 226 and above support this version.
 TasksMax=infinity
+TimeoutStartSec=0
 
 # set delegate yes so that systemd does not reset the cgroups of docker containers
 Delegate=yes
 
 # kill only the docker process, not all processes in the cgroup
 KillMode=process
-OOMScoreAdjust=-500
 
 [Install]
 WantedBy=multi-user.target
Synchronizing state of docker.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable docker

I0920 05:20:17.988910    7432 machine.go:91] provisioned docker machine in 3.7469464s
I0920 05:20:17.988910    7432 client.go:171] LocalClient.Create took 4m10.7101895s
I0920 05:20:17.989914    7432 start.go:174] duration metric: libmachine.API.Create for "minikube" took 4m10.7111927s
I0920 05:20:17.989914    7432 start.go:307] post-start starting for "minikube-m03" (driver="docker")
I0920 05:20:17.989914    7432 start.go:335] creating required directories: [/etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs]
I0920 05:20:17.999909    7432 ssh_runner.go:195] Run: sudo mkdir -p /etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs
I0920 05:20:18.012908    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube-m03
I0920 05:20:18.287826    7432 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:55868 SSHKeyPath:C:\Users\Esteban\.minikube\machines\minikube-m03\id_rsa Username:docker}
I0920 05:20:18.366202    7432 ssh_runner.go:195] Run: cat /etc/os-release
I0920 05:20:18.371205    7432 command_runner.go:130] > NAME="Ubuntu"
I0920 05:20:18.371205    7432 command_runner.go:130] > VERSION="20.04.4 LTS (Focal Fossa)"
I0920 05:20:18.371205    7432 command_runner.go:130] > ID=ubuntu
I0920 05:20:18.371205    7432 command_runner.go:130] > ID_LIKE=debian
I0920 05:20:18.371205    7432 command_runner.go:130] > PRETTY_NAME="Ubuntu 20.04.4 LTS"
I0920 05:20:18.371205    7432 command_runner.go:130] > VERSION_ID="20.04"
I0920 05:20:18.371205    7432 command_runner.go:130] > HOME_URL="https://www.ubuntu.com/"
I0920 05:20:18.371205    7432 command_runner.go:130] > SUPPORT_URL="https://help.ubuntu.com/"
I0920 05:20:18.371205    7432 command_runner.go:130] > BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
I0920 05:20:18.371205    7432 command_runner.go:130] > PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
I0920 05:20:18.371205    7432 command_runner.go:130] > VERSION_CODENAME=focal
I0920 05:20:18.371205    7432 command_runner.go:130] > UBUNTU_CODENAME=focal
I0920 05:20:18.373203    7432 main.go:134] libmachine: Couldn't set key PRIVACY_POLICY_URL, no corresponding struct field found
I0920 05:20:18.373203    7432 main.go:134] libmachine: Couldn't set key VERSION_CODENAME, no corresponding struct field found
I0920 05:20:18.373203    7432 main.go:134] libmachine: Couldn't set key UBUNTU_CODENAME, no corresponding struct field found
I0920 05:20:18.375203    7432 info.go:137] Remote host: Ubuntu 20.04.4 LTS
I0920 05:20:18.375203    7432 filesync.go:126] Scanning C:\Users\Esteban\.minikube\addons for local assets ...
I0920 05:20:18.376203    7432 filesync.go:126] Scanning C:\Users\Esteban\.minikube\files for local assets ...
I0920 05:20:18.376203    7432 start.go:310] post-start completed in 386.2894ms
I0920 05:20:18.401202    7432 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube-m03
I0920 05:20:18.591283    7432 profile.go:148] Saving config to C:\Users\Esteban\.minikube\profiles\minikube\config.json ...
I0920 05:20:18.627006    7432 ssh_runner.go:195] Run: sh -c "df -h /var | awk 'NR==2{print $5}'"
I0920 05:20:18.639003    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube-m03
I0920 05:20:18.818542    7432 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:55868 SSHKeyPath:C:\Users\Esteban\.minikube\machines\minikube-m03\id_rsa Username:docker}
I0920 05:20:18.860176    7432 command_runner.go:130] > 3%
I0920 05:20:18.880534    7432 ssh_runner.go:195] Run: sh -c "df -BG /var | awk 'NR==2{print $4}'"
I0920 05:20:18.886232    7432 command_runner.go:130] > 232G
I0920 05:20:18.886232    7432 start.go:135] duration metric: createHost completed in 4m11.6123242s
I0920 05:20:18.886765    7432 start.go:82] releasing machines lock for "minikube-m03", held for 4m11.6128571s
I0920 05:20:18.903187    7432 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube-m03
I0920 05:20:19.088067    7432 out.go:177] * Found network options:
I0920 05:20:19.093855    7432 out.go:177]   - NO_PROXY=192.168.49.2,192.168.49.3
W0920 05:20:19.105934    7432 proxy.go:118] fail to check proxy env: Error ip not in block
W0920 05:20:19.106983    7432 proxy.go:118] fail to check proxy env: Error ip not in block
I0920 05:20:19.108563    7432 out.go:177]   - no_proxy=192.168.49.2,192.168.49.3
W0920 05:20:19.110138    7432 proxy.go:118] fail to check proxy env: Error ip not in block
W0920 05:20:19.110138    7432 proxy.go:118] fail to check proxy env: Error ip not in block
W0920 05:20:19.110665    7432 proxy.go:118] fail to check proxy env: Error ip not in block
W0920 05:20:19.110665    7432 proxy.go:118] fail to check proxy env: Error ip not in block
I0920 05:20:19.115690    7432 ssh_runner.go:195] Run: curl -sS -m 2 https://k8s.gcr.io/
I0920 05:20:19.121691    7432 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/cri-docker.service.d
I0920 05:20:19.141391    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube-m03
I0920 05:20:19.142028    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube-m03
I0920 05:20:19.377463    7432 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:55868 SSHKeyPath:C:\Users\Esteban\.minikube\machines\minikube-m03\id_rsa Username:docker}
I0920 05:20:19.390618    7432 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:55868 SSHKeyPath:C:\Users\Esteban\.minikube\machines\minikube-m03\id_rsa Username:docker}
I0920 05:20:19.474942    7432 ssh_runner.go:362] scp memory --> /etc/systemd/system/cri-docker.service.d/10-cni.conf (234 bytes)
I0920 05:20:19.502273    7432 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0920 05:20:20.457773    7432 command_runner.go:130] > <HTML><HEAD><meta http-equiv="content-type" content="text/html;charset=utf-8">
I0920 05:20:20.457773    7432 command_runner.go:130] > <TITLE>302 Moved</TITLE></HEAD><BODY>
I0920 05:20:20.457773    7432 command_runner.go:130] > <H1>302 Moved</H1>
I0920 05:20:20.457773    7432 command_runner.go:130] > The document has moved
I0920 05:20:20.457773    7432 command_runner.go:130] > <A HREF="https://cloud.google.com/container-registry/">here</A>.
I0920 05:20:20.457773    7432 command_runner.go:130] > </BODY></HTML>
I0920 05:20:20.457773    7432 ssh_runner.go:235] Completed: curl -sS -m 2 https://k8s.gcr.io/: (1.3420835s)
I0920 05:20:20.469874    7432 ssh_runner.go:195] Run: sudo systemctl restart cri-docker
I0920 05:20:20.579627    7432 ssh_runner.go:195] Run: sudo systemctl cat docker.service
I0920 05:20:20.592629    7432 command_runner.go:130] > # /lib/systemd/system/docker.service
I0920 05:20:20.592629    7432 command_runner.go:130] > [Unit]
I0920 05:20:20.592629    7432 command_runner.go:130] > Description=Docker Application Container Engine
I0920 05:20:20.592629    7432 command_runner.go:130] > Documentation=https://docs.docker.com
I0920 05:20:20.592629    7432 command_runner.go:130] > BindsTo=containerd.service
I0920 05:20:20.592629    7432 command_runner.go:130] > After=network-online.target firewalld.service containerd.service
I0920 05:20:20.592629    7432 command_runner.go:130] > Wants=network-online.target
I0920 05:20:20.592629    7432 command_runner.go:130] > Requires=docker.socket
I0920 05:20:20.592629    7432 command_runner.go:130] > StartLimitBurst=3
I0920 05:20:20.592629    7432 command_runner.go:130] > StartLimitIntervalSec=60
I0920 05:20:20.592629    7432 command_runner.go:130] > [Service]
I0920 05:20:20.592629    7432 command_runner.go:130] > Type=notify
I0920 05:20:20.592629    7432 command_runner.go:130] > Restart=on-failure
I0920 05:20:20.592629    7432 command_runner.go:130] > Environment=NO_PROXY=192.168.49.2
I0920 05:20:20.593628    7432 command_runner.go:130] > Environment=NO_PROXY=192.168.49.2,192.168.49.3
I0920 05:20:20.593628    7432 command_runner.go:130] > # This file is a systemd drop-in unit that inherits from the base dockerd configuration.
I0920 05:20:20.593628    7432 command_runner.go:130] > # The base configuration already specifies an 'ExecStart=...' command. The first directive
I0920 05:20:20.593628    7432 command_runner.go:130] > # here is to clear out that command inherited from the base configuration. Without this,
I0920 05:20:20.593628    7432 command_runner.go:130] > # the command from the base configuration and the command specified here are treated as
I0920 05:20:20.593628    7432 command_runner.go:130] > # a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
I0920 05:20:20.593628    7432 command_runner.go:130] > # will catch this invalid input and refuse to start the service with an error like:
I0920 05:20:20.593628    7432 command_runner.go:130] > #  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.
I0920 05:20:20.593628    7432 command_runner.go:130] > # NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
I0920 05:20:20.593628    7432 command_runner.go:130] > # container runtimes. If left unlimited, it may result in OOM issues with MySQL.
I0920 05:20:20.593628    7432 command_runner.go:130] > ExecStart=
I0920 05:20:20.593628    7432 command_runner.go:130] > ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
I0920 05:20:20.593628    7432 command_runner.go:130] > ExecReload=/bin/kill -s HUP $MAINPID
I0920 05:20:20.593628    7432 command_runner.go:130] > # Having non-zero Limit*s causes performance problems due to accounting overhead
I0920 05:20:20.593628    7432 command_runner.go:130] > # in the kernel. We recommend using cgroups to do container-local accounting.
I0920 05:20:20.593628    7432 command_runner.go:130] > LimitNOFILE=infinity
I0920 05:20:20.593628    7432 command_runner.go:130] > LimitNPROC=infinity
I0920 05:20:20.593628    7432 command_runner.go:130] > LimitCORE=infinity
I0920 05:20:20.593628    7432 command_runner.go:130] > # Uncomment TasksMax if your systemd version supports it.
I0920 05:20:20.593628    7432 command_runner.go:130] > # Only systemd 226 and above support this version.
I0920 05:20:20.593628    7432 command_runner.go:130] > TasksMax=infinity
I0920 05:20:20.593628    7432 command_runner.go:130] > TimeoutStartSec=0
I0920 05:20:20.593628    7432 command_runner.go:130] > # set delegate yes so that systemd does not reset the cgroups of docker containers
I0920 05:20:20.593628    7432 command_runner.go:130] > Delegate=yes
I0920 05:20:20.593628    7432 command_runner.go:130] > # kill only the docker process, not all processes in the cgroup
I0920 05:20:20.593628    7432 command_runner.go:130] > KillMode=process
I0920 05:20:20.593628    7432 command_runner.go:130] > [Install]
I0920 05:20:20.593628    7432 command_runner.go:130] > WantedBy=multi-user.target
I0920 05:20:20.595627    7432 cruntime.go:273] skipping containerd shutdown because we are bound to it
I0920 05:20:20.605627    7432 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service crio
I0920 05:20:20.619627    7432 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %s "runtime-endpoint: unix:///var/run/cri-dockerd.sock
image-endpoint: unix:///var/run/cri-dockerd.sock
" | sudo tee /etc/crictl.yaml"
I0920 05:20:20.640969    7432 command_runner.go:130] > runtime-endpoint: unix:///var/run/cri-dockerd.sock
I0920 05:20:20.640969    7432 command_runner.go:130] > image-endpoint: unix:///var/run/cri-dockerd.sock
I0920 05:20:20.657834    7432 ssh_runner.go:195] Run: sudo systemctl unmask docker.service
I0920 05:20:20.785941    7432 ssh_runner.go:195] Run: sudo systemctl enable docker.socket
I0920 05:20:20.929244    7432 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0920 05:20:21.051519    7432 ssh_runner.go:195] Run: sudo systemctl restart docker
I0920 05:20:21.500696    7432 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I0920 05:20:21.611498    7432 command_runner.go:130] ! Created symlink /etc/systemd/system/sockets.target.wants/cri-docker.socket → /lib/systemd/system/cri-docker.socket.
I0920 05:20:21.619457    7432 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0920 05:20:21.747324    7432 ssh_runner.go:195] Run: sudo systemctl start cri-docker.socket
I0920 05:20:21.762617    7432 start.go:450] Will wait 60s for socket path /var/run/cri-dockerd.sock
I0920 05:20:21.786354    7432 ssh_runner.go:195] Run: stat /var/run/cri-dockerd.sock
I0920 05:20:21.790926    7432 command_runner.go:130] >   File: /var/run/cri-dockerd.sock
I0920 05:20:21.790926    7432 command_runner.go:130] >   Size: 0         	Blocks: 0          IO Block: 4096   socket
I0920 05:20:21.790926    7432 command_runner.go:130] > Device: 1000c7h/1048775d	Inode: 136         Links: 1
I0920 05:20:21.790926    7432 command_runner.go:130] > Access: (0660/srw-rw----)  Uid: (    0/    root)   Gid: (  999/  docker)
I0920 05:20:21.790926    7432 command_runner.go:130] > Access: 2022-09-20 10:20:20.468079000 +0000
I0920 05:20:21.790926    7432 command_runner.go:130] > Modify: 2022-09-20 10:20:20.468079000 +0000
I0920 05:20:21.790926    7432 command_runner.go:130] > Change: 2022-09-20 10:20:20.478079000 +0000
I0920 05:20:21.790926    7432 command_runner.go:130] >  Birth: -
I0920 05:20:21.791433    7432 start.go:471] Will wait 60s for crictl version
I0920 05:20:21.802119    7432 ssh_runner.go:195] Run: sudo crictl version
I0920 05:20:23.532345    7432 command_runner.go:130] > Version:  0.1.0
I0920 05:20:23.532345    7432 command_runner.go:130] > RuntimeName:  docker
I0920 05:20:23.532345    7432 command_runner.go:130] > RuntimeVersion:  20.10.17
I0920 05:20:23.532345    7432 command_runner.go:130] > RuntimeApiVersion:  1.41.0
I0920 05:20:23.532345    7432 ssh_runner.go:235] Completed: sudo crictl version: (1.7302255s)
I0920 05:20:23.532345    7432 start.go:480] Version:  0.1.0
RuntimeName:  docker
RuntimeVersion:  20.10.17
RuntimeApiVersion:  1.41.0
I0920 05:20:23.549409    7432 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0920 05:20:23.589159    7432 command_runner.go:130] > 20.10.17
I0920 05:20:23.607904    7432 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0920 05:20:23.655400    7432 command_runner.go:130] > 20.10.17
I0920 05:20:23.665280    7432 out.go:204] * Preparing Kubernetes v1.24.3 on Docker 20.10.17 ...
I0920 05:20:23.679946    7432 out.go:177]   - env NO_PROXY=192.168.49.2
I0920 05:20:23.684235    7432 out.go:177]   - env NO_PROXY=192.168.49.2,192.168.49.3
I0920 05:20:23.709351    7432 cli_runner.go:164] Run: docker exec -t minikube-m03 dig +short host.docker.internal
I0920 05:20:24.873555    7432 cli_runner.go:217] Completed: docker exec -t minikube-m03 dig +short host.docker.internal: (1.1642039s)
I0920 05:20:24.873555    7432 network.go:96] got host ip for mount in container by digging dns: 192.168.65.2
I0920 05:20:24.907554    7432 ssh_runner.go:195] Run: grep 192.168.65.2	host.minikube.internal$ /etc/hosts
I0920 05:20:24.914555    7432 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\thost.minikube.internal$' "/etc/hosts"; echo "192.168.65.2	host.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0920 05:20:24.931562    7432 certs.go:54] Setting up C:\Users\Esteban\.minikube\profiles\minikube for IP: 192.168.49.4
I0920 05:20:24.934835    7432 certs.go:182] skipping minikubeCA CA generation: C:\Users\Esteban\.minikube\ca.key
I0920 05:20:24.937031    7432 certs.go:182] skipping proxyClientCA CA generation: C:\Users\Esteban\.minikube\proxy-client-ca.key
I0920 05:20:24.937645    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\ca.crt -> /var/lib/minikube/certs/ca.crt
I0920 05:20:24.937645    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\ca.key -> /var/lib/minikube/certs/ca.key
I0920 05:20:24.937645    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\proxy-client-ca.crt -> /var/lib/minikube/certs/proxy-client-ca.crt
I0920 05:20:24.937645    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\proxy-client-ca.key -> /var/lib/minikube/certs/proxy-client-ca.key
I0920 05:20:24.938181    7432 certs.go:388] found cert: C:\Users\Esteban\.minikube\certs\C:\Users\Esteban\.minikube\certs\ca-key.pem (1675 bytes)
I0920 05:20:24.938181    7432 certs.go:388] found cert: C:\Users\Esteban\.minikube\certs\C:\Users\Esteban\.minikube\certs\ca.pem (1082 bytes)
I0920 05:20:24.938694    7432 certs.go:388] found cert: C:\Users\Esteban\.minikube\certs\C:\Users\Esteban\.minikube\certs\cert.pem (1123 bytes)
I0920 05:20:24.938754    7432 certs.go:388] found cert: C:\Users\Esteban\.minikube\certs\C:\Users\Esteban\.minikube\certs\key.pem (1679 bytes)
I0920 05:20:24.939312    7432 vm_assets.go:163] NewFileAsset: C:\Users\Esteban\.minikube\ca.crt -> /usr/share/ca-certificates/minikubeCA.pem
I0920 05:20:24.992571    7432 ssh_runner.go:362] scp C:\Users\Esteban\.minikube\ca.crt --> /var/lib/minikube/certs/ca.crt (1111 bytes)
I0920 05:20:25.016492    7432 ssh_runner.go:362] scp C:\Users\Esteban\.minikube\ca.key --> /var/lib/minikube/certs/ca.key (1675 bytes)
I0920 05:20:25.039545    7432 ssh_runner.go:362] scp C:\Users\Esteban\.minikube\proxy-client-ca.crt --> /var/lib/minikube/certs/proxy-client-ca.crt (1119 bytes)
I0920 05:20:25.065295    7432 ssh_runner.go:362] scp C:\Users\Esteban\.minikube\proxy-client-ca.key --> /var/lib/minikube/certs/proxy-client-ca.key (1675 bytes)
I0920 05:20:25.265151    7432 ssh_runner.go:362] scp C:\Users\Esteban\.minikube\ca.crt --> /usr/share/ca-certificates/minikubeCA.pem (1111 bytes)
I0920 05:20:25.305539    7432 ssh_runner.go:195] Run: openssl version
I0920 05:20:25.313874    7432 command_runner.go:130] > OpenSSL 1.1.1f  31 Mar 2020
I0920 05:20:25.323875    7432 ssh_runner.go:195] Run: sudo /bin/bash -c "test -s /usr/share/ca-certificates/minikubeCA.pem && ln -fs /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem"
I0920 05:20:25.347875    7432 ssh_runner.go:195] Run: ls -la /usr/share/ca-certificates/minikubeCA.pem
I0920 05:20:25.353878    7432 command_runner.go:130] > -rw-r--r-- 1 root root 1111 Sep 20 09:09 /usr/share/ca-certificates/minikubeCA.pem
I0920 05:20:25.353878    7432 certs.go:431] hashing: -rw-r--r-- 1 root root 1111 Sep 20 09:09 /usr/share/ca-certificates/minikubeCA.pem
I0920 05:20:25.361876    7432 ssh_runner.go:195] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
I0920 05:20:25.367876    7432 command_runner.go:130] > b5213941
I0920 05:20:25.375873    7432 ssh_runner.go:195] Run: sudo /bin/bash -c "test -L /etc/ssl/certs/b5213941.0 || ln -fs /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0"
I0920 05:20:25.400874    7432 ssh_runner.go:195] Run: docker info --format {{.CgroupDriver}}
I0920 05:20:25.474516    7432 command_runner.go:130] > cgroupfs
I0920 05:20:25.476674    7432 cni.go:95] Creating CNI manager for ""
I0920 05:20:25.477739    7432 cni.go:156] 3 nodes found, recommending kindnet
I0920 05:20:25.481441    7432 kubeadm.go:87] Using pod CIDR: 10.244.0.0/16
I0920 05:20:25.483005    7432 kubeadm.go:158] kubeadm options: {CertDir:/var/lib/minikube/certs ServiceCIDR:10.96.0.0/12 PodSubnet:10.244.0.0/16 AdvertiseAddress:192.168.49.4 APIServerPort:8443 KubernetesVersion:v1.24.3 EtcdDataDir:/var/lib/minikube/etcd EtcdExtraArgs:map[] ClusterName:minikube NodeName:minikube-m03 DNSDomain:cluster.local CRISocket:/var/run/cri-dockerd.sock ImageRepository: ComponentOptions:[{Component:apiServer ExtraArgs:map[enable-admission-plugins:NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota] Pairs:map[certSANs:["127.0.0.1", "localhost", "192.168.49.2"]]} {Component:controllerManager ExtraArgs:map[allocate-node-cidrs:true leader-elect:false] Pairs:map[]} {Component:scheduler ExtraArgs:map[leader-elect:false] Pairs:map[]}] FeatureArgs:map[] NoTaintMaster:true NodeIP:192.168.49.4 CgroupDriver:cgroupfs ClientCAFile:/var/lib/minikube/certs/ca.crt StaticPodPath:/etc/kubernetes/manifests ControlPlaneAddress:control-plane.minikube.internal KubeProxyOptions:map[]}
I0920 05:20:25.488675    7432 kubeadm.go:162] kubeadm config:
apiVersion: kubeadm.k8s.io/v1beta3
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.49.4
  bindPort: 8443
bootstrapTokens:
  - groups:
      - system:bootstrappers:kubeadm:default-node-token
    ttl: 24h0m0s
    usages:
      - signing
      - authentication
nodeRegistration:
  criSocket: /var/run/cri-dockerd.sock
  name: "minikube-m03"
  kubeletExtraArgs:
    node-ip: 192.168.49.4
  taints: []
---
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
apiServer:
  certSANs: ["127.0.0.1", "localhost", "192.168.49.2"]
  extraArgs:
    enable-admission-plugins: "NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota"
controllerManager:
  extraArgs:
    allocate-node-cidrs: "true"
    leader-elect: "false"
scheduler:
  extraArgs:
    leader-elect: "false"
certificatesDir: /var/lib/minikube/certs
clusterName: mk
controlPlaneEndpoint: control-plane.minikube.internal:8443
etcd:
  local:
    dataDir: /var/lib/minikube/etcd
    extraArgs:
      proxy-refresh-interval: "70000"
kubernetesVersion: v1.24.3
networking:
  dnsDomain: cluster.local
  podSubnet: "10.244.0.0/16"
  serviceSubnet: 10.96.0.0/12
---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
authentication:
  x509:
    clientCAFile: /var/lib/minikube/certs/ca.crt
cgroupDriver: cgroupfs
clusterDomain: "cluster.local"
# disable disk resource management by default
imageGCHighThresholdPercent: 100
evictionHard:
  nodefs.available: "0%"
  nodefs.inodesFree: "0%"
  imagefs.available: "0%"
failSwapOn: false
staticPodPath: /etc/kubernetes/manifests
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
clusterCIDR: "10.244.0.0/16"
metricsBindAddress: 0.0.0.0:10249
conntrack:
  maxPerCore: 0
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_established"
  tcpEstablishedTimeout: 0s
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_close"
  tcpCloseWaitTimeout: 0s

I0920 05:20:25.491675    7432 kubeadm.go:961] kubelet [Unit]
Wants=docker.socket

[Service]
ExecStart=
ExecStart=/var/lib/minikube/binaries/v1.24.3/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --config=/var/lib/kubelet/config.yaml --container-runtime=remote --container-runtime-endpoint=/var/run/cri-dockerd.sock --hostname-override=minikube-m03 --image-service-endpoint=/var/run/cri-dockerd.sock --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=192.168.49.4 --runtime-request-timeout=15m

[Install]
 config:
{KubernetesVersion:v1.24.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:}
I0920 05:20:25.499674    7432 ssh_runner.go:195] Run: sudo ls /var/lib/minikube/binaries/v1.24.3
I0920 05:20:25.508675    7432 command_runner.go:130] > kubeadm
I0920 05:20:25.508675    7432 command_runner.go:130] > kubectl
I0920 05:20:25.508675    7432 command_runner.go:130] > kubelet
I0920 05:20:25.509675    7432 binaries.go:44] Found k8s binaries, skipping transfer
I0920 05:20:25.517675    7432 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/kubelet.service.d /lib/systemd/system
I0920 05:20:25.527676    7432 ssh_runner.go:362] scp memory --> /etc/systemd/system/kubelet.service.d/10-kubeadm.conf (474 bytes)
I0920 05:20:25.543675    7432 ssh_runner.go:362] scp memory --> /lib/systemd/system/kubelet.service (352 bytes)
I0920 05:20:25.582676    7432 ssh_runner.go:195] Run: grep 192.168.49.2	control-plane.minikube.internal$ /etc/hosts
I0920 05:20:25.587675    7432 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\tcontrol-plane.minikube.internal$' "/etc/hosts"; echo "192.168.49.2	control-plane.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0920 05:20:25.601675    7432 host.go:66] Checking if "minikube" exists ...
I0920 05:20:25.604675    7432 config.go:180] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.24.3
I0920 05:20:25.610675    7432 start.go:285] JoinCluster: &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 Memory:2200 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.24.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.24.3 ContainerRuntime:docker ControlPlane:true Worker:true} {Name:m02 IP:192.168.49.3 Port:0 KubernetesVersion:v1.24.3 ContainerRuntime:docker ControlPlane:false Worker:true} {Name:m03 IP:192.168.49.4 Port:0 KubernetesVersion:v1.24.3 ContainerRuntime:docker ControlPlane:false Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:true ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:C:\Users\Esteban:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath:}
I0920 05:20:25.610675    7432 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.24.3:$PATH" kubeadm token create --print-join-command --ttl=0"
I0920 05:20:25.624677    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0920 05:20:25.817527    7432 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:55721 SSHKeyPath:C:\Users\Esteban\.minikube\machines\minikube\id_rsa Username:docker}
I0920 05:20:25.969811    7432 command_runner.go:130] > kubeadm join control-plane.minikube.internal:8443 --token 5d32yj.ltvq8j2lf9diiwg3 --discovery-token-ca-cert-hash sha256:73202b2265c3b3018d12119f3c78685654b918967fd5f268db3bf3b4d7e92013 
I0920 05:20:25.969845    7432 start.go:306] trying to join worker node "m03" to cluster: &{Name:m03 IP:192.168.49.4 Port:0 KubernetesVersion:v1.24.3 ContainerRuntime:docker ControlPlane:false Worker:true}
I0920 05:20:25.969845    7432 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.24.3:$PATH" kubeadm join control-plane.minikube.internal:8443 --token 5d32yj.ltvq8j2lf9diiwg3 --discovery-token-ca-cert-hash sha256:73202b2265c3b3018d12119f3c78685654b918967fd5f268db3bf3b4d7e92013 --ignore-preflight-errors=all --cri-socket /var/run/cri-dockerd.sock --node-name=minikube-m03"
I0920 05:20:26.261796    7432 command_runner.go:130] ! W0920 10:20:26.261696    1126 initconfiguration.go:120] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme "unix" to the "criSocket" with value "/var/run/cri-dockerd.sock". Please update your configuration!
I0920 05:20:26.281327    7432 command_runner.go:130] ! 	[WARNING Swap]: swap is enabled; production deployments should disable swap unless testing the NodeSwap feature gate of the kubelet
I0920 05:20:26.422668    7432 command_runner.go:130] ! 	[WARNING Service-Kubelet]: kubelet service is not enabled, please run 'systemctl enable kubelet.service'
I0920 05:20:32.164822    7432 command_runner.go:130] > [preflight] Running pre-flight checks
I0920 05:20:32.164822    7432 command_runner.go:130] > [preflight] Reading configuration from the cluster...
I0920 05:20:32.164822    7432 command_runner.go:130] > [preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'
I0920 05:20:32.164822    7432 command_runner.go:130] > [kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
I0920 05:20:32.164822    7432 command_runner.go:130] > [kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
I0920 05:20:32.164822    7432 command_runner.go:130] > [kubelet-start] Starting the kubelet
I0920 05:20:32.164822    7432 command_runner.go:130] > [kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...
I0920 05:20:32.164822    7432 command_runner.go:130] > This node has joined the cluster:
I0920 05:20:32.164822    7432 command_runner.go:130] > * Certificate signing request was sent to apiserver and a response was received.
I0920 05:20:32.164822    7432 command_runner.go:130] > * The Kubelet was informed of the new secure connection details.
I0920 05:20:32.164822    7432 command_runner.go:130] > Run 'kubectl get nodes' on the control-plane to see this node join the cluster.
I0920 05:20:32.164822    7432 ssh_runner.go:235] Completed: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.24.3:$PATH" kubeadm join control-plane.minikube.internal:8443 --token 5d32yj.ltvq8j2lf9diiwg3 --discovery-token-ca-cert-hash sha256:73202b2265c3b3018d12119f3c78685654b918967fd5f268db3bf3b4d7e92013 --ignore-preflight-errors=all --cri-socket /var/run/cri-dockerd.sock --node-name=minikube-m03": (6.1949777s)
I0920 05:20:32.166439    7432 ssh_runner.go:195] Run: /bin/bash -c "sudo systemctl daemon-reload && sudo systemctl enable kubelet && sudo systemctl start kubelet"
I0920 05:20:32.268130    7432 command_runner.go:130] ! Created symlink /etc/systemd/system/multi-user.target.wants/kubelet.service → /lib/systemd/system/kubelet.service.
I0920 05:20:32.368496    7432 start.go:287] JoinCluster complete in 6.7578208s
I0920 05:20:32.368496    7432 cni.go:95] Creating CNI manager for ""
I0920 05:20:32.368496    7432 cni.go:156] 3 nodes found, recommending kindnet
I0920 05:20:32.390145    7432 ssh_runner.go:195] Run: stat /opt/cni/bin/portmap
I0920 05:20:32.395211    7432 command_runner.go:130] >   File: /opt/cni/bin/portmap
I0920 05:20:32.395211    7432 command_runner.go:130] >   Size: 2828728   	Blocks: 5528       IO Block: 4096   regular file
I0920 05:20:32.395211    7432 command_runner.go:130] > Device: 100011h/1048593d	Inode: 98512       Links: 1
I0920 05:20:32.395211    7432 command_runner.go:130] > Access: (0755/-rwxr-xr-x)  Uid: (    0/    root)   Gid: (    0/    root)
I0920 05:20:32.395211    7432 command_runner.go:130] > Access: 2022-05-18 18:39:21.000000000 +0000
I0920 05:20:32.395211    7432 command_runner.go:130] > Modify: 2022-05-18 18:39:21.000000000 +0000
I0920 05:20:32.395211    7432 command_runner.go:130] > Change: 2022-09-20 09:07:54.348968000 +0000
I0920 05:20:32.395211    7432 command_runner.go:130] >  Birth: -
I0920 05:20:32.395211    7432 cni.go:189] applying CNI manifest using /var/lib/minikube/binaries/v1.24.3/kubectl ...
I0920 05:20:32.396785    7432 ssh_runner.go:362] scp memory --> /var/tmp/minikube/cni.yaml (2429 bytes)
I0920 05:20:32.419142    7432 ssh_runner.go:195] Run: sudo /var/lib/minikube/binaries/v1.24.3/kubectl apply --kubeconfig=/var/lib/minikube/kubeconfig -f /var/tmp/minikube/cni.yaml
I0920 05:20:33.052936    7432 command_runner.go:130] > clusterrole.rbac.authorization.k8s.io/kindnet unchanged
I0920 05:20:33.052936    7432 command_runner.go:130] > clusterrolebinding.rbac.authorization.k8s.io/kindnet unchanged
I0920 05:20:33.052936    7432 command_runner.go:130] > serviceaccount/kindnet unchanged
I0920 05:20:33.052936    7432 command_runner.go:130] > daemonset.apps/kindnet configured
I0920 05:20:33.054536    7432 start.go:211] Will wait 6m0s for node &{Name:m03 IP:192.168.49.4 Port:0 KubernetesVersion:v1.24.3 ContainerRuntime:docker ControlPlane:false Worker:true}
I0920 05:20:33.056694    7432 out.go:177] * Verifying Kubernetes components...
I0920 05:20:33.069078    7432 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service kubelet
I0920 05:20:33.094169    7432 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I0920 05:20:33.301234    7432 loader.go:372] Config loaded from file:  C:\Users\Esteban\.kube\config
I0920 05:20:33.308786    7432 kapi.go:59] client config for minikube: &rest.Config{Host:"https://127.0.0.1:55725", APIPath:"", ContentConfig:rest.ContentConfig{AcceptContentTypes:"", ContentType:"", GroupVersion:(*schema.GroupVersion)(nil), NegotiatedSerializer:runtime.NegotiatedSerializer(nil)}, Username:"", Password:"", BearerToken:"", BearerTokenFile:"", Impersonate:rest.ImpersonationConfig{UserName:"", UID:"", Groups:[]string(nil), Extra:map[string][]string(nil)}, AuthProvider:<nil>, AuthConfigPersister:rest.AuthProviderConfigPersister(nil), ExecProvider:<nil>, TLSClientConfig:rest.sanitizedTLSClientConfig{Insecure:false, ServerName:"", CertFile:"C:\\Users\\Esteban\\.minikube\\profiles\\minikube\\client.crt", KeyFile:"C:\\Users\\Esteban\\.minikube\\profiles\\minikube\\client.key", CAFile:"C:\\Users\\Esteban\\.minikube\\ca.crt", CertData:[]uint8(nil), KeyData:[]uint8(nil), CAData:[]uint8(nil), NextProtos:[]string(nil)}, UserAgent:"", DisableCompression:false, Transport:http.RoundTripper(nil), WrapTransport:(transport.WrapperFunc)(0x1803b20), QPS:0, Burst:0, RateLimiter:flowcontrol.RateLimiter(nil), WarningHandler:rest.WarningHandler(nil), Timeout:0, Dial:(func(context.Context, string, string) (net.Conn, error))(nil), Proxy:(func(*http.Request) (*url.URL, error))(nil)}
I0920 05:20:33.356067    7432 kubeadm.go:572] duration metric: took 301.5301ms to wait for : map[apiserver:true system_pods:true] ...
I0920 05:20:33.357067    7432 node_conditions.go:102] verifying NodePressure condition ...
I0920 05:20:33.388066    7432 round_trippers.go:466] curl -v -XGET  -H "Accept: application/json, */*" -H "User-Agent: minikube.exe/v0.0.0 (windows/amd64) kubernetes/$Format" 'https://127.0.0.1:55725/api/v1/nodes'
I0920 05:20:33.417062    7432 round_trippers.go:510] HTTP Trace: Dial to tcp:127.0.0.1:55725 succeed
I0920 05:20:33.491857    7432 round_trippers.go:553] GET https://127.0.0.1:55725/api/v1/nodes 200 OK in 103 milliseconds
I0920 05:20:33.493976    7432 round_trippers.go:570] HTTP Statistics: DNSLookup 0 ms Dial 0 ms TLSHandshake 50 ms ServerProcessing 7 ms Duration 103 ms
I0920 05:20:33.493976    7432 round_trippers.go:577] Response Headers:
I0920 05:20:33.493976    7432 round_trippers.go:580]     X-Kubernetes-Pf-Flowschema-Uid: 02cd4939-01f5-4b09-a0a9-02b620700246
I0920 05:20:33.493976    7432 round_trippers.go:580]     X-Kubernetes-Pf-Prioritylevel-Uid: fd684f0e-e7d0-4d27-979b-454254971228
I0920 05:20:33.493976    7432 round_trippers.go:580]     Date: Tue, 20 Sep 2022 10:20:33 GMT
I0920 05:20:33.493976    7432 round_trippers.go:580]     Audit-Id: eee2b3a8-792c-4ee4-86ba-c579a2a6dd6f
I0920 05:20:33.493976    7432 round_trippers.go:580]     Cache-Control: no-cache, private
I0920 05:20:33.493976    7432 round_trippers.go:580]     Content-Type: application/json
I0920 05:20:33.496834    7432 request.go:1073] Response Body: {"kind":"NodeList","apiVersion":"v1","metadata":{"resourceVersion":"641"},"items":[{"metadata":{"name":"minikube","uid":"88395272-a0b5-4a2c-bb07-daf0b9548da3","resourceVersion":"521","creationTimestamp":"2022-09-20T10:15:01Z","labels":{"beta.kubernetes.io/arch":"amd64","beta.kubernetes.io/os":"linux","kubernetes.io/arch":"amd64","kubernetes.io/hostname":"minikube","kubernetes.io/os":"linux","minikube.k8s.io/commit":"62e108c3dfdec8029a890ad6d8ef96b6461426dc","minikube.k8s.io/name":"minikube","minikube.k8s.io/primary":"true","minikube.k8s.io/updated_at":"2022_09_20T05_15_05_0700","minikube.k8s.io/version":"v1.26.1","node-role.kubernetes.io/control-plane":"","node.kubernetes.io/exclude-from-external-load-balancers":""},"annotations":{"kubeadm.alpha.kubernetes.io/cri-socket":"unix:///var/run/cri-dockerd.sock","node.alpha.kubernetes.io/ttl":"0","volumes.kubernetes.io/controller-managed-attach-detach":"true"},"managedFields":[{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-09-20T10:15:01Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:volumes.kubernetes.io/controller-managed-attach-detach":{}},"f:labels":{".":{},"f:beta.kubernetes.io/arch":{},"f:beta.kubernetes.io/os":{},"f:kubernetes.io/arch":{},"f:kubernetes.io/hostname":{},"f:kubernetes.io/os":{}}}}},{"manager":"kubeadm","operation":"Update","apiVersion":"v1","time":"2022-09-20T10:15:04Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{"f:kubeadm.alpha.kubernetes.io/cri-socket":{}},"f:labels":{"f:node-role.kubernetes.io/control-plane":{},"f:node.kubernetes.io/exclude-from-external-load-balancers":{}}}}},{"manager":"kubectl-label","operation":"Update","apiVersion":"v1","time":"2022-09-20T10:15:06Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:labels":{"f:minikube.k8s.io/commit":{},"f:minikube.k8s.io/name":{},"f:minikube.k8s.io/primary":{},"f:minikube.k8s.io/updated_at":{},"f:minikube.k8s.io/version":{}}}}},{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-09-20T10:17:01Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{"f:node.alpha.kubernetes.io/ttl":{}}},"f:spec":{"f:podCIDR":{},"f:podCIDRs":{".":{},"v:\"10.244.0.0/24\"":{}}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-09-20T10:20:22Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"DiskPressure\"}":{"f:lastHeartbeatTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{}},"k:{\"type\":\"MemoryPressure\"}":{"f:lastHeartbeatTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{}},"k:{\"type\":\"PIDPressure\"}":{"f:lastHeartbeatTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{}},"k:{\"type\":\"Ready\"}":{"f:lastHeartbeatTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{}}},"f:images":{}}},"subresource":"status"}]},"spec":{"podCIDR":"10.244.0.0/24","podCIDRs":["10.244.0.0/24"]},"status":{"capacity":{"cpu":"12","ephemeral-storage":"263174212Ki","hugepages-1Gi":"0","hugepages-2Mi":"0","memory":"12923048Ki","pods":"110"},"allocatable":{"cpu":"12","ephemeral-storage":"263174212Ki","hugepages-1Gi":"0","hugepages-2Mi":"0","memory":"12923048Ki","pods":"110"},"conditions":[{"type":"MemoryPressure","status":"False","lastHeartbeatTime":"2022-09-20T10:20:22Z","lastTransitionTime":"2022-09-20T10:20:22Z","reason":"KubeletHasSufficientMemory","message":"kubelet has sufficient memory available"},{"type":"DiskPressure","status":"False","lastHeartbeatTime":"2022-09-20T10:20:22Z","lastTransitionTime":"2022-09-20T10:20:22Z","reason":"KubeletHasNoDiskPressure","message":"kubelet has no disk pressure"},{"type":"PIDPressure","status":"False","lastHeartbeatTime":"2022-09-20T10:20:22Z","lastTransitionTime":"2022-09-20T10:20:22Z","reason":"KubeletHasSufficientPID","message":"kubelet has sufficient PID available"},{"type":"Ready","status":"True","lastHeartbeatTime":"2022-09-20T10:20:22Z","lastTransitionTime":"2022-09-20T10:20:22Z","reason":"KubeletReady","message":"kubelet is posting ready status"}],"addresses":[{"type":"InternalIP","address":"192.168.49.2"},{"type":"Hostname","address":"minikube"}],"daemonEndpoints":{"kubeletEndpoint":{"Port":10250}},"nodeInfo":{"machineID":"4c192b04687c403f8fbb9bc7975b21b3","systemUUID":"4c192b04687c403f8fbb9bc7975b21b3","bootID":"de31de94-2a42-4516-a4e6-7cb2de739fde","kernelVersion":"5.10.102.1-microsoft-standard-WSL2","osImage":"Ubuntu 20.04.4 LTS","containerRuntimeVersion":"docker://20.10.17","kubeletVersion":"v1.24.3","kubeProxyVersion":"v1.24.3","operatingSystem":"linux","architecture":"amd64"},"images":[{"names":["k8s.gcr.io/etcd@sha256:13f53ed1d91e2e11aac476ee9a0269fdda6cc4874eba903efd40daf50c55eee5","k8s.gcr.io/etcd:3.5.3-0"],"sizeBytes":299495233},{"names":["k8s.gcr.io/kube-apiserver@sha256:a04609b85962da7e6531d32b75f652b4fb9f5fe0b0ee0aa160856faad8ec5d96","k8s.gcr.io/kube-apiserver:v1.24.3"],"sizeBytes":129710737},{"names":["k8s.gcr.io/kube-controller-manager@sha256:f504eead8b8674ebc9067370ef51abbdc531b4a81813bfe464abccb8c76b6a53","k8s.gcr.io/kube-controller-manager:v1.24.3"],"sizeBytes":119360464},{"names":["k8s.gcr.io/kube-proxy@sha256:c1b135231b5b1a6799346cd701da4b59e5b7ef8e694ec7b04fb23b8dbe144137","k8s.gcr.io/kube-proxy:v1.24.3"],"sizeBytes":109939784},{"names":["kindest/kindnetd@sha256:e2d4d675dcf28a90102ad5219b75c5a0ee096c4321247dfae31dd1467611a9fb","kindest/kindnetd:v20220726-ed811e41"],"sizeBytes":61761170},{"names":["k8s.gcr.io/kube-scheduler@sha256:e199523298224cd9f2a9a43c7c2c37fa57aff87648ed1e1de9984eba6f6005f0","k8s.gcr.io/kube-scheduler:v1.24.3"],"sizeBytes":50989989},{"names":["k8s.gcr.io/coredns/coredns@sha256:5b6ec0d6de9baaf3e92d0f66cd96a25b9edbce8716f5f15dcd1a616b3abd590e","k8s.gcr.io/coredns/coredns:v1.8.6"],"sizeBytes":46829283},{"names":["gcr.io/k8s-minikube/storage-provisioner@sha256:18eb69d1418e854ad5a19e399310e52808a8321e4c441c1dddad8977a0d7a944","gcr.io/k8s-minikube/storage-provisioner:v5"],"sizeBytes":31465472},{"names":["k8s.gcr.io/pause@sha256:bb6ed397957e9ca7c65ada0db5c5d1c707c9c8afc80a94acbe69f3ae76988f0c","k8s.gcr.io/pause:3.7"],"sizeBytes":711184},{"names":["k8s.gcr.io/pause@sha256:3d380ca8864549e74af4b29c10f9cb0956236dfb01c40ca076fb6c37253234db","k8s.gcr.io/pause:3.6"],"sizeBytes":682696}]}},{"metadata":{"name":"minikube-m02","uid":"3948aa81-d5a1-41bd-b626-a754af61513f","resourceVersion":"619","creationTimestamp":"2022-09-20T10:16:06Z","labels":{"beta.kubernetes.io/arch":"amd64","beta.kubernetes.io/os":"linux","kubernetes.io/arch":"amd64","kubernetes.io/hostname":"minikube-m02","kubernetes.io/os":"linux"},"annotations":{"kubeadm.alpha.kubernetes.io/cri-socket":"/var/run/cri-dockerd.sock","node.alpha.kubernetes.io/ttl":"0","volumes.kubernetes.io/controller-managed-attach-detach":"true"},"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-09-20T10:16:06Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{"f:node.alpha.kubernetes.io/ttl":{}}},"f:spec":{"f:podCIDR":{},"f:podCIDRs":{".":{},"v:\"10.244.1.0/24\"":{}},"f:taints":{}}}},{"manager":"kubeadm","operation":"Update","apiVersion":"v1","time":"2022-09-20T10:16:06Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{"f:kubeadm.alpha.kubernetes.io/cri-socket":{}}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-09-20T10:16:06Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:volumes.kubernetes.io/controller-managed-attach-detach":{}},"f:labels":{".":{},"f:beta.kubernetes.io/arch":{},"f:beta.kubernetes.io/os":{},"f:kubernetes.io/arch":{},"f:kubernetes.io/hostname":{},"f:kubernetes.io/os":{}}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-09-20T10:20:19Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"DiskPressure\"}":{"f:lastHeartbeatTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{}},"k:{\"type\":\"MemoryPressure\"}":{"f:lastHeartbeatTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{}},"k:{\"type\":\"PIDPressure\"}":{"f:lastHeartbeatTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{}},"k:{\"type\":\"Ready\"}":{"f:lastHeartbeatTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{}}},"f:images":{}}},"subresource":"status"}]},"spec":{"podCIDR":"10.244.1.0/24","podCIDRs":["10.244.1.0/24"],"taints":[{"key":"node.kubernetes.io/not-ready","effect":"NoSchedule","timeAdded":"2022-09-20T10:20:19Z"}]},"status":{"capacity":{"cpu":"12","ephemeral-storage":"263174212Ki","hugepages-1Gi":"0","hugepages-2Mi":"0","memory":"12923048Ki","pods":"110"},"allocatable":{"cpu":"12","ephemeral-storage":"263174212Ki","hugepages-1Gi":"0","hugepages-2Mi":"0","memory":"12923048Ki","pods":"110"},"conditions":[{"type":"MemoryPressure","status":"False","lastHeartbeatTime":"2022-09-20T10:20:29Z","lastTransitionTime":"2022-09-20T10:20:19Z","reason":"KubeletHasSufficientMemory","message":"kubelet has sufficient memory available"},{"type":"DiskPressure","status":"False","lastHeartbeatTime":"2022-09-20T10:20:29Z","lastTransitionTime":"2022-09-20T10:20:19Z","reason":"KubeletHasNoDiskPressure","message":"kubelet has no disk pressure"},{"type":"PIDPressure","status":"False","lastHeartbeatTime":"2022-09-20T10:20:29Z","lastTransitionTime":"2022-09-20T10:20:19Z","reason":"KubeletHasSufficientPID","message":"kubelet has sufficient PID available"},{"type":"Ready","status":"False","lastHeartbeatTime":"2022-09-20T10:20:29Z","lastTransitionTime":"2022-09-20T10:20:19Z","reason":"KubeletNotReady","message":"container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:docker: network plugin is not ready: cni config uninitialized"}],"addresses":[{"type":"InternalIP","address":"192.168.49.3"},{"type":"Hostname","address":"minikube-m02"}],"daemonEndpoints":{"kubeletEndpoint":{"Port":10250}},"nodeInfo":{"machineID":"4c192b04687c403f8fbb9bc7975b21b3","systemUUID":"4c192b04687c403f8fbb9bc7975b21b3","bootID":"de31de94-2a42-4516-a4e6-7cb2de739fde","kernelVersion":"5.10.102.1-microsoft-standard-WSL2","osImage":"Ubuntu 20.04.4 LTS","containerRuntimeVersion":"docker://20.10.17","kubeletVersion":"v1.24.3","kubeProxyVersion":"v1.24.3","operatingSystem":"linux","architecture":"amd64"},"images":[{"names":["k8s.gcr.io/etcd@sha256:13f53ed1d91e2e11aac476ee9a0269fdda6cc4874eba903efd40daf50c55eee5","k8s.gcr.io/etcd:3.5.3-0"],"sizeBytes":299495233},{"names":["k8s.gcr.io/kube-apiserver@sha256:a04609b85962da7e6531d32b75f652b4fb9f5fe0b0ee0aa160856faad8ec5d96","k8s.gcr.io/kube-apiserver:v1.24.3"],"sizeBytes":129710737},{"names":["k8s.gcr.io/kube-controller-manager@sha256:f504eead8b8674ebc9067370ef51abbdc531b4a81813bfe464abccb8c76b6a53","k8s.gcr.io/kube-controller-manager:v1.24.3"],"sizeBytes":119360464},{"names":["k8s.gcr.io/kube-proxy@sha256:c1b135231b5b1a6799346cd701da4b59e5b7ef8e694ec7b04fb23b8dbe144137","k8s.gcr.io/kube-proxy:v1.24.3"],"sizeBytes":109939784},{"names":["kindest/kindnetd@sha256:e2d4d675dcf28a90102ad5219b75c5a0ee096c4321247dfae31dd1467611a9fb","kindest/kindnetd:v20220726-ed811e41"],"sizeBytes":61761170},{"names":["k8s.gcr.io/kube-scheduler@sha256:e199523298224cd9f2a9a43c7c2c37fa57aff87648ed1e1de9984eba6f6005f0","k8s.gcr.io/kube-scheduler:v1.24.3"],"sizeBytes":50989989},{"names":["k8s.gcr.io/coredns/coredns@sha256:5b6ec0d6de9baaf3e92d0f66cd96a25b9edbce8716f5f15dcd1a616b3abd590e","k8s.gcr.io/coredns/coredns:v1.8.6"],"sizeBytes":46829283},{"names":["gcr.io/k8s-minikube/storage-provisioner@sha256:18eb69d1418e854ad5a19e399310e52808a8321e4c441c1dddad8977a0d7a944","gcr.io/k8s-minikube/storage-provisioner:v5"],"sizeBytes":31465472},{"names":["k8s.gcr.io/pause@sha256:bb6ed397957e9ca7c65ada0db5c5d1c707c9c8afc80a94acbe69f3ae76988f0c","k8s.gcr.io/pause:3.7"],"sizeBytes":711184},{"names":["k8s.gcr.io/pause@sha256:3d380ca8864549e74af4b29c10f9cb0956236dfb01c40ca076fb6c37253234db","k8s.gcr.io/pause:3.6"],"sizeBytes":682696}]}},{"metadata":{"name":"minikube-m03","uid":"ec8c8928-0555-4816-861c-c15a29c32293","resourceVersion":"635","creationTimestamp":"2022-09-20T10:20:27Z","labels":{"beta.kubernetes.io/arch":"amd64","beta.kubernetes.io/os":"linux","kubernetes.io/arch":"amd64","kubernetes.io/hostname":"minikube-m03","kubernetes.io/os":"linux"},"annotations":{"kubeadm.alpha.kubernetes.io/cri-socket":"/var/run/cri-dockerd.sock","node.alpha.kubernetes.io/ttl":"0","volumes.kubernetes.io/controller-managed-attach-detach":"true"},"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-09-20T10:20:27Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{"f:node.alpha.kubernetes.io/ttl":{}}},"f:spec":{"f:podCIDR":{},"f:podCIDRs":{".":{},"v:\"10.244.2.0/24\"":{}}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-09-20T10:20:27Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:volumes.kubernetes.io/controller-managed-attach-detach":{}},"f:labels":{".":{},"f:beta.kubernetes.io/arch":{},"f:beta.kubernetes.io/os":{},"f:kubernetes.io/arch":{},"f:kubernetes.io/hostname":{},"f:kubernetes.io/os":{}}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-09-20T10:20:27Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:allocatable":{"f:ephemeral-storage":{}},"f:capacity":{"f:ephemeral-storage":{}},"f:conditions":{"k:{\"type\":\"Ready\"}":{"f:message":{}}}}},"subresource":"status"},{"manager":"kubeadm","operation":"Update","apiVersion":"v1","time":"2022-09-20T10:20:32Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{"f:kubeadm.alpha.kubernetes.io/cri-socket":{}}}}}]},"spec":{"podCIDR":"10.244.2.0/24","podCIDRs":["10.244.2.0/24"],"taints":[{"key":"node.kubernetes.io/not-ready","effect":"NoSchedule"}]},"status":{"capacity":{"cpu":"12","ephemeral-storage":"263174212Ki","hugepages-1Gi":"0","hugepages-2Mi":"0","memory":"12923048Ki","pods":"110"},"allocatable":{"cpu":"12","ephemeral-storage":"263174212Ki","hugepages-1Gi":"0","hugepages-2Mi":"0","memory":"12923048Ki","pods":"110"},"conditions":[{"type":"MemoryPressure","status":"False","lastHeartbeatTime":"2022-09-20T10:20:27Z","lastTransitionTime":"2022-09-20T10:20:27Z","reason":"KubeletHasSufficientMemory","message":"kubelet has sufficient memory available"},{"type":"DiskPressure","status":"False","lastHeartbeatTime":"2022-09-20T10:20:27Z","lastTransitionTime":"2022-09-20T10:20:27Z","reason":"KubeletHasNoDiskPressure","message":"kubelet has no disk pressure"},{"type":"PIDPressure","status":"False","lastHeartbeatTime":"2022-09-20T10:20:27Z","lastTransitionTime":"2022-09-20T10:20:27Z","reason":"KubeletHasSufficientPID","message":"kubelet has sufficient PID available"},{"type":"Ready","status":"False","lastHeartbeatTime":"2022-09-20T10:20:27Z","lastTransitionTime":"2022-09-20T10:20:27Z","reason":"KubeletNotReady","message":"[container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:docker: network plugin is not ready: cni config uninitialized, CSINode is not yet initialized]"}],"addresses":[{"type":"InternalIP","address":"192.168.49.4"},{"type":"Hostname","address":"minikube-m03"}],"daemonEndpoints":{"kubeletEndpoint":{"Port":10250}},"nodeInfo":{"machineID":"4c192b04687c403f8fbb9bc7975b21b3","systemUUID":"4c192b04687c403f8fbb9bc7975b21b3","bootID":"de31de94-2a42-4516-a4e6-7cb2de739fde","kernelVersion":"5.10.102.1-microsoft-standard-WSL2","osImage":"Ubuntu 20.04.4 LTS","containerRuntimeVersion":"docker://20.10.17","kubeletVersion":"v1.24.3","kubeProxyVersion":"v1.24.3","operatingSystem":"linux","architecture":"amd64"},"images":[{"names":["k8s.gcr.io/etcd@sha256:13f53ed1d91e2e11aac476ee9a0269fdda6cc4874eba903efd40daf50c55eee5","k8s.gcr.io/etcd:3.5.3-0"],"sizeBytes":299495233},{"names":["k8s.gcr.io/kube-apiserver@sha256:a04609b85962da7e6531d32b75f652b4fb9f5fe0b0ee0aa160856faad8ec5d96","k8s.gcr.io/kube-apiserver:v1.24.3"],"sizeBytes":129710737},{"names":["k8s.gcr.io/kube-controller-manager@sha256:f504eead8b8674ebc9067370ef51abbdc531b4a81813bfe464abccb8c76b6a53","k8s.gcr.io/kube-controller-manager:v1.24.3"],"sizeBytes":119360464},{"names":["k8s.gcr.io/kube-proxy@sha256:c1b135231b5b1a6799346cd701da4b59e5b7ef8e694ec7b04fb23b8dbe144137","k8s.gcr.io/kube-proxy:v1.24.3"],"sizeBytes":109939784},{"names":["k8s.gcr.io/kube-scheduler@sha256:e199523298224cd9f2a9a43c7c2c37fa57aff87648ed1e1de9984eba6f6005f0","k8s.gcr.io/kube-scheduler:v1.24.3"],"sizeBytes":50989989},{"names":["k8s.gcr.io/coredns/coredns@sha256:5b6ec0d6de9baaf3e92d0f66cd96a25b9edbce8716f5f15dcd1a616b3abd590e","k8s.gcr.io/coredns/coredns:v1.8.6"],"sizeBytes":46829283},{"names":["gcr.io/k8s-minikube/storage-provisioner@sha256:18eb69d1418e854ad5a19e399310e52808a8321e4c441c1dddad8977a0d7a944","gcr.io/k8s-minikube/storage-provisioner:v5"],"sizeBytes":31465472},{"names":["k8s.gcr.io/pause@sha256:bb6ed397957e9ca7c65ada0db5c5d1c707c9c8afc80a94acbe69f3ae76988f0c","k8s.gcr.io/pause:3.7"],"sizeBytes":711184}]}}]}
I0920 05:20:33.535388    7432 node_conditions.go:122] node storage ephemeral capacity is 263174212Ki
I0920 05:20:33.537387    7432 node_conditions.go:123] node cpu capacity is 12
I0920 05:20:33.540387    7432 node_conditions.go:122] node storage ephemeral capacity is 263174212Ki
I0920 05:20:33.540387    7432 node_conditions.go:123] node cpu capacity is 12
I0920 05:20:33.540387    7432 node_conditions.go:122] node storage ephemeral capacity is 263174212Ki
I0920 05:20:33.540387    7432 node_conditions.go:123] node cpu capacity is 12
I0920 05:20:33.540387    7432 node_conditions.go:105] duration metric: took 183.3202ms to run NodePressure ...
I0920 05:20:33.541387    7432 start.go:216] waiting for startup goroutines ...
I0920 05:20:34.097744    7432 start.go:506] kubectl: 1.25.1, cluster: 1.24.3 (minor skew: 1)
I0920 05:20:34.102086    7432 out.go:177] * Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default
